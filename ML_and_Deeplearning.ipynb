{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7bca798b-b21e-4b8b-b5cc-baa03825ea68",
   "metadata": {},
   "source": [
    "## Member\n",
    "6210422003 Kritsana Jongsathitphaibul​\n",
    "\n",
    "6210422033 Watcharapong Wongrattanasirikul​\n",
    "\n",
    "6210422038 Rangsarid Pringwanid​\n",
    "\n",
    "6210422058 Theptat Santanon "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3df6ed3c-fa9d-41e4-95e1-fa18b111dec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import re \n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, accuracy_score, classification_report, roc_curve, auc\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from xgboost import plot_importance\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.metrics import confusion_matrix\n",
    "sns.set_style(\"darkgrid\")\n",
    "from imblearn.pipeline import Pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.combine import SMOTETomek\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774c55ce-574d-4e07-8700-99e5906ce722",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "464c2121-540f-45f5-ae13-59a04346da85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UDI</th>\n",
       "      <th>Product ID</th>\n",
       "      <th>Type</th>\n",
       "      <th>Air temperature [K]</th>\n",
       "      <th>Process temperature [K]</th>\n",
       "      <th>Rotational speed [rpm]</th>\n",
       "      <th>Torque [Nm]</th>\n",
       "      <th>Tool wear [min]</th>\n",
       "      <th>Machine failure</th>\n",
       "      <th>TWF</th>\n",
       "      <th>HDF</th>\n",
       "      <th>PWF</th>\n",
       "      <th>OSF</th>\n",
       "      <th>RNF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>M14860</td>\n",
       "      <td>M</td>\n",
       "      <td>298.1</td>\n",
       "      <td>308.6</td>\n",
       "      <td>1551</td>\n",
       "      <td>42.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>L47181</td>\n",
       "      <td>L</td>\n",
       "      <td>298.2</td>\n",
       "      <td>308.7</td>\n",
       "      <td>1408</td>\n",
       "      <td>46.3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>L47182</td>\n",
       "      <td>L</td>\n",
       "      <td>298.1</td>\n",
       "      <td>308.5</td>\n",
       "      <td>1498</td>\n",
       "      <td>49.4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>L47183</td>\n",
       "      <td>L</td>\n",
       "      <td>298.2</td>\n",
       "      <td>308.6</td>\n",
       "      <td>1433</td>\n",
       "      <td>39.5</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>L47184</td>\n",
       "      <td>L</td>\n",
       "      <td>298.2</td>\n",
       "      <td>308.7</td>\n",
       "      <td>1408</td>\n",
       "      <td>40.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UDI Product ID Type  Air temperature [K]  Process temperature [K]  \\\n",
       "0    1     M14860    M                298.1                    308.6   \n",
       "1    2     L47181    L                298.2                    308.7   \n",
       "2    3     L47182    L                298.1                    308.5   \n",
       "3    4     L47183    L                298.2                    308.6   \n",
       "4    5     L47184    L                298.2                    308.7   \n",
       "\n",
       "   Rotational speed [rpm]  Torque [Nm]  Tool wear [min]  Machine failure  TWF  \\\n",
       "0                    1551         42.8                0                0    0   \n",
       "1                    1408         46.3                3                0    0   \n",
       "2                    1498         49.4                5                0    0   \n",
       "3                    1433         39.5                7                0    0   \n",
       "4                    1408         40.0                9                0    0   \n",
       "\n",
       "   HDF  PWF  OSF  RNF  \n",
       "0    0    0    0    0  \n",
       "1    0    0    0    0  \n",
       "2    0    0    0    0  \n",
       "3    0    0    0    0  \n",
       "4    0    0    0    0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading data \n",
    "\n",
    "df = pd.read_csv('ai4i2020.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec0f2c6-c03a-4385-910c-9ef19b2b0177",
   "metadata": {},
   "source": [
    "# Data Preparing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3cd0fc6a-8c54-4573-9825-296598373a4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UDI                        0\n",
       "Product ID                 0\n",
       "Type                       0\n",
       "Air temperature [K]        0\n",
       "Process temperature [K]    0\n",
       "Rotational speed [rpm]     0\n",
       "Torque [Nm]                0\n",
       "Tool wear [min]            0\n",
       "Machine failure            0\n",
       "TWF                        0\n",
       "HDF                        0\n",
       "PWF                        0\n",
       "OSF                        0\n",
       "RNF                        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# explore data \n",
    "# check null data \n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3295ea41-0449-42fb-a466-85b86d895370",
   "metadata": {},
   "source": [
    "# Column Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d50815aa-00ca-4ebf-958d-312a5b1eda48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['UDI', 'Product ID', 'Type', 'Air temperature [K]',\n",
       "       'Process temperature [K]', 'Rotational speed [rpm]', 'Torque [Nm]',\n",
       "       'Tool wear [min]', 'Machine failure', 'TWF', 'HDF', 'PWF', 'OSF',\n",
       "       'RNF'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42d35f39-3b92-4a8b-8a33-3301135d4f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_selected  =  ['Air temperature [K]','Process temperature [K]', 'Rotational speed [rpm]', 'Torque [Nm]','Tool wear [min]']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96cfcf8-5884-43e4-98c9-dab52949b1ab",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    " we transform feature from 8 feature to 37 feature such  take log ,  root , power, devide and multipier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d43224b1-4a6e-4558-8efd-159c71d7cec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering  \n",
    "def power_f(data) :\n",
    "    return data*data\n",
    "\n",
    "def root_f(data) :\n",
    "    return data**(0.5)\n",
    "# df[['Air temperature [K]_2' , 'Process temperature [K]_2' , 'Rotational speed [rpm]_2' ,'Torque [Nm]_2','Tool wear [min]_2']] = df[df_selected].apply(power_f)\n",
    "# df[['Air temperature [K]_rt' , 'Process temperature [K]_rt' , 'Rotational speed [rpm]_rt' ,'Torque [Nm]_rt','Tool wear [min]_rt']] = df[df_selected].apply(root_f)\n",
    "# df['Rotation_Torque'] = df['Rotational speed [rpm]'] * df['Torque [Nm]']\n",
    "# df['Temp_diff'] =  df['Process temperature [K]'] - df['Process temperature [K]']\n",
    "\n",
    "df[\"Temp\"] = df[\"Air temperature [K]\"]*df[\"Process temperature [K]\"]\n",
    "df[\"Poor\"] = df[\"Torque [Nm]\"]/df[\"Rotational speed [rpm]\"]\n",
    "df[\"Poor2\"] = df[\"Torque [Nm]\"]/np.sqrt(df[\"Rotational speed [rpm]\"])\n",
    "df[\"In_Temp\"] = df[\"Air temperature [K]\"]/df[\"Process temperature [K]\"]\n",
    "df[\"In_Poor\"] = df[\"Torque [Nm]\"]*df[\"Rotational speed [rpm]\"]\n",
    "df[\"In_Poor2\"] = df[\"Torque [Nm]\"]*np.sqrt(df[\"Rotational speed [rpm]\"])\n",
    "df[\"Air_Sq\"] = df[\"Air temperature [K]\"]**2\n",
    "df[\"Pro_Sq\"] = df[\"Process temperature [K]\"]**2\n",
    "df[\"Rot_Sq\"] = df[\"Rotational speed [rpm]\"]**2\n",
    "df[\"Tor_Sq\"] = df[\"Torque [Nm]\"]**(1/2)\n",
    "df[\"Too_Sq\"] = df[\"Tool wear [min]\"]**(1/2)\n",
    "df[\"Air_Sqr\"] = df[\"Air temperature [K]\"]**(1/2)\n",
    "df[\"Pro_Sqr\"] = df[\"Process temperature [K]\"]**(1/2)\n",
    "df[\"Rot_Sqr\"] = df[\"Rotational speed [rpm]\"]**(1/2)\n",
    "df[\"Tor_Sqr\"] = df[\"Torque [Nm]\"]**(1/2)\n",
    "df[\"Too_Sqr\"] = df[\"Tool wear [min]\"]**(1/2)\n",
    "df[\"Diff_Tepm\"] = np.abs(df[\"Air temperature [K]\"]-df[\"Process temperature [K]\"])\n",
    "df[\"Ro_Tor_Mul\"] = df[\"Rotational speed [rpm]\"]*df[\"Torque [Nm]\"]\n",
    "df[\"Ro_Tor_Div\"] = df[\"Rotational speed [rpm]\"]/df[\"Torque [Nm]\"]\n",
    "df[\"Ro_Tor_Mul_Sqr\"] = np.sqrt(df[\"Rotational speed [rpm]\"])*np.sqrt(df[\"Torque [Nm]\"])\n",
    "df[\"Ro_Tor_Mul_Log\"] = np.log(df[\"Rotational speed [rpm]\"])*np.log(df[\"Torque [Nm]\"])\n",
    "df[\"Ro_Tor_Div_Sqr\"] = np.sqrt(df[\"Rotational speed [rpm]\"])/np.sqrt(df[\"Torque [Nm]\"])\n",
    "df[\"Ro_Tor_Div_Log\"] = np.log(df[\"Rotational speed [rpm]\"])/np.log(df[\"Torque [Nm]\"])\n",
    "df[\"Ro_Tem_Mul\"] = df[\"Rotational speed [rpm]\"]*df[\"Diff_Tepm\"]\n",
    "df[\"Tor_Tem_Div\"] = df[\"Diff_Tepm\"]/df[\"Torque [Nm]\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3460b0dc-f591-4958-afc1-0d88e6d1799f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['UDI', 'Product ID', 'Type', 'Air temperature [K]',\n",
       "       'Process temperature [K]', 'Rotational speed [rpm]', 'Torque [Nm]',\n",
       "       'Tool wear [min]', 'Machine failure', 'TWF', 'HDF', 'PWF', 'OSF', 'RNF',\n",
       "       'Temp', 'Poor', 'Poor2', 'In_Temp', 'In_Poor', 'In_Poor2', 'Air_Sq',\n",
       "       'Pro_Sq', 'Rot_Sq', 'Tor_Sq', 'Too_Sq', 'Air_Sqr', 'Pro_Sqr', 'Rot_Sqr',\n",
       "       'Tor_Sqr', 'Too_Sqr', 'Diff_Tepm', 'Ro_Tor_Mul', 'Ro_Tor_Div',\n",
       "       'Ro_Tor_Mul_Sqr', 'Ro_Tor_Mul_Log', 'Ro_Tor_Div_Sqr', 'Ro_Tor_Div_Log',\n",
       "       'Ro_Tem_Mul', 'Tor_Tem_Div'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4f375ff-aa8c-411c-943e-2738b694dcfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UDI</th>\n",
       "      <th>Product ID</th>\n",
       "      <th>Type</th>\n",
       "      <th>Air temperature [K]</th>\n",
       "      <th>Process temperature [K]</th>\n",
       "      <th>Rotational speed [rpm]</th>\n",
       "      <th>Torque [Nm]</th>\n",
       "      <th>Tool wear [min]</th>\n",
       "      <th>Machine failure</th>\n",
       "      <th>TWF</th>\n",
       "      <th>...</th>\n",
       "      <th>Too_Sqr</th>\n",
       "      <th>Diff_Tepm</th>\n",
       "      <th>Ro_Tor_Mul</th>\n",
       "      <th>Ro_Tor_Div</th>\n",
       "      <th>Ro_Tor_Mul_Sqr</th>\n",
       "      <th>Ro_Tor_Mul_Log</th>\n",
       "      <th>Ro_Tor_Div_Sqr</th>\n",
       "      <th>Ro_Tor_Div_Log</th>\n",
       "      <th>Ro_Tem_Mul</th>\n",
       "      <th>Tor_Tem_Div</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>M14860</td>\n",
       "      <td>M</td>\n",
       "      <td>298.1</td>\n",
       "      <td>308.6</td>\n",
       "      <td>1551</td>\n",
       "      <td>42.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.5</td>\n",
       "      <td>66382.8</td>\n",
       "      <td>36.238318</td>\n",
       "      <td>257.648598</td>\n",
       "      <td>27.597990</td>\n",
       "      <td>6.019827</td>\n",
       "      <td>1.955698</td>\n",
       "      <td>16285.5</td>\n",
       "      <td>0.245327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>L47181</td>\n",
       "      <td>L</td>\n",
       "      <td>298.2</td>\n",
       "      <td>308.7</td>\n",
       "      <td>1408</td>\n",
       "      <td>46.3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.732051</td>\n",
       "      <td>10.5</td>\n",
       "      <td>65190.4</td>\n",
       "      <td>30.410367</td>\n",
       "      <td>255.324108</td>\n",
       "      <td>27.804494</td>\n",
       "      <td>5.514560</td>\n",
       "      <td>1.890393</td>\n",
       "      <td>14784.0</td>\n",
       "      <td>0.226782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>L47182</td>\n",
       "      <td>L</td>\n",
       "      <td>298.1</td>\n",
       "      <td>308.5</td>\n",
       "      <td>1498</td>\n",
       "      <td>49.4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.236068</td>\n",
       "      <td>10.4</td>\n",
       "      <td>74001.2</td>\n",
       "      <td>30.323887</td>\n",
       "      <td>272.031616</td>\n",
       "      <td>28.515994</td>\n",
       "      <td>5.506713</td>\n",
       "      <td>1.874866</td>\n",
       "      <td>15579.2</td>\n",
       "      <td>0.210526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>L47183</td>\n",
       "      <td>L</td>\n",
       "      <td>298.2</td>\n",
       "      <td>308.6</td>\n",
       "      <td>1433</td>\n",
       "      <td>39.5</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.645751</td>\n",
       "      <td>10.4</td>\n",
       "      <td>56603.5</td>\n",
       "      <td>36.278481</td>\n",
       "      <td>237.914901</td>\n",
       "      <td>26.717609</td>\n",
       "      <td>6.023162</td>\n",
       "      <td>1.976858</td>\n",
       "      <td>14903.2</td>\n",
       "      <td>0.263291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>L47184</td>\n",
       "      <td>L</td>\n",
       "      <td>298.2</td>\n",
       "      <td>308.7</td>\n",
       "      <td>1408</td>\n",
       "      <td>40.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>10.5</td>\n",
       "      <td>56320.0</td>\n",
       "      <td>35.200000</td>\n",
       "      <td>237.318352</td>\n",
       "      <td>26.744101</td>\n",
       "      <td>5.932959</td>\n",
       "      <td>1.965346</td>\n",
       "      <td>14784.0</td>\n",
       "      <td>0.262500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   UDI Product ID Type  Air temperature [K]  Process temperature [K]  \\\n",
       "0    1     M14860    M                298.1                    308.6   \n",
       "1    2     L47181    L                298.2                    308.7   \n",
       "2    3     L47182    L                298.1                    308.5   \n",
       "3    4     L47183    L                298.2                    308.6   \n",
       "4    5     L47184    L                298.2                    308.7   \n",
       "\n",
       "   Rotational speed [rpm]  Torque [Nm]  Tool wear [min]  Machine failure  TWF  \\\n",
       "0                    1551         42.8                0                0    0   \n",
       "1                    1408         46.3                3                0    0   \n",
       "2                    1498         49.4                5                0    0   \n",
       "3                    1433         39.5                7                0    0   \n",
       "4                    1408         40.0                9                0    0   \n",
       "\n",
       "   ...   Too_Sqr  Diff_Tepm  Ro_Tor_Mul  Ro_Tor_Div  Ro_Tor_Mul_Sqr  \\\n",
       "0  ...  0.000000       10.5     66382.8   36.238318      257.648598   \n",
       "1  ...  1.732051       10.5     65190.4   30.410367      255.324108   \n",
       "2  ...  2.236068       10.4     74001.2   30.323887      272.031616   \n",
       "3  ...  2.645751       10.4     56603.5   36.278481      237.914901   \n",
       "4  ...  3.000000       10.5     56320.0   35.200000      237.318352   \n",
       "\n",
       "   Ro_Tor_Mul_Log  Ro_Tor_Div_Sqr  Ro_Tor_Div_Log  Ro_Tem_Mul  Tor_Tem_Div  \n",
       "0       27.597990        6.019827        1.955698     16285.5     0.245327  \n",
       "1       27.804494        5.514560        1.890393     14784.0     0.226782  \n",
       "2       28.515994        5.506713        1.874866     15579.2     0.210526  \n",
       "3       26.717609        6.023162        1.976858     14903.2     0.263291  \n",
       "4       26.744101        5.932959        1.965346     14784.0     0.262500  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cdb63b4e-19bc-4dff-afaa-0160648409fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 39)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06055315-3a64-4aed-86f0-be3efb51d7c6",
   "metadata": {},
   "source": [
    "## Duplicated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "52578e6b-42a1-4985-a574-e914c494b4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## copy \n",
    "\n",
    "df_c =  df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5edcf953-da4b-484c-825f-e226c5ec581f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['UDI', 'Product ID', 'Type', 'Air temperature [K]',\n",
       "       'Process temperature [K]', 'Rotational speed [rpm]', 'Torque [Nm]',\n",
       "       'Tool wear [min]', 'Machine failure', 'TWF', 'HDF', 'PWF', 'OSF', 'RNF',\n",
       "       'Temp', 'Poor', 'Poor2', 'In_Temp', 'In_Poor', 'In_Poor2', 'Air_Sq',\n",
       "       'Pro_Sq', 'Rot_Sq', 'Tor_Sq', 'Too_Sq', 'Air_Sqr', 'Pro_Sqr', 'Rot_Sqr',\n",
       "       'Tor_Sqr', 'Too_Sqr', 'Diff_Tepm', 'Ro_Tor_Mul', 'Ro_Tor_Div',\n",
       "       'Ro_Tor_Mul_Sqr', 'Ro_Tor_Mul_Log', 'Ro_Tor_Div_Sqr', 'Ro_Tor_Div_Log',\n",
       "       'Ro_Tem_Mul', 'Tor_Tem_Div'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_c.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6118e4d3-3113-4d71-aec6-e636a181683e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check data label  \n",
    "#df_label  =  df_c.groupby(by  = 'Machine failure' ).count()\n",
    "\n",
    "df_label =  df_c['Machine failure'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0e6694-781c-4097-be75-c4fb18f3800f",
   "metadata": {},
   "source": [
    "# Data Exploratory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bca02fc6-c7b8-486a-a59f-74ddfd9ce113",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    9661\n",
       "1     339\n",
       "Name: Machine failure, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "41bb67e8-5729-443a-8452-f0efafd20d5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(close=None, block=None)>"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "x=range(2)\n",
    "plt.bar(x,df_label)\n",
    "plt.xticks(df_label.index)\n",
    "plt.title('Response Distribution')\n",
    "plt.xlabel('Convert or Not')\n",
    "plt.ylabel('no. of users')\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6c2e055c-f265-4198-a893-0b9ef27502a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x,y data \n",
    "x =  df_c.drop(columns = ['UDI','Product ID','Machine failure', 'TWF', 'HDF', 'PWF', 'OSF', 'RNF','Type'], axis =  1   )\n",
    "y = df_c['Machine failure']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3666f4a4-f5b3-4e6e-9ff3-cdd33ac04595",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Air temperature [K]', 'Process temperature [K]',\n",
       "       'Rotational speed [rpm]', 'Torque [Nm]', 'Tool wear [min]', 'Temp',\n",
       "       'Poor', 'Poor2', 'In_Temp', 'In_Poor', 'In_Poor2', 'Air_Sq', 'Pro_Sq',\n",
       "       'Rot_Sq', 'Tor_Sq', 'Too_Sq', 'Air_Sqr', 'Pro_Sqr', 'Rot_Sqr',\n",
       "       'Tor_Sqr', 'Too_Sqr', 'Diff_Tepm', 'Ro_Tor_Mul', 'Ro_Tor_Div',\n",
       "       'Ro_Tor_Mul_Sqr', 'Ro_Tor_Mul_Log', 'Ro_Tor_Div_Sqr', 'Ro_Tor_Div_Log',\n",
       "       'Ro_Tem_Mul', 'Tor_Tem_Div'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1780bb6d-f142-4b1e-8639-df8997b8da5e",
   "metadata": {},
   "source": [
    "## Function  preparing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d2cf07e6-c10a-4ef5-acea-1bb7d3e6dc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## feature importance\n",
    "\n",
    "\n",
    "# ## Feature importtance\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "# data train test split \n",
    "def split_data(x,y,n): # test_size\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=float(n), random_state=123)\n",
    "    return X_train, X_test, y_train, y_test \n",
    "\n",
    "#one hot encoder \n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "def one_hot(x):\n",
    "    x = pd.get_dummies(data = x , columns  =  ['Type'] )\n",
    "    return x \n",
    "\n",
    "## feature importance \n",
    "def f_importance(X,y) :\n",
    "    model_impor =  DecisionTreeClassifier()\n",
    "    rf  =  RandomForestRegressor(n_estimators=100)\n",
    "    rf.fit(X,y)\n",
    "    # check type value \n",
    "    print(type(rf.feature_importances_))\n",
    "    feature_score = rf.feature_importances_\n",
    "    \n",
    "    df_feature_score =  pd.DataFrame(feature_score, index = list(X.columns), columns= ['Feature_importance']).sort_values(by = 'Feature_importance' , ascending = False)\n",
    "    \n",
    "    return df_feature_score\n",
    "# check number of sample \n",
    "\n",
    "def plot_sample(df,columns_label) :\n",
    "    df_goup =  df.groupby(by=columns_label).count().reset_index()\n",
    "    df_goup.plot.bar(x=columns_label,y='Machine failure').show()\n",
    "    \n",
    "## data standardize \n",
    "from sklearn import preprocessing\n",
    "def standardized(data) :\n",
    "    #new_data  =  preprocessing.scale(data) # \n",
    "    sc = StandardScaler()\n",
    "    new_data = sc.fit_transform(data)\n",
    "    return new_data      \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e66425-61c2-4979-8b8b-9eb56e9068f9",
   "metadata": {},
   "source": [
    "## Imbalance Handling function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e5d90c36-60bf-40ad-9947-eb7d8f2d700d",
   "metadata": {},
   "outputs": [],
   "source": [
    "imbalance_list = ['under_sample','over_sample','SMOTE','SMOTE_TOMEK',None]\n",
    "\n",
    "def imbalance( x_train , y_train ,m = None ):\n",
    "    if m == 'under_sample' :\n",
    "        random_under = RandomUnderSampler(random_state=123)\n",
    "        random_under.fit(x_train, y_train)\n",
    "        x_undersampled, y_undersampled = random_under.fit_resample(x_train, y_train)\n",
    "        return x_undersampled, y_undersampled\n",
    "    \n",
    "    elif m == 'over_sample' :\n",
    "        random_over = RandomOverSampler(random_state=123)\n",
    "        random_over.fit(x_train, y_train)\n",
    "        X_oversampled, y_oversampled = random_over.fit_resample(x_train, y_train)\n",
    "        df_oversampled = pd.concat([pd.DataFrame(data=X_oversampled),pd.DataFrame(data=y_oversampled)], axis=1, sort=False)\n",
    "        return  X_oversampled, y_oversampled\n",
    "    elif m == 'SMOTE' :\n",
    "        sm = SMOTE(random_state=123)\n",
    "        sm.fit(x_train, y_train)\n",
    "        X_SMOTE, y_SMOTE = sm.fit_resample(x_train, y_train)\n",
    "        df_SMOTE = pd.concat([pd.DataFrame(data=X_SMOTE),pd.DataFrame(data=y_SMOTE)], axis=1, sort=False)\n",
    "        return  X_SMOTE, y_SMOTE\n",
    "    elif m == 'SMOTE_TOMEK' :\n",
    "        smt=SMOTETomek(random_state=123)\n",
    "        smt.fit(x_train, y_train)\n",
    "        X_SMOTET, y_SMOTET = smt.fit_resample(x_train, y_train)\n",
    "        df_SMOTET = pd.concat([pd.DataFrame(data=X_SMOTET),pd.DataFrame(data=y_SMOTET)], axis=1, sort=False)\n",
    "        return X_SMOTET, y_SMOTET\n",
    "    elif m == None : \n",
    "        \n",
    "        return x_train , y_train\n",
    "        \n",
    "        #  rotation speed* toue "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c9a4e14-838d-4a3c-8141-7e21c8ced7f7",
   "metadata": {},
   "source": [
    "## Result Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "74b66502-392f-4cca-9f9d-51f764515226",
   "metadata": {},
   "outputs": [],
   "source": [
    "# result data \n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# calculates recall for 1:100 dataset with 90 tp and 10 fn\n",
    "from sklearn.metrics import recall_score , precision_score\n",
    "def result_AOC(y_test, y_predict,probs):\n",
    "    \n",
    "    # tn, fp, fn, tp  = confusion_matrix(y_test, y_predict).ravel()\n",
    "    # accuracy   =  (tp+tn)/(tn+tp+fn+fp)\n",
    "    # percision  =  tp/(tp+fp) \n",
    "    # recall   =  tp/(tp+fn)\n",
    "    predicted_y = []\n",
    "    expected_y = []\n",
    "    #predictions = logreg_model_under.predict(X_test)\n",
    "    predicted_y.extend(y_predict)\n",
    "    expected_y.extend(y_test)\n",
    "    report_test = classification_report(expected_y, predicted_y)\n",
    "    print(report_test)\n",
    "    probs = probs[:, 1]\n",
    "    # calculate scores\n",
    "   # ns_auc = roc_auc_score(y_test, ns_probs)\n",
    "    lr_auc = roc_auc_score(y_test, probs)\n",
    "    # summarize scores\n",
    "    #print('No Skill: ROC AUC=%.3f' % (ns_auc))\n",
    "    print('Logistic: ROC AUC=%.3f' % (lr_auc))\n",
    "    #print(f'accuracy {accuracy} , percision {percision},  recall {recall}')\n",
    "    #return accuracy ,percision , recall,lr_auc\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53e4116-e1a4-41c4-87d8-31f791ed1dc1",
   "metadata": {},
   "source": [
    "## Model Function Preparing configure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cc101337-d25d-46bd-80fc-098b1a5c9ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## created model  function\n",
    " # Models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, VotingClassifier, AdaBoostClassifier, BaggingRegressor, GradientBoostingClassifier,BaggingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import SGDClassifier , LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "model = ['Svm','Logistic','XGBoost','Nb','sgd','Random_f','Knn','Decision_t']\n",
    "def fn_model(model,x_train,y_train,x_test,y_test) :\n",
    "    if model == 'Svm' :\n",
    "        clf = SVC(kernel='linear',probability=True)\n",
    "        train_d = clf.fit(x_train, y_train)\n",
    "        #Predict the response for test dataset\n",
    "        sc = StandardScaler()\n",
    "        x_test = sc.fit_transform(x_test)\n",
    "        y_pred = train_d.predict(x_test)\n",
    "        y_probs = train_d.predict_proba(x_test)\n",
    "        return y_pred,y_probs\n",
    "    elif model  ==  'Logistic' :\n",
    "        logreg = LogisticRegression(solver='liblinear', class_weight='balanced')\n",
    "        train_d = logreg.fit(x_train, y_train)\n",
    "        sc = StandardScaler()\n",
    "        x_test = sc.fit_transform(x_test)\n",
    "        y_pred = train_d.predict(x_test)\n",
    "        y_probs = train_d.predict_proba(x_test)\n",
    "        return y_pred, y_probs\n",
    "    elif model == 'XGBoost' :\n",
    "        xgb_model =  xgb.XGBClassifier(objective='binary:logistic', eval_metric=\"auc\" )\n",
    "        xgb_m = xgb_model.fit(x_train, y_train, early_stopping_rounds=5, eval_set=[(x_test.to_numpy(), y_test)] )\n",
    "        sc = StandardScaler()\n",
    "        x_test = sc.fit_transform(x_test)\n",
    "        y_pred =  xgb_m.predict(x_test)\n",
    "        y_probs = xgb_m.predict_proba(x_test)\n",
    "        return y_pred, y_probs         \n",
    "    elif model ==  'Nb' :\n",
    "        nb =  GaussianNB()\n",
    "        nb.fit(x_train, y_train)\n",
    "        sc = StandardScaler()\n",
    "        x_test = sc.fit_transform(x_test)\n",
    "        y_pred=nb.predict(x_test) \n",
    "        y_probs =  nb.predict_proba(x_test)\n",
    "        return y_pred ,  y_probs \n",
    "    \n",
    "    elif model == 'sgd' :\n",
    "        sgd =  SGDClassifier(loss='modified_huber', shuffle=True,random_state=101)\n",
    "        sgd.fit(x_train, y_train)\n",
    "        sc = StandardScaler()\n",
    "        x_test = sc.fit_transform(x_test)\n",
    "        y_pred=sgd.predict(x_test)\n",
    "        y_probs  =  sgd.predict_proba(x_test)\n",
    "        return y_pred , y_probs\n",
    "    \n",
    "    elif model  ==  'Random_f' :\n",
    "        Rdf =RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "        #Train the model using the training sets y_pred=clf.predict(X_test)\n",
    "        Rdf.fit(x_train,y_train)\n",
    "        sc = StandardScaler()\n",
    "        x_test = sc.fit_transform(x_test)\n",
    "        y_pred = Rdf.predict(x_test)        \n",
    "        \n",
    "        y_probs  =  Rdf.predict_proba(x_test)\n",
    "        return y_pred , y_probs\n",
    "        \n",
    "    elif model ==  'Knn' :\n",
    "        Knn =  KNeighborsClassifier(n_neighbors=3)\n",
    "        Knn.fit(x_train,y_train)\n",
    "        # prediction\n",
    "        sc = StandardScaler()\n",
    "        x_test = sc.fit_transform(x_test)\n",
    "        y_pred = Knn.predict(x_test)\n",
    "        y_probs = Knn.predict_proba(x_test)\n",
    "        return  y_pred,y_probs\n",
    "    elif model   ==  'Decision_t' :\n",
    "        Dt = DecisionTreeClassifier(max_depth=10, random_state=101, max_features = None, min_samples_leaf = trees)\n",
    "        Dt.fit(x_train,y_train)\n",
    "        sc = StandardScaler()\n",
    "        x_test = sc.fit_transform(x_test)\n",
    "        #prediction \n",
    "        y_pred = Dt.predict(x_test)\n",
    "        y_probs  =  Dt.predict_proba(x_test)\n",
    "        return y_pred , y_probs\n",
    "        \n",
    "     \n",
    "    elif model  == 'deep' :\n",
    "        \n",
    "        ### created model  ###\n",
    "        model = Sequential()  \n",
    "        model.add(Dense(256, kernel_initializer='uniform',activation='relu',input_dim= x_train.shape[1]))\n",
    "        #model.add(Dense(256,activation='relu'))\n",
    "        model.add(Dense(128, kernel_initializer='uniform',activation='relu'))\n",
    "        model.add(Dense(64, kernel_initializer='uniform',activation='relu'))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(Dense(1, kernel_initializer='uniform',activation='sigmoid'))\n",
    "        ### add complie###\n",
    "        \n",
    "        model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "         \n",
    "        model_fit = model.fit(x = x_train ,y = y_train,epochs = 200,batch_size=512) #,validation_data=(x_test ,y_test)\n",
    "        sc = StandardScaler()\n",
    "        x_test = sc.fit_transform(x_test)\n",
    "        y_pred = model.predict(x_test)\n",
    "        #y_probs  =  model.predict_proba(x_test)\n",
    "        \n",
    "        return y_pred , y_probs \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e292d6c-9c5a-48a7-966e-b0f121132fdf",
   "metadata": {},
   "source": [
    "# Runing Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dafccacf-a752-4b6b-9bcb-707b233438ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare to find feature importance \n",
    "x1  =  x.copy()\n",
    "#x1 = x1.drop(columns=['Type'])\n",
    "x_col = list(x1.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "737928de-b925-45d5-ae6e-fc708cb6a662",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Air temperature [K]</th>\n",
       "      <th>Process temperature [K]</th>\n",
       "      <th>Rotational speed [rpm]</th>\n",
       "      <th>Torque [Nm]</th>\n",
       "      <th>Tool wear [min]</th>\n",
       "      <th>Temp</th>\n",
       "      <th>Poor</th>\n",
       "      <th>Poor2</th>\n",
       "      <th>In_Temp</th>\n",
       "      <th>In_Poor</th>\n",
       "      <th>...</th>\n",
       "      <th>Too_Sqr</th>\n",
       "      <th>Diff_Tepm</th>\n",
       "      <th>Ro_Tor_Mul</th>\n",
       "      <th>Ro_Tor_Div</th>\n",
       "      <th>Ro_Tor_Mul_Sqr</th>\n",
       "      <th>Ro_Tor_Mul_Log</th>\n",
       "      <th>Ro_Tor_Div_Sqr</th>\n",
       "      <th>Ro_Tor_Div_Log</th>\n",
       "      <th>Ro_Tem_Mul</th>\n",
       "      <th>Tor_Tem_Div</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>298.1</td>\n",
       "      <td>308.6</td>\n",
       "      <td>1551</td>\n",
       "      <td>42.8</td>\n",
       "      <td>0</td>\n",
       "      <td>91993.66</td>\n",
       "      <td>0.027595</td>\n",
       "      <td>1.086771</td>\n",
       "      <td>0.965975</td>\n",
       "      <td>66382.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.5</td>\n",
       "      <td>66382.8</td>\n",
       "      <td>36.238318</td>\n",
       "      <td>257.648598</td>\n",
       "      <td>27.597990</td>\n",
       "      <td>6.019827</td>\n",
       "      <td>1.955698</td>\n",
       "      <td>16285.5</td>\n",
       "      <td>0.245327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>298.2</td>\n",
       "      <td>308.7</td>\n",
       "      <td>1408</td>\n",
       "      <td>46.3</td>\n",
       "      <td>3</td>\n",
       "      <td>92054.34</td>\n",
       "      <td>0.032884</td>\n",
       "      <td>1.233899</td>\n",
       "      <td>0.965986</td>\n",
       "      <td>65190.4</td>\n",
       "      <td>...</td>\n",
       "      <td>1.732051</td>\n",
       "      <td>10.5</td>\n",
       "      <td>65190.4</td>\n",
       "      <td>30.410367</td>\n",
       "      <td>255.324108</td>\n",
       "      <td>27.804494</td>\n",
       "      <td>5.514560</td>\n",
       "      <td>1.890393</td>\n",
       "      <td>14784.0</td>\n",
       "      <td>0.226782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>298.1</td>\n",
       "      <td>308.5</td>\n",
       "      <td>1498</td>\n",
       "      <td>49.4</td>\n",
       "      <td>5</td>\n",
       "      <td>91963.85</td>\n",
       "      <td>0.032977</td>\n",
       "      <td>1.276354</td>\n",
       "      <td>0.966288</td>\n",
       "      <td>74001.2</td>\n",
       "      <td>...</td>\n",
       "      <td>2.236068</td>\n",
       "      <td>10.4</td>\n",
       "      <td>74001.2</td>\n",
       "      <td>30.323887</td>\n",
       "      <td>272.031616</td>\n",
       "      <td>28.515994</td>\n",
       "      <td>5.506713</td>\n",
       "      <td>1.874866</td>\n",
       "      <td>15579.2</td>\n",
       "      <td>0.210526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>298.2</td>\n",
       "      <td>308.6</td>\n",
       "      <td>1433</td>\n",
       "      <td>39.5</td>\n",
       "      <td>7</td>\n",
       "      <td>92024.52</td>\n",
       "      <td>0.027565</td>\n",
       "      <td>1.043456</td>\n",
       "      <td>0.966299</td>\n",
       "      <td>56603.5</td>\n",
       "      <td>...</td>\n",
       "      <td>2.645751</td>\n",
       "      <td>10.4</td>\n",
       "      <td>56603.5</td>\n",
       "      <td>36.278481</td>\n",
       "      <td>237.914901</td>\n",
       "      <td>26.717609</td>\n",
       "      <td>6.023162</td>\n",
       "      <td>1.976858</td>\n",
       "      <td>14903.2</td>\n",
       "      <td>0.263291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>298.2</td>\n",
       "      <td>308.7</td>\n",
       "      <td>1408</td>\n",
       "      <td>40.0</td>\n",
       "      <td>9</td>\n",
       "      <td>92054.34</td>\n",
       "      <td>0.028409</td>\n",
       "      <td>1.066004</td>\n",
       "      <td>0.965986</td>\n",
       "      <td>56320.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>10.5</td>\n",
       "      <td>56320.0</td>\n",
       "      <td>35.200000</td>\n",
       "      <td>237.318352</td>\n",
       "      <td>26.744101</td>\n",
       "      <td>5.932959</td>\n",
       "      <td>1.965346</td>\n",
       "      <td>14784.0</td>\n",
       "      <td>0.262500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Air temperature [K]  Process temperature [K]  Rotational speed [rpm]  \\\n",
       "0                298.1                    308.6                    1551   \n",
       "1                298.2                    308.7                    1408   \n",
       "2                298.1                    308.5                    1498   \n",
       "3                298.2                    308.6                    1433   \n",
       "4                298.2                    308.7                    1408   \n",
       "\n",
       "   Torque [Nm]  Tool wear [min]      Temp      Poor     Poor2   In_Temp  \\\n",
       "0         42.8                0  91993.66  0.027595  1.086771  0.965975   \n",
       "1         46.3                3  92054.34  0.032884  1.233899  0.965986   \n",
       "2         49.4                5  91963.85  0.032977  1.276354  0.966288   \n",
       "3         39.5                7  92024.52  0.027565  1.043456  0.966299   \n",
       "4         40.0                9  92054.34  0.028409  1.066004  0.965986   \n",
       "\n",
       "   In_Poor  ...   Too_Sqr  Diff_Tepm  Ro_Tor_Mul  Ro_Tor_Div  Ro_Tor_Mul_Sqr  \\\n",
       "0  66382.8  ...  0.000000       10.5     66382.8   36.238318      257.648598   \n",
       "1  65190.4  ...  1.732051       10.5     65190.4   30.410367      255.324108   \n",
       "2  74001.2  ...  2.236068       10.4     74001.2   30.323887      272.031616   \n",
       "3  56603.5  ...  2.645751       10.4     56603.5   36.278481      237.914901   \n",
       "4  56320.0  ...  3.000000       10.5     56320.0   35.200000      237.318352   \n",
       "\n",
       "   Ro_Tor_Mul_Log  Ro_Tor_Div_Sqr  Ro_Tor_Div_Log  Ro_Tem_Mul  Tor_Tem_Div  \n",
       "0       27.597990        6.019827        1.955698     16285.5     0.245327  \n",
       "1       27.804494        5.514560        1.890393     14784.0     0.226782  \n",
       "2       28.515994        5.506713        1.874866     15579.2     0.210526  \n",
       "3       26.717609        6.023162        1.976858     14903.2     0.263291  \n",
       "4       26.744101        5.932959        1.965346     14784.0     0.262500  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd0990b-1498-44e4-9992-16dc5efc2972",
   "metadata": {},
   "source": [
    "## Data Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "75edf789-dbc5-4b44-998c-4e102a86ce45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.95238944, -0.94735989,  0.06818514, ..., -0.31755104,\n",
       "         0.38396764, -0.24887505],\n",
       "       [-0.90239341, -0.879959  , -0.72947151, ..., -0.62883143,\n",
       "        -0.2567811 , -0.43493645],\n",
       "       [-0.95238944, -1.01476077, -0.22744984, ..., -0.70283946,\n",
       "         0.08256182, -0.59802563],\n",
       "       ...,\n",
       "       [-0.50242514, -0.94735989,  0.59251888, ...,  0.42125301,\n",
       "         0.1733719 ,  0.17348774],\n",
       "       [-0.50242514, -0.879959  , -0.72947151, ..., -0.73659479,\n",
       "        -0.73746001, -0.70363443],\n",
       "       [-0.50242514, -0.879959  , -0.2162938 , ..., -0.20253698,\n",
       "        -0.35663805, -0.2893432 ]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_std = standardized(x1)\n",
    "x_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "e0f299d5-aee1-4ded-b2bb-ede6e265d3c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Air temperature [K]</th>\n",
       "      <th>Process temperature [K]</th>\n",
       "      <th>Rotational speed [rpm]</th>\n",
       "      <th>Torque [Nm]</th>\n",
       "      <th>Tool wear [min]</th>\n",
       "      <th>Temp</th>\n",
       "      <th>Poor</th>\n",
       "      <th>Poor2</th>\n",
       "      <th>In_Temp</th>\n",
       "      <th>In_Poor</th>\n",
       "      <th>...</th>\n",
       "      <th>Too_Sqr</th>\n",
       "      <th>Diff_Tepm</th>\n",
       "      <th>Ro_Tor_Mul</th>\n",
       "      <th>Ro_Tor_Div</th>\n",
       "      <th>Ro_Tor_Mul_Sqr</th>\n",
       "      <th>Ro_Tor_Mul_Log</th>\n",
       "      <th>Ro_Tor_Div_Sqr</th>\n",
       "      <th>Ro_Tor_Div_Log</th>\n",
       "      <th>Ro_Tem_Mul</th>\n",
       "      <th>Tor_Tem_Div</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.952389</td>\n",
       "      <td>-0.947360</td>\n",
       "      <td>0.068185</td>\n",
       "      <td>0.282200</td>\n",
       "      <td>-1.695984</td>\n",
       "      <td>-0.980109</td>\n",
       "      <td>0.079191</td>\n",
       "      <td>0.169599</td>\n",
       "      <td>-0.538083</td>\n",
       "      <td>0.629443</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.723864</td>\n",
       "      <td>0.498849</td>\n",
       "      <td>0.629443</td>\n",
       "      <td>-0.276573</td>\n",
       "      <td>0.647619</td>\n",
       "      <td>0.493815</td>\n",
       "      <td>-0.281829</td>\n",
       "      <td>-0.317551</td>\n",
       "      <td>0.383968</td>\n",
       "      <td>-0.248875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.902393</td>\n",
       "      <td>-0.879959</td>\n",
       "      <td>-0.729472</td>\n",
       "      <td>0.633308</td>\n",
       "      <td>-1.648852</td>\n",
       "      <td>-0.921349</td>\n",
       "      <td>0.677574</td>\n",
       "      <td>0.660881</td>\n",
       "      <td>-0.534714</td>\n",
       "      <td>0.512456</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.240150</td>\n",
       "      <td>0.498849</td>\n",
       "      <td>0.512456</td>\n",
       "      <td>-0.509201</td>\n",
       "      <td>0.537571</td>\n",
       "      <td>0.615954</td>\n",
       "      <td>-0.640230</td>\n",
       "      <td>-0.628831</td>\n",
       "      <td>-0.256781</td>\n",
       "      <td>-0.434936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.952389</td>\n",
       "      <td>-1.014761</td>\n",
       "      <td>-0.227450</td>\n",
       "      <td>0.944290</td>\n",
       "      <td>-1.617430</td>\n",
       "      <td>-1.008976</td>\n",
       "      <td>0.688185</td>\n",
       "      <td>0.802643</td>\n",
       "      <td>-0.442365</td>\n",
       "      <td>1.376889</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.099392</td>\n",
       "      <td>0.398954</td>\n",
       "      <td>1.376889</td>\n",
       "      <td>-0.512653</td>\n",
       "      <td>1.328550</td>\n",
       "      <td>1.036780</td>\n",
       "      <td>-0.645796</td>\n",
       "      <td>-0.702839</td>\n",
       "      <td>0.082562</td>\n",
       "      <td>-0.598026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.902393</td>\n",
       "      <td>-0.947360</td>\n",
       "      <td>-0.590021</td>\n",
       "      <td>-0.048845</td>\n",
       "      <td>-1.586009</td>\n",
       "      <td>-0.950226</td>\n",
       "      <td>0.075735</td>\n",
       "      <td>0.024965</td>\n",
       "      <td>-0.439026</td>\n",
       "      <td>-0.330009</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.984978</td>\n",
       "      <td>0.398954</td>\n",
       "      <td>-0.330009</td>\n",
       "      <td>-0.274970</td>\n",
       "      <td>-0.286628</td>\n",
       "      <td>-0.026899</td>\n",
       "      <td>-0.279463</td>\n",
       "      <td>-0.216691</td>\n",
       "      <td>-0.205914</td>\n",
       "      <td>-0.068645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.902393</td>\n",
       "      <td>-0.879959</td>\n",
       "      <td>-0.729472</td>\n",
       "      <td>0.001313</td>\n",
       "      <td>-1.554588</td>\n",
       "      <td>-0.921349</td>\n",
       "      <td>0.171294</td>\n",
       "      <td>0.100256</td>\n",
       "      <td>-0.534714</td>\n",
       "      <td>-0.357824</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.886046</td>\n",
       "      <td>0.498849</td>\n",
       "      <td>-0.357824</td>\n",
       "      <td>-0.318019</td>\n",
       "      <td>-0.314871</td>\n",
       "      <td>-0.011229</td>\n",
       "      <td>-0.343447</td>\n",
       "      <td>-0.271563</td>\n",
       "      <td>-0.256781</td>\n",
       "      <td>-0.076582</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Air temperature [K]  Process temperature [K]  Rotational speed [rpm]  \\\n",
       "0            -0.952389                -0.947360                0.068185   \n",
       "1            -0.902393                -0.879959               -0.729472   \n",
       "2            -0.952389                -1.014761               -0.227450   \n",
       "3            -0.902393                -0.947360               -0.590021   \n",
       "4            -0.902393                -0.879959               -0.729472   \n",
       "\n",
       "   Torque [Nm]  Tool wear [min]      Temp      Poor     Poor2   In_Temp  \\\n",
       "0     0.282200        -1.695984 -0.980109  0.079191  0.169599 -0.538083   \n",
       "1     0.633308        -1.648852 -0.921349  0.677574  0.660881 -0.534714   \n",
       "2     0.944290        -1.617430 -1.008976  0.688185  0.802643 -0.442365   \n",
       "3    -0.048845        -1.586009 -0.950226  0.075735  0.024965 -0.439026   \n",
       "4     0.001313        -1.554588 -0.921349  0.171294  0.100256 -0.534714   \n",
       "\n",
       "    In_Poor  ...   Too_Sqr  Diff_Tepm  Ro_Tor_Mul  Ro_Tor_Div  Ro_Tor_Mul_Sqr  \\\n",
       "0  0.629443  ... -2.723864   0.498849    0.629443   -0.276573        0.647619   \n",
       "1  0.512456  ... -2.240150   0.498849    0.512456   -0.509201        0.537571   \n",
       "2  1.376889  ... -2.099392   0.398954    1.376889   -0.512653        1.328550   \n",
       "3 -0.330009  ... -1.984978   0.398954   -0.330009   -0.274970       -0.286628   \n",
       "4 -0.357824  ... -1.886046   0.498849   -0.357824   -0.318019       -0.314871   \n",
       "\n",
       "   Ro_Tor_Mul_Log  Ro_Tor_Div_Sqr  Ro_Tor_Div_Log  Ro_Tem_Mul  Tor_Tem_Div  \n",
       "0        0.493815       -0.281829       -0.317551    0.383968    -0.248875  \n",
       "1        0.615954       -0.640230       -0.628831   -0.256781    -0.434936  \n",
       "2        1.036780       -0.645796       -0.702839    0.082562    -0.598026  \n",
       "3       -0.026899       -0.279463       -0.216691   -0.205914    -0.068645  \n",
       "4       -0.011229       -0.343447       -0.271563   -0.256781    -0.076582  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_std_df =  pd.DataFrame(x_std, columns  = x_col )\n",
    "#x_all = pd.concat( [x_std_df,pd.DataFrame(x['Type'],columns  =  ['Type'])],axis = 1)\n",
    "x_std_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "40235e1e-b20e-4350-af6e-fa25bcf45d20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 30)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_std_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6a1ebd-9f0a-465c-9532-760c7827632e",
   "metadata": {},
   "source": [
    "## Feature Importance Runing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "1b16a809-a9aa-4841-9377-3c7c048363c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature_importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Ro_Tem_Mul</th>\n",
       "      <td>0.159812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>In_Poor</th>\n",
       "      <td>0.111869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ro_Tor_Mul_Sqr</th>\n",
       "      <td>0.093711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ro_Tor_Mul</th>\n",
       "      <td>0.077914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tor_Tem_Div</th>\n",
       "      <td>0.076890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>In_Temp</th>\n",
       "      <td>0.048268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rotational speed [rpm]</th>\n",
       "      <td>0.041991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rot_Sq</th>\n",
       "      <td>0.040103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Too_Sqr</th>\n",
       "      <td>0.038278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Too_Sq</th>\n",
       "      <td>0.036749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tool wear [min]</th>\n",
       "      <td>0.036523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rot_Sqr</th>\n",
       "      <td>0.034989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>In_Poor2</th>\n",
       "      <td>0.033941</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Feature_importance\n",
       "Ro_Tem_Mul                        0.159812\n",
       "In_Poor                           0.111869\n",
       "Ro_Tor_Mul_Sqr                    0.093711\n",
       "Ro_Tor_Mul                        0.077914\n",
       "Tor_Tem_Div                       0.076890\n",
       "In_Temp                           0.048268\n",
       "Rotational speed [rpm]            0.041991\n",
       "Rot_Sq                            0.040103\n",
       "Too_Sqr                           0.038278\n",
       "Too_Sq                            0.036749\n",
       "Tool wear [min]                   0.036523\n",
       "Rot_Sqr                           0.034989\n",
       "In_Poor2                          0.033941"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y =  df_c['Machine failure']\n",
    "feature= f_importance(x_std_df,y)\n",
    "feature = feature[feature['Feature_importance'] > 0.03]\n",
    "#selector = SelectFromModel(feature)\n",
    "feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15196ac-c249-412a-923c-a8f1b5652399",
   "metadata": {},
   "source": [
    "## Feature Result After Feature Importance Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "101ac40a-7859-4348-a0f2-bbae6eaa3e2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ro_Tem_Mul',\n",
       " 'In_Poor',\n",
       " 'Ro_Tor_Mul_Sqr',\n",
       " 'Ro_Tor_Mul',\n",
       " 'Tor_Tem_Div',\n",
       " 'In_Temp',\n",
       " 'Rotational speed [rpm]',\n",
       " 'Rot_Sq',\n",
       " 'Too_Sqr',\n",
       " 'Too_Sq',\n",
       " 'Tool wear [min]',\n",
       " 'Rot_Sqr',\n",
       " 'In_Poor2']"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## columns \n",
    "list(feature.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "8947f534-e590-4f70-a7df-c0b228d1f6a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 13)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx = x[list(feature.index)]\n",
    "xx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5ef4a8b4-6270-469d-b8a7-4ddc15776fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list1 = [\"a\", \"b\", \"c\"]\n",
    "# list2 = [1, 2]\n",
    "# all_combinations = []\n",
    "\n",
    "# # list1_permutations = itertools.permutations(list1, len(list2))\n",
    "\n",
    "# for u in list1 :\n",
    "#     for i in  list2 :\n",
    "#         all_combinations.append((u,i))\n",
    "# print(all_combinations)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "4e633c1e-09fb-4913-a2d9-a85544fe98d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f4d189-d164-4d5e-8709-b87d92eaceea",
   "metadata": {},
   "source": [
    "## Data Train Test Split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "1eefa9ad-33c0-471e-bb88-6a922512640d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "x_train_s, x_test_s, y_train_s, y_test_s = split_data(xx,y,0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "41b90bc2-af6d-4c9b-8717-5d169a7bdd28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize \n",
    "x_train_s = standardized(x_train_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "74808b88-bf7b-4d1f-a88b-ff127ba83ee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8000, 13)\n",
      "(8000,)\n"
     ]
    }
   ],
   "source": [
    "# before\n",
    "print(x_train_s.shape)\n",
    "print(y_train_s.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "521751c6-f165-4ced-b21f-423892b764b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['UDI', 'Product ID', 'Type', 'Air temperature [K]',\n",
       "       'Process temperature [K]', 'Rotational speed [rpm]', 'Torque [Nm]',\n",
       "       'Tool wear [min]', 'Machine failure', 'TWF', 'HDF', 'PWF', 'OSF', 'RNF',\n",
       "       'Temp', 'Poor', 'Poor2', 'In_Temp', 'In_Poor', 'In_Poor2', 'Air_Sq',\n",
       "       'Pro_Sq', 'Rot_Sq', 'Tor_Sq', 'Too_Sq', 'Air_Sqr', 'Pro_Sqr', 'Rot_Sqr',\n",
       "       'Tor_Sqr', 'Too_Sqr', 'Diff_Tepm', 'Ro_Tor_Mul', 'Ro_Tor_Div',\n",
       "       'Ro_Tor_Mul_Sqr', 'Ro_Tor_Mul_Log', 'Ro_Tor_Div_Sqr', 'Ro_Tor_Div_Log',\n",
       "       'Ro_Tem_Mul', 'Tor_Tem_Div'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4102650-887f-4712-93fd-ca924b148fae",
   "metadata": {},
   "source": [
    "## Model Running "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "55379365-1d14-4505-9e1c-b3ddeb4d2773",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Svm-under_sample\n",
      "---Done---\n",
      "Svm-over_sample\n",
      "---Done---\n",
      "Svm-SMOTE\n",
      "---Done---\n",
      "Svm-SMOTE_TOMEK\n",
      "---Done---\n",
      "Svm-None\n",
      "---Done---\n",
      "Logistic-under_sample\n",
      "---Done---\n",
      "Logistic-over_sample\n",
      "---Done---\n",
      "Logistic-SMOTE\n",
      "---Done---\n",
      "Logistic-SMOTE_TOMEK\n",
      "---Done---\n",
      "Logistic-None\n",
      "---Done---\n",
      "XGBoost-under_sample\n",
      "[0]\tvalidation_0-auc:0.50624\n",
      "[1]\tvalidation_0-auc:0.47115\n",
      "[2]\tvalidation_0-auc:0.47115\n",
      "[3]\tvalidation_0-auc:0.47115\n",
      "[4]\tvalidation_0-auc:0.47103\n",
      "[5]\tvalidation_0-auc:0.47103\n",
      "---Done---\n",
      "XGBoost-over_sample\n",
      "[0]\tvalidation_0-auc:0.50624\n",
      "[1]\tvalidation_0-auc:0.50624\n",
      "[2]\tvalidation_0-auc:0.50624\n",
      "[3]\tvalidation_0-auc:0.50624\n",
      "[4]\tvalidation_0-auc:0.50624\n",
      "[5]\tvalidation_0-auc:0.50624\n",
      "---Done---\n",
      "XGBoost-SMOTE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ThinkPad\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\ThinkPad\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\ThinkPad\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.50624\n",
      "[1]\tvalidation_0-auc:0.50260\n",
      "[2]\tvalidation_0-auc:0.50260\n",
      "[3]\tvalidation_0-auc:0.50260\n",
      "[4]\tvalidation_0-auc:0.50260\n",
      "[5]\tvalidation_0-auc:0.50260\n",
      "---Done---\n",
      "XGBoost-SMOTE_TOMEK\n",
      "[0]\tvalidation_0-auc:0.50624\n",
      "[1]\tvalidation_0-auc:0.50260\n",
      "[2]\tvalidation_0-auc:0.50260\n",
      "[3]\tvalidation_0-auc:0.50260\n",
      "[4]\tvalidation_0-auc:0.50260\n",
      "[5]\tvalidation_0-auc:0.50260\n",
      "---Done---\n",
      "XGBoost-None\n",
      "[0]\tvalidation_0-auc:0.50000\n",
      "[1]\tvalidation_0-auc:0.50000\n",
      "[2]\tvalidation_0-auc:0.50624\n",
      "[3]\tvalidation_0-auc:0.50624\n",
      "[4]\tvalidation_0-auc:0.50624\n",
      "[5]\tvalidation_0-auc:0.50624\n",
      "[6]\tvalidation_0-auc:0.50987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ThinkPad\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\ThinkPad\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7]\tvalidation_0-auc:0.50987\n",
      "[8]\tvalidation_0-auc:0.50987\n",
      "[9]\tvalidation_0-auc:0.50987\n",
      "[10]\tvalidation_0-auc:0.50987\n",
      "[11]\tvalidation_0-auc:0.50987\n",
      "---Done---\n",
      "Nb-under_sample\n",
      "---Done---\n",
      "Nb-over_sample\n",
      "---Done---\n",
      "Nb-SMOTE\n",
      "---Done---\n",
      "Nb-SMOTE_TOMEK\n",
      "---Done---\n",
      "Nb-None\n",
      "---Done---\n",
      "sgd-under_sample\n",
      "---Done---\n",
      "sgd-over_sample\n",
      "---Done---\n",
      "sgd-SMOTE\n",
      "---Done---\n",
      "sgd-SMOTE_TOMEK\n",
      "---Done---\n",
      "sgd-None\n",
      "---Done---\n",
      "Random_f-under_sample\n",
      "---Done---\n",
      "Random_f-over_sample\n",
      "---Done---\n",
      "Random_f-SMOTE\n",
      "---Done---\n",
      "Random_f-SMOTE_TOMEK\n",
      "---Done---\n",
      "Random_f-None\n",
      "---Done---\n",
      "Knn-under_sample\n",
      "---Done---\n",
      "Knn-over_sample\n",
      "---Done---\n",
      "Knn-SMOTE\n",
      "---Done---\n",
      "Knn-SMOTE_TOMEK\n",
      "---Done---\n",
      "Knn-None\n",
      "---Done---\n",
      "Decision_t-under_sample\n",
      "--Fail--\n",
      "Decision_t-over_sample\n",
      "--Fail--\n",
      "Decision_t-SMOTE\n",
      "--Fail--\n",
      "Decision_t-SMOTE_TOMEK\n",
      "--Fail--\n",
      "Decision_t-None\n",
      "--Fail--\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import metrics\n",
    "df_result = pd.DataFrame(columns = ['Model_N','Imbalance','accuracy','auc','tp','tn','fn','fp'])\n",
    "counter = 0 \n",
    "for i in range(len(model)) :\n",
    "    for j in range(len(imbalance_list)) :\n",
    "        df_result.loc[counter,'Model_N'] = model[i] \n",
    "        df_result.loc[counter,'Imbalance'] = imbalance_list[j] \n",
    "        counter += 1          \n",
    "for i,j in df_result.iterrows():\n",
    "    #print(j)\n",
    "    try:\n",
    "        print(f\"{j['Model_N']}-{j['Imbalance']}\")\n",
    "        x_b,y_b = imbalance( x_train_s , y_train_s ,j['Imbalance'] )  #x,y = imbalance( x_train , y_train , 'over_sample')\n",
    "        x_train_after  =  x_b\n",
    "        y_train_after = y_b\n",
    "        x_test_after = x_test_s\n",
    "        y_test_after = y_test_s\n",
    "        predict = fn_model(j['Model_N'],x_train_after,y_train_after,x_test_after,y_test_after) \n",
    "        auc = metrics.roc_auc_score(y_test_after, predict[1][:,1])\n",
    "        tn, fp, fn, tp  = confusion_matrix(y_test_after, predict[0]).ravel()\n",
    "        accuracy = accuracy_score(y_test_after, predict[0])\n",
    "        df_result.loc[i,'accuracy'] = accuracy\n",
    "        df_result.loc[i,'auc'] = auc\n",
    "        df_result.loc[i, 'tp'] = tp \n",
    "        df_result.loc[i, 'tn'] = tn\n",
    "        df_result.loc[i, 'fn'] = fn\n",
    "        df_result.loc[i, 'fp'] = fp\n",
    "        print('---Done---')\n",
    "    except :\n",
    "        print('--Fail--')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e632d2-7a5b-4ebd-8260-fcbd58916dfd",
   "metadata": {},
   "source": [
    "## Find Measurement Precision and Recall  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "0e6f6ac2-ded9-42a7-b2b3-45d468b3aa33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model_N</th>\n",
       "      <th>Imbalance</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>auc</th>\n",
       "      <th>tp</th>\n",
       "      <th>tn</th>\n",
       "      <th>fn</th>\n",
       "      <th>fp</th>\n",
       "      <th>pecision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Svm</td>\n",
       "      <td>under_sample</td>\n",
       "      <td>0.895</td>\n",
       "      <td>0.934587</td>\n",
       "      <td>63</td>\n",
       "      <td>1727</td>\n",
       "      <td>13</td>\n",
       "      <td>197</td>\n",
       "      <td>0.242308</td>\n",
       "      <td>0.828947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Svm</td>\n",
       "      <td>over_sample</td>\n",
       "      <td>0.874</td>\n",
       "      <td>0.940564</td>\n",
       "      <td>65</td>\n",
       "      <td>1683</td>\n",
       "      <td>11</td>\n",
       "      <td>241</td>\n",
       "      <td>0.212418</td>\n",
       "      <td>0.855263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Svm</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>0.873</td>\n",
       "      <td>0.935195</td>\n",
       "      <td>65</td>\n",
       "      <td>1681</td>\n",
       "      <td>11</td>\n",
       "      <td>243</td>\n",
       "      <td>0.211039</td>\n",
       "      <td>0.855263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Svm</td>\n",
       "      <td>SMOTE_TOMEK</td>\n",
       "      <td>0.874</td>\n",
       "      <td>0.935312</td>\n",
       "      <td>65</td>\n",
       "      <td>1683</td>\n",
       "      <td>11</td>\n",
       "      <td>241</td>\n",
       "      <td>0.212418</td>\n",
       "      <td>0.855263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Svm</td>\n",
       "      <td>None</td>\n",
       "      <td>0.962</td>\n",
       "      <td>0.932248</td>\n",
       "      <td>0</td>\n",
       "      <td>1924</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Logistic</td>\n",
       "      <td>under_sample</td>\n",
       "      <td>0.8895</td>\n",
       "      <td>0.936802</td>\n",
       "      <td>61</td>\n",
       "      <td>1718</td>\n",
       "      <td>15</td>\n",
       "      <td>206</td>\n",
       "      <td>0.228464</td>\n",
       "      <td>0.802632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Logistic</td>\n",
       "      <td>over_sample</td>\n",
       "      <td>0.8815</td>\n",
       "      <td>0.939948</td>\n",
       "      <td>63</td>\n",
       "      <td>1700</td>\n",
       "      <td>13</td>\n",
       "      <td>224</td>\n",
       "      <td>0.219512</td>\n",
       "      <td>0.828947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Logistic</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>0.884</td>\n",
       "      <td>0.938663</td>\n",
       "      <td>63</td>\n",
       "      <td>1705</td>\n",
       "      <td>13</td>\n",
       "      <td>219</td>\n",
       "      <td>0.223404</td>\n",
       "      <td>0.828947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Logistic</td>\n",
       "      <td>SMOTE_TOMEK</td>\n",
       "      <td>0.885</td>\n",
       "      <td>0.938663</td>\n",
       "      <td>63</td>\n",
       "      <td>1707</td>\n",
       "      <td>13</td>\n",
       "      <td>217</td>\n",
       "      <td>0.225</td>\n",
       "      <td>0.828947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Logistic</td>\n",
       "      <td>None</td>\n",
       "      <td>0.8825</td>\n",
       "      <td>0.938033</td>\n",
       "      <td>63</td>\n",
       "      <td>1702</td>\n",
       "      <td>13</td>\n",
       "      <td>222</td>\n",
       "      <td>0.221053</td>\n",
       "      <td>0.828947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>under_sample</td>\n",
       "      <td>0.845</td>\n",
       "      <td>0.911837</td>\n",
       "      <td>64</td>\n",
       "      <td>1626</td>\n",
       "      <td>12</td>\n",
       "      <td>298</td>\n",
       "      <td>0.176796</td>\n",
       "      <td>0.842105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>over_sample</td>\n",
       "      <td>0.9605</td>\n",
       "      <td>0.952867</td>\n",
       "      <td>63</td>\n",
       "      <td>1858</td>\n",
       "      <td>13</td>\n",
       "      <td>66</td>\n",
       "      <td>0.488372</td>\n",
       "      <td>0.828947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.955968</td>\n",
       "      <td>70</td>\n",
       "      <td>1830</td>\n",
       "      <td>6</td>\n",
       "      <td>94</td>\n",
       "      <td>0.426829</td>\n",
       "      <td>0.921053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>SMOTE_TOMEK</td>\n",
       "      <td>0.9505</td>\n",
       "      <td>0.955199</td>\n",
       "      <td>70</td>\n",
       "      <td>1831</td>\n",
       "      <td>6</td>\n",
       "      <td>93</td>\n",
       "      <td>0.429448</td>\n",
       "      <td>0.921053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>None</td>\n",
       "      <td>0.981</td>\n",
       "      <td>0.974908</td>\n",
       "      <td>50</td>\n",
       "      <td>1912</td>\n",
       "      <td>26</td>\n",
       "      <td>12</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.657895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Nb</td>\n",
       "      <td>under_sample</td>\n",
       "      <td>0.8705</td>\n",
       "      <td>0.881155</td>\n",
       "      <td>51</td>\n",
       "      <td>1690</td>\n",
       "      <td>25</td>\n",
       "      <td>234</td>\n",
       "      <td>0.178947</td>\n",
       "      <td>0.671053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Nb</td>\n",
       "      <td>over_sample</td>\n",
       "      <td>0.8875</td>\n",
       "      <td>0.889731</td>\n",
       "      <td>51</td>\n",
       "      <td>1724</td>\n",
       "      <td>25</td>\n",
       "      <td>200</td>\n",
       "      <td>0.203187</td>\n",
       "      <td>0.671053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Nb</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>0.878</td>\n",
       "      <td>0.891865</td>\n",
       "      <td>51</td>\n",
       "      <td>1705</td>\n",
       "      <td>25</td>\n",
       "      <td>219</td>\n",
       "      <td>0.188889</td>\n",
       "      <td>0.671053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Nb</td>\n",
       "      <td>SMOTE_TOMEK</td>\n",
       "      <td>0.8775</td>\n",
       "      <td>0.891769</td>\n",
       "      <td>51</td>\n",
       "      <td>1704</td>\n",
       "      <td>25</td>\n",
       "      <td>220</td>\n",
       "      <td>0.188192</td>\n",
       "      <td>0.671053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Nb</td>\n",
       "      <td>None</td>\n",
       "      <td>0.9205</td>\n",
       "      <td>0.892138</td>\n",
       "      <td>36</td>\n",
       "      <td>1805</td>\n",
       "      <td>40</td>\n",
       "      <td>119</td>\n",
       "      <td>0.232258</td>\n",
       "      <td>0.473684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>sgd</td>\n",
       "      <td>under_sample</td>\n",
       "      <td>0.8435</td>\n",
       "      <td>0.835649</td>\n",
       "      <td>61</td>\n",
       "      <td>1626</td>\n",
       "      <td>15</td>\n",
       "      <td>298</td>\n",
       "      <td>0.169916</td>\n",
       "      <td>0.802632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>sgd</td>\n",
       "      <td>over_sample</td>\n",
       "      <td>0.892</td>\n",
       "      <td>0.936543</td>\n",
       "      <td>63</td>\n",
       "      <td>1721</td>\n",
       "      <td>13</td>\n",
       "      <td>203</td>\n",
       "      <td>0.236842</td>\n",
       "      <td>0.828947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>sgd</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>0.8685</td>\n",
       "      <td>0.936843</td>\n",
       "      <td>66</td>\n",
       "      <td>1671</td>\n",
       "      <td>10</td>\n",
       "      <td>253</td>\n",
       "      <td>0.206897</td>\n",
       "      <td>0.868421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>sgd</td>\n",
       "      <td>SMOTE_TOMEK</td>\n",
       "      <td>0.9025</td>\n",
       "      <td>0.934323</td>\n",
       "      <td>61</td>\n",
       "      <td>1744</td>\n",
       "      <td>15</td>\n",
       "      <td>180</td>\n",
       "      <td>0.253112</td>\n",
       "      <td>0.802632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>sgd</td>\n",
       "      <td>None</td>\n",
       "      <td>0.964</td>\n",
       "      <td>0.794148</td>\n",
       "      <td>8</td>\n",
       "      <td>1920</td>\n",
       "      <td>68</td>\n",
       "      <td>4</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.105263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Random_f</td>\n",
       "      <td>under_sample</td>\n",
       "      <td>0.8985</td>\n",
       "      <td>0.963771</td>\n",
       "      <td>69</td>\n",
       "      <td>1728</td>\n",
       "      <td>7</td>\n",
       "      <td>196</td>\n",
       "      <td>0.260377</td>\n",
       "      <td>0.907895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Random_f</td>\n",
       "      <td>over_sample</td>\n",
       "      <td>0.983</td>\n",
       "      <td>0.962862</td>\n",
       "      <td>57</td>\n",
       "      <td>1909</td>\n",
       "      <td>19</td>\n",
       "      <td>15</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Random_f</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>0.9655</td>\n",
       "      <td>0.976167</td>\n",
       "      <td>63</td>\n",
       "      <td>1868</td>\n",
       "      <td>13</td>\n",
       "      <td>56</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.828947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Random_f</td>\n",
       "      <td>SMOTE_TOMEK</td>\n",
       "      <td>0.9645</td>\n",
       "      <td>0.969653</td>\n",
       "      <td>64</td>\n",
       "      <td>1865</td>\n",
       "      <td>12</td>\n",
       "      <td>59</td>\n",
       "      <td>0.520325</td>\n",
       "      <td>0.842105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Random_f</td>\n",
       "      <td>None</td>\n",
       "      <td>0.984</td>\n",
       "      <td>0.973339</td>\n",
       "      <td>56</td>\n",
       "      <td>1912</td>\n",
       "      <td>20</td>\n",
       "      <td>12</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.736842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Knn</td>\n",
       "      <td>under_sample</td>\n",
       "      <td>0.885</td>\n",
       "      <td>0.939935</td>\n",
       "      <td>67</td>\n",
       "      <td>1703</td>\n",
       "      <td>9</td>\n",
       "      <td>221</td>\n",
       "      <td>0.232639</td>\n",
       "      <td>0.881579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Knn</td>\n",
       "      <td>over_sample</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.840423</td>\n",
       "      <td>46</td>\n",
       "      <td>1874</td>\n",
       "      <td>30</td>\n",
       "      <td>50</td>\n",
       "      <td>0.479167</td>\n",
       "      <td>0.605263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Knn</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>0.9385</td>\n",
       "      <td>0.868209</td>\n",
       "      <td>54</td>\n",
       "      <td>1823</td>\n",
       "      <td>22</td>\n",
       "      <td>101</td>\n",
       "      <td>0.348387</td>\n",
       "      <td>0.710526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Knn</td>\n",
       "      <td>SMOTE_TOMEK</td>\n",
       "      <td>0.939</td>\n",
       "      <td>0.868749</td>\n",
       "      <td>54</td>\n",
       "      <td>1824</td>\n",
       "      <td>22</td>\n",
       "      <td>100</td>\n",
       "      <td>0.350649</td>\n",
       "      <td>0.710526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Knn</td>\n",
       "      <td>None</td>\n",
       "      <td>0.974</td>\n",
       "      <td>0.844642</td>\n",
       "      <td>39</td>\n",
       "      <td>1909</td>\n",
       "      <td>37</td>\n",
       "      <td>15</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.513158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Decision_t</td>\n",
       "      <td>under_sample</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Decision_t</td>\n",
       "      <td>over_sample</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Decision_t</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Decision_t</td>\n",
       "      <td>SMOTE_TOMEK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Decision_t</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Model_N     Imbalance accuracy       auc   tp    tn   fn   fp  \\\n",
       "0          Svm  under_sample    0.895  0.934587   63  1727   13  197   \n",
       "1          Svm   over_sample    0.874  0.940564   65  1683   11  241   \n",
       "2          Svm         SMOTE    0.873  0.935195   65  1681   11  243   \n",
       "3          Svm   SMOTE_TOMEK    0.874  0.935312   65  1683   11  241   \n",
       "4          Svm          None    0.962  0.932248    0  1924   76    0   \n",
       "5     Logistic  under_sample   0.8895  0.936802   61  1718   15  206   \n",
       "6     Logistic   over_sample   0.8815  0.939948   63  1700   13  224   \n",
       "7     Logistic         SMOTE    0.884  0.938663   63  1705   13  219   \n",
       "8     Logistic   SMOTE_TOMEK    0.885  0.938663   63  1707   13  217   \n",
       "9     Logistic          None   0.8825  0.938033   63  1702   13  222   \n",
       "10     XGBoost  under_sample    0.845  0.911837   64  1626   12  298   \n",
       "11     XGBoost   over_sample   0.9605  0.952867   63  1858   13   66   \n",
       "12     XGBoost         SMOTE     0.95  0.955968   70  1830    6   94   \n",
       "13     XGBoost   SMOTE_TOMEK   0.9505  0.955199   70  1831    6   93   \n",
       "14     XGBoost          None    0.981  0.974908   50  1912   26   12   \n",
       "15          Nb  under_sample   0.8705  0.881155   51  1690   25  234   \n",
       "16          Nb   over_sample   0.8875  0.889731   51  1724   25  200   \n",
       "17          Nb         SMOTE    0.878  0.891865   51  1705   25  219   \n",
       "18          Nb   SMOTE_TOMEK   0.8775  0.891769   51  1704   25  220   \n",
       "19          Nb          None   0.9205  0.892138   36  1805   40  119   \n",
       "20         sgd  under_sample   0.8435  0.835649   61  1626   15  298   \n",
       "21         sgd   over_sample    0.892  0.936543   63  1721   13  203   \n",
       "22         sgd         SMOTE   0.8685  0.936843   66  1671   10  253   \n",
       "23         sgd   SMOTE_TOMEK   0.9025  0.934323   61  1744   15  180   \n",
       "24         sgd          None    0.964  0.794148    8  1920   68    4   \n",
       "25    Random_f  under_sample   0.8985  0.963771   69  1728    7  196   \n",
       "26    Random_f   over_sample    0.983  0.962862   57  1909   19   15   \n",
       "27    Random_f         SMOTE   0.9655  0.976167   63  1868   13   56   \n",
       "28    Random_f   SMOTE_TOMEK   0.9645  0.969653   64  1865   12   59   \n",
       "29    Random_f          None    0.984  0.973339   56  1912   20   12   \n",
       "30         Knn  under_sample    0.885  0.939935   67  1703    9  221   \n",
       "31         Knn   over_sample     0.96  0.840423   46  1874   30   50   \n",
       "32         Knn         SMOTE   0.9385  0.868209   54  1823   22  101   \n",
       "33         Knn   SMOTE_TOMEK    0.939  0.868749   54  1824   22  100   \n",
       "34         Knn          None    0.974  0.844642   39  1909   37   15   \n",
       "35  Decision_t  under_sample      NaN       NaN  NaN   NaN  NaN  NaN   \n",
       "36  Decision_t   over_sample      NaN       NaN  NaN   NaN  NaN  NaN   \n",
       "37  Decision_t         SMOTE      NaN       NaN  NaN   NaN  NaN  NaN   \n",
       "38  Decision_t   SMOTE_TOMEK      NaN       NaN  NaN   NaN  NaN  NaN   \n",
       "39  Decision_t          None      NaN       NaN  NaN   NaN  NaN  NaN   \n",
       "\n",
       "    pecision    recall  \n",
       "0   0.242308  0.828947  \n",
       "1   0.212418  0.855263  \n",
       "2   0.211039  0.855263  \n",
       "3   0.212418  0.855263  \n",
       "4        NaN       0.0  \n",
       "5   0.228464  0.802632  \n",
       "6   0.219512  0.828947  \n",
       "7   0.223404  0.828947  \n",
       "8      0.225  0.828947  \n",
       "9   0.221053  0.828947  \n",
       "10  0.176796  0.842105  \n",
       "11  0.488372  0.828947  \n",
       "12  0.426829  0.921053  \n",
       "13  0.429448  0.921053  \n",
       "14  0.806452  0.657895  \n",
       "15  0.178947  0.671053  \n",
       "16  0.203187  0.671053  \n",
       "17  0.188889  0.671053  \n",
       "18  0.188192  0.671053  \n",
       "19  0.232258  0.473684  \n",
       "20  0.169916  0.802632  \n",
       "21  0.236842  0.828947  \n",
       "22  0.206897  0.868421  \n",
       "23  0.253112  0.802632  \n",
       "24  0.666667  0.105263  \n",
       "25  0.260377  0.907895  \n",
       "26  0.791667      0.75  \n",
       "27  0.529412  0.828947  \n",
       "28  0.520325  0.842105  \n",
       "29  0.823529  0.736842  \n",
       "30  0.232639  0.881579  \n",
       "31  0.479167  0.605263  \n",
       "32  0.348387  0.710526  \n",
       "33  0.350649  0.710526  \n",
       "34  0.722222  0.513158  \n",
       "35       NaN       NaN  \n",
       "36       NaN       NaN  \n",
       "37       NaN       NaN  \n",
       "38       NaN       NaN  \n",
       "39       NaN       NaN  "
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result['pecision'] = df_result['tp'] / (df_result['tp'] + df_result['fp']) \n",
    "df_result['recall'] = df_result['tp'] / (df_result['tp']+df_result['fn'])\n",
    "df_result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2db6b0-712a-48c2-ba20-16eb8da5f53b",
   "metadata": {},
   "source": [
    "## Save Model Result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fb4b9a29-fc9c-402d-bde4-89b993b4b4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result.to_csv('model_performance_result.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f650d3-3fbc-4fbf-aba7-d49e6a3d5107",
   "metadata": {},
   "outputs": [],
   "source": [
    "report_test_dic = classification_report(tup_im[4], predicted_y_test,output_dict=True)\n",
    "\n",
    "  res_df = pd.DataFrame(report_test_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24eec880-3fd3-44d4-8c9c-9358182b9cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas \n",
    "import numpy \n",
    "\n",
    "df2 =  pd.read_csv('./model_performance_result.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3757a365-9eee-49ab-8bcc-e2f58057d580",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8000, 12) (8000,)\n",
      "(2000, 12) (2000,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train_s.shape, y_train_s.shape)\n",
    "print(x_test_s.shape, y_test_s.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8452d947-cbbd-409c-8a45-b714100f65df",
   "metadata": {},
   "source": [
    "## Deep Learning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f0b44313-4ff7-4caf-a089-89393464acf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## start with  deep learning \n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense \n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from tensorflow.keras.optimizers import SGD,Adagrad\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "    ### created model  ###\n",
    "def model_deep(optimizer='adam', len_featrure=list(x_train_s.shape)[1]):   \n",
    "    model = Sequential()  \n",
    "    model.add(Dense(128, kernel_initializer='uniform',activation='relu',input_dim= x_train_s.shape[1]))\n",
    "    #model.add(Dense(256,activation='relu'))\n",
    "    #model.add(Dense(128, kernel_initializer='uniform',activation='relu'))\n",
    "    #model.add(Dropout(0.2))\n",
    "    model.add(Dense(64, kernel_initializer='uniform',activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(32, kernel_initializer='uniform',activation='relu')) \n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, kernel_initializer='uniform',activation='sigmoid')) #sigmoid , tanh , \n",
    "    ### add complie###\n",
    "    #sgd = SGD(lr=0.1, momentum=0.9) #tf.keras.optimizers.Adagrad(0.1)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['AUC']) #sgd adam Adagrad\n",
    "    #model_fit = model.fit(x = x_train_s ,y = y_train_s, epochs = 200, batch_size=256)\n",
    "    return model \n",
    "#model_fit = model.fit(x = X_train ,y = y_train, epochs = 200, batch_size=256) #,validation_data=(x_test ,y_test)\n",
    "#y_pred = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f6cac3fa-ae26-40bc-94d1-31b9d20a723f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15474,)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_b.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a9a6fd-5c26-4d28-b4e5-66481f330cbc",
   "metadata": {},
   "source": [
    "## Grid Search Approch to find the best  parameter set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c1981d18-e9a9-4e6f-ae52-2873eae5b06e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ThinkPad\\AppData\\Local\\Temp/ipykernel_18232/3879024614.py:6: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead.\n",
      "  model22 = KerasRegressor(build_fn=model_deep)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "387/387 [==============================] - 1s 1ms/step - loss: 0.6778 - auc: 0.5040\n",
      "97/97 [==============================] - 0s 834us/step - loss: 0.8402 - auc: 0.7783\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.6776 - auc: 0.5070\n",
      "97/97 [==============================] - 0s 823us/step - loss: 0.8421 - auc: 0.5000\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.6929 - auc: 0.5006\n",
      "97/97 [==============================] - 0s 834us/step - loss: 0.6959 - auc: 0.5000\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.6757 - auc: 0.4974\n",
      "97/97 [==============================] - 0s 834us/step - loss: 0.8598 - auc: 0.0000e+00\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.6755 - auc: 0.5093\n",
      "97/97 [==============================] - 0s 813us/step - loss: 0.8638 - auc: 0.0000e+00\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.3511 - auc: 0.9214\n",
      "97/97 [==============================] - 0s 813us/step - loss: 0.3409 - auc: 0.9633\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.3486 - auc: 0.9207\n",
      "97/97 [==============================] - 0s 802us/step - loss: 0.3248 - auc: 0.9574\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.3531 - auc: 0.9251\n",
      "97/97 [==============================] - 0s 792us/step - loss: 0.3053 - auc: 0.9511\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.3518 - auc: 0.9209\n",
      "97/97 [==============================] - 0s 823us/step - loss: 0.2588 - auc: 0.0000e+00\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.3648 - auc: 0.9126\n",
      "97/97 [==============================] - 0s 813us/step - loss: 0.2882 - auc: 0.0000e+00\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.6911 - auc: 0.5110\n",
      "97/97 [==============================] - 0s 802us/step - loss: 0.7068 - auc: 0.5000\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.6911 - auc: 0.4961\n",
      "97/97 [==============================] - 0s 823us/step - loss: 0.7065 - auc: 0.5000\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.6932 - auc: 0.5000\n",
      "97/97 [==============================] - 0s 791us/step - loss: 0.6936 - auc: 0.5000\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.6908 - auc: 0.4918\n",
      "97/97 [==============================] - 0s 1ms/step - loss: 0.7088 - auc: 0.0000e+00\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.6909 - auc: 0.4854\n",
      "97/97 [==============================] - 0s 833us/step - loss: 0.7088 - auc: 0.0000e+00\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.6931 - auc: 0.5000\n",
      "97/97 [==============================] - 0s 907us/step - loss: 0.6935 - auc: 0.5000\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.6932 - auc: 0.5000\n",
      "97/97 [==============================] - 0s 917us/step - loss: 0.6934 - auc: 0.5000\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.6931 - auc: 0.5000\n",
      "97/97 [==============================] - 0s 802us/step - loss: 0.6931 - auc: 0.5000\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.6931 - auc: 0.5000\n",
      "97/97 [==============================] - 0s 865us/step - loss: 0.6932 - auc: 0.0000e+00\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.6931 - auc: 0.5000\n",
      "97/97 [==============================] - 0s 823us/step - loss: 0.6935 - auc: 0.0000e+00\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.3568 - auc: 0.9151\n",
      "97/97 [==============================] - 0s 844us/step - loss: 0.3943 - auc: 0.9633\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.3562 - auc: 0.9170\n",
      "97/97 [==============================] - 0s 823us/step - loss: 0.3199 - auc: 0.9625\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.3650 - auc: 0.9206\n",
      "97/97 [==============================] - 0s 834us/step - loss: 0.2835 - auc: 0.9560\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.3609 - auc: 0.9175\n",
      "97/97 [==============================] - 0s 865us/step - loss: 0.2417 - auc: 0.0000e+00\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.3628 - auc: 0.9141\n",
      "97/97 [==============================] - 1s 906us/step - loss: 0.2962 - auc: 0.0000e+00\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.4798 - auc: 0.8466\n",
      "97/97 [==============================] - 0s 906us/step - loss: 0.4862 - auc: 0.9491\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.4742 - auc: 0.8594\n",
      "97/97 [==============================] - 0s 875us/step - loss: 0.4443 - auc: 0.9309\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.4763 - auc: 0.8753\n",
      "97/97 [==============================] - 0s 906us/step - loss: 0.3476 - auc: 0.9311\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.4731 - auc: 0.8654\n",
      "97/97 [==============================] - 0s 844us/step - loss: 0.3413 - auc: 0.0000e+00\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.4699 - auc: 0.8662\n",
      "97/97 [==============================] - 0s 813us/step - loss: 0.3651 - auc: 0.0000e+00\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.3332 - auc: 0.9269\n",
      "97/97 [==============================] - 0s 823us/step - loss: 0.2725 - auc: 0.9657\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.3414 - auc: 0.9218\n",
      "97/97 [==============================] - 0s 844us/step - loss: 0.3330 - auc: 0.9640\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.3474 - auc: 0.9273\n",
      "97/97 [==============================] - 0s 792us/step - loss: 0.2774 - auc: 0.9581\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.3482 - auc: 0.9214\n",
      "97/97 [==============================] - 0s 792us/step - loss: 0.2679 - auc: 0.0000e+00\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.3412 - auc: 0.9254\n",
      "97/97 [==============================] - 0s 823us/step - loss: 0.2996 - auc: 0.0000e+00\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.6780 - auc: 0.5001\n",
      "97/97 [==============================] - 0s 792us/step - loss: 0.8384 - auc: 0.5000\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.6778 - auc: 0.4970\n",
      "97/97 [==============================] - 0s 844us/step - loss: 0.8392 - auc: 0.5000\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.6928 - auc: 0.5018\n",
      "97/97 [==============================] - 0s 811us/step - loss: 0.6961 - auc: 0.5000\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.6758 - auc: 0.4911\n",
      "97/97 [==============================] - 0s 865us/step - loss: 0.8587 - auc: 0.0000e+00\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.6755 - auc: 0.5040\n",
      "97/97 [==============================] - 0s 833us/step - loss: 0.8633 - auc: 0.0000e+00\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.3411 - auc: 0.9244\n",
      "97/97 [==============================] - 0s 886us/step - loss: 0.4095 - auc: 0.9603\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.3494 - auc: 0.9239\n",
      "97/97 [==============================] - 0s 792us/step - loss: 0.3498 - auc: 0.9656\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.3512 - auc: 0.9269\n",
      "97/97 [==============================] - 0s 927us/step - loss: 0.2977 - auc: 0.9493\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.3465 - auc: 0.9222\n",
      "97/97 [==============================] - 0s 792us/step - loss: 0.3225 - auc: 0.0000e+00\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.3546 - auc: 0.9184\n",
      "97/97 [==============================] - 0s 823us/step - loss: 0.4295 - auc: 0.0000e+00\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.6910 - auc: 0.5013\n",
      "97/97 [==============================] - 0s 865us/step - loss: 0.7070 - auc: 0.4985\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.6910 - auc: 0.4983\n",
      "97/97 [==============================] - 0s 823us/step - loss: 0.7069 - auc: 0.5027\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.6930 - auc: 0.5000\n",
      "97/97 [==============================] - 0s 995us/step - loss: 0.6935 - auc: 0.5000\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.6910 - auc: 0.4981\n",
      "97/97 [==============================] - 0s 917us/step - loss: 0.7076 - auc: 0.0000e+00\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.6909 - auc: 0.4971\n",
      "97/97 [==============================] - 0s 813us/step - loss: 0.7082 - auc: 0.0000e+00\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.6933 - auc: 0.5000\n",
      "97/97 [==============================] - 0s 844us/step - loss: 0.6932 - auc: 0.5000\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.6931 - auc: 0.5000\n",
      "97/97 [==============================] - 0s 813us/step - loss: 0.6935 - auc: 0.5000\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.6932 - auc: 0.5000\n",
      "97/97 [==============================] - 0s 854us/step - loss: 0.6932 - auc: 0.5000\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.6931 - auc: 0.5000\n",
      "97/97 [==============================] - 0s 854us/step - loss: 0.6933 - auc: 0.0000e+00\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.6931 - auc: 0.5000\n",
      "97/97 [==============================] - 0s 813us/step - loss: 0.6934 - auc: 0.0000e+00\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.3465 - auc: 0.9204\n",
      "97/97 [==============================] - 0s 802us/step - loss: 0.3936 - auc: 0.9645\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.3543 - auc: 0.9173\n",
      "97/97 [==============================] - 0s 896us/step - loss: 0.4308 - auc: 0.9660\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.3605 - auc: 0.9228\n",
      "97/97 [==============================] - 0s 834us/step - loss: 0.2577 - auc: 0.9580\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.3598 - auc: 0.9168\n",
      "97/97 [==============================] - 0s 792us/step - loss: 0.3595 - auc: 0.0000e+00\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.3730 - auc: 0.9083\n",
      "97/97 [==============================] - 0s 802us/step - loss: 0.4010 - auc: 0.0000e+00\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.4727 - auc: 0.8657\n",
      "97/97 [==============================] - 0s 781us/step - loss: 0.5147 - auc: 0.9528\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.4784 - auc: 0.8617\n",
      "97/97 [==============================] - 0s 812us/step - loss: 0.4999 - auc: 0.9323\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.4807 - auc: 0.8740\n",
      "97/97 [==============================] - 0s 896us/step - loss: 0.3411 - auc: 0.9336\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.4755 - auc: 0.8549\n",
      "97/97 [==============================] - 0s 802us/step - loss: 0.4209 - auc: 0.0000e+00\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.4705 - auc: 0.8588\n",
      "97/97 [==============================] - 0s 860us/step - loss: 0.4115 - auc: 0.0000e+00\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.3374 - auc: 0.9234\n",
      "97/97 [==============================] - 0s 854us/step - loss: 0.3180 - auc: 0.9640\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.3355 - auc: 0.9262\n",
      "97/97 [==============================] - 0s 854us/step - loss: 0.2686 - auc: 0.9636\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.3412 - auc: 0.9308\n",
      "97/97 [==============================] - 0s 865us/step - loss: 0.2781 - auc: 0.9594\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.3447 - auc: 0.9243\n",
      "97/97 [==============================] - 0s 875us/step - loss: 0.2897 - auc: 0.0000e+00\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.3374 - auc: 0.9264\n",
      "97/97 [==============================] - 0s 854us/step - loss: 0.3638 - auc: 0.0000e+00\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.6781 - auc: 0.4977\n",
      "97/97 [==============================] - 0s 854us/step - loss: 0.8382 - auc: 0.5000\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.6778 - auc: 0.4959\n",
      "97/97 [==============================] - 0s 854us/step - loss: 0.8399 - auc: 0.5000\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.6928 - auc: 0.5011\n",
      "97/97 [==============================] - 0s 823us/step - loss: 0.6962 - auc: 0.5000\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.6758 - auc: 0.4903\n",
      "97/97 [==============================] - 0s 813us/step - loss: 0.8580 - auc: 0.0000e+00\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.6759 - auc: 0.4871\n",
      "97/97 [==============================] - 0s 865us/step - loss: 0.8568 - auc: 0.0000e+00\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.3417 - auc: 0.9252\n",
      "97/97 [==============================] - 0s 850us/step - loss: 0.3229 - auc: 0.9647\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.3465 - auc: 0.9238\n",
      "97/97 [==============================] - 0s 864us/step - loss: 0.3199 - auc: 0.9587\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.3615 - auc: 0.9242\n",
      "97/97 [==============================] - 0s 854us/step - loss: 0.3015 - auc: 0.9574\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.3484 - auc: 0.9216\n",
      "97/97 [==============================] - 0s 812us/step - loss: 0.3110 - auc: 0.0000e+00\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.3564 - auc: 0.9180\n",
      "97/97 [==============================] - 0s 854us/step - loss: 0.3564 - auc: 0.0000e+00\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.6910 - auc: 0.5021\n",
      "97/97 [==============================] - 0s 813us/step - loss: 0.7071 - auc: 0.5751\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.6910 - auc: 0.5067\n",
      "97/97 [==============================] - 0s 833us/step - loss: 0.7072 - auc: 0.4924\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.6931 - auc: 0.5000\n",
      "97/97 [==============================] - 0s 802us/step - loss: 0.6935 - auc: 0.5000\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.6908 - auc: 0.4911\n",
      "97/97 [==============================] - 0s 813us/step - loss: 0.7083 - auc: 0.0000e+00\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.6908 - auc: 0.5020\n",
      "97/97 [==============================] - 0s 844us/step - loss: 0.7080 - auc: 0.0000e+00\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.6932 - auc: 0.5000\n",
      "97/97 [==============================] - 0s 833us/step - loss: 0.6933 - auc: 0.5000\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.6932 - auc: 0.5000\n",
      "97/97 [==============================] - 0s 781us/step - loss: 0.6934 - auc: 0.5000\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.6931 - auc: 0.5000\n",
      "97/97 [==============================] - 0s 854us/step - loss: 0.6931 - auc: 0.5000\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.6930 - auc: 0.5000\n",
      "97/97 [==============================] - 0s 823us/step - loss: 0.6938 - auc: 0.0000e+00\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.6931 - auc: 0.5000\n",
      "97/97 [==============================] - 0s 802us/step - loss: 0.6931 - auc: 0.0000e+00\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.3547 - auc: 0.9173\n",
      "97/97 [==============================] - 0s 833us/step - loss: 0.3816 - auc: 0.9663\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.3585 - auc: 0.9162\n",
      "97/97 [==============================] - 0s 823us/step - loss: 0.2277 - auc: 0.9628\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.3665 - auc: 0.9200\n",
      "97/97 [==============================] - 0s 833us/step - loss: 0.2833 - auc: 0.9561\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.3628 - auc: 0.9143\n",
      "97/97 [==============================] - 0s 822us/step - loss: 0.3004 - auc: 0.0000e+00\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.3657 - auc: 0.9119\n",
      "97/97 [==============================] - 0s 854us/step - loss: 0.3615 - auc: 0.0000e+00\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.4666 - auc: 0.8752\n",
      "97/97 [==============================] - 0s 823us/step - loss: 0.4834 - auc: 0.9530\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.4660 - auc: 0.8697\n",
      "97/97 [==============================] - 0s 865us/step - loss: 0.4585 - auc: 0.9365\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.4805 - auc: 0.8765\n",
      "97/97 [==============================] - 0s 844us/step - loss: 0.3472 - auc: 0.9310\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.4685 - auc: 0.8595\n",
      "97/97 [==============================] - 0s 813us/step - loss: 0.5302 - auc: 0.0000e+00\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.4872 - auc: 0.8449\n",
      "97/97 [==============================] - 0s 813us/step - loss: 0.4396 - auc: 0.0000e+00\n",
      "387/387 [==============================] - 2s 1ms/step - loss: 0.3310 - auc: 0.9276\n",
      "97/97 [==============================] - 0s 833us/step - loss: 0.3302 - auc: 0.9645\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.3303 - auc: 0.9275\n",
      "97/97 [==============================] - 0s 834us/step - loss: 0.2931 - auc: 0.9664\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.3310 - auc: 0.9342\n",
      "97/97 [==============================] - 0s 854us/step - loss: 0.2712 - auc: 0.9607\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.3528 - auc: 0.9195\n",
      "97/97 [==============================] - 0s 802us/step - loss: 0.2926 - auc: 0.0000e+00\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.3418 - auc: 0.9247\n",
      "97/97 [==============================] - 0s 851us/step - loss: 0.3023 - auc: 0.0000e+00\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.6780 - auc: 0.4973\n",
      "97/97 [==============================] - 0s 813us/step - loss: 0.8371 - auc: 0.5000\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.6780 - auc: 0.4944\n",
      "97/97 [==============================] - 0s 844us/step - loss: 0.8390 - auc: 0.5000\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.6929 - auc: 0.4897\n",
      "97/97 [==============================] - 0s 813us/step - loss: 0.6956 - auc: 0.5000\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.6757 - auc: 0.4986\n",
      "97/97 [==============================] - 0s 875us/step - loss: 0.8605 - auc: 0.0000e+00\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.6755 - auc: 0.5020\n",
      "97/97 [==============================] - 0s 864us/step - loss: 0.8621 - auc: 0.0000e+00\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.3542 - auc: 0.9241\n",
      "97/97 [==============================] - 0s 781us/step - loss: 0.2841 - auc: 0.9641\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.3436 - auc: 0.9225\n",
      "97/97 [==============================] - 0s 823us/step - loss: 0.2488 - auc: 0.9605\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.3549 - auc: 0.9244\n",
      "97/97 [==============================] - 1s 865us/step - loss: 0.2796 - auc: 0.9570\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.3694 - auc: 0.9113\n",
      "97/97 [==============================] - 0s 823us/step - loss: 0.7007 - auc: 0.0000e+00\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.3628 - auc: 0.9141\n",
      "97/97 [==============================] - 0s 823us/step - loss: 0.4131 - auc: 0.0000e+00\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.6910 - auc: 0.5096\n",
      "97/97 [==============================] - 0s 854us/step - loss: 0.7069 - auc: 0.4994\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.6911 - auc: 0.5019\n",
      "97/97 [==============================] - 0s 834us/step - loss: 0.7066 - auc: 0.5000\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.6931 - auc: 0.5002\n",
      "97/97 [==============================] - 0s 834us/step - loss: 0.6935 - auc: 0.5000\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.6909 - auc: 0.4966\n",
      "97/97 [==============================] - 0s 833us/step - loss: 0.7082 - auc: 0.0000e+00\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.6909 - auc: 0.4988\n",
      "97/97 [==============================] - 0s 834us/step - loss: 0.7079 - auc: 0.0000e+00\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.6931 - auc: 0.5000\n",
      "97/97 [==============================] - 0s 813us/step - loss: 0.6934 - auc: 0.5000\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.6931 - auc: 0.5000\n",
      "97/97 [==============================] - 0s 834us/step - loss: 0.6934 - auc: 0.5000\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.6932 - auc: 0.5000\n",
      "97/97 [==============================] - 0s 844us/step - loss: 0.6931 - auc: 0.5000\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.6931 - auc: 0.5000\n",
      "97/97 [==============================] - 0s 865us/step - loss: 0.6932 - auc: 0.0000e+00\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.6931 - auc: 0.5000\n",
      "97/97 [==============================] - 0s 823us/step - loss: 0.6935 - auc: 0.0000e+00\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.3544 - auc: 0.9161\n",
      "97/97 [==============================] - 0s 833us/step - loss: 0.3631 - auc: 0.9652\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.3675 - auc: 0.9156\n",
      "97/97 [==============================] - 0s 854us/step - loss: 0.3298 - auc: 0.9652\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.3574 - auc: 0.9245\n",
      "97/97 [==============================] - 0s 833us/step - loss: 0.2546 - auc: 0.9588\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.3633 - auc: 0.9163\n",
      "97/97 [==============================] - 0s 879us/step - loss: 0.2755 - auc: 0.0000e+00\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.3563 - auc: 0.9187\n",
      "97/97 [==============================] - 0s 834us/step - loss: 0.2594 - auc: 0.0000e+00\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.4677 - auc: 0.8759\n",
      "97/97 [==============================] - 0s 833us/step - loss: 0.5426 - auc: 0.9521\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.4631 - auc: 0.8608\n",
      "97/97 [==============================] - 0s 823us/step - loss: 0.4630 - auc: 0.9371\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.4791 - auc: 0.8765\n",
      "97/97 [==============================] - 0s 813us/step - loss: 0.3567 - auc: 0.9347\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.4791 - auc: 0.8531\n",
      "97/97 [==============================] - 0s 802us/step - loss: 0.4057 - auc: 0.0000e+00\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.4840 - auc: 0.8537\n",
      "97/97 [==============================] - 0s 813us/step - loss: 0.3555 - auc: 0.0000e+00\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.3301 - auc: 0.9286\n",
      "97/97 [==============================] - 0s 823us/step - loss: 0.3135 - auc: 0.9642\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.3333 - auc: 0.9257\n",
      "97/97 [==============================] - 0s 823us/step - loss: 0.2847 - auc: 0.9663\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.3440 - auc: 0.9296\n",
      "97/97 [==============================] - 0s 802us/step - loss: 0.2580 - auc: 0.9589\n",
      "387/387 [==============================] - 2s 1ms/step - loss: 0.3453 - auc: 0.9228\n",
      "97/97 [==============================] - 0s 813us/step - loss: 0.2790 - auc: 0.0000e+00\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.3552 - auc: 0.9192\n",
      "97/97 [==============================] - 0s 875us/step - loss: 0.3846 - auc: 0.0000e+00\n",
      "194/194 [==============================] - 1s 1ms/step - loss: 0.6834 - auc: 0.5064\n",
      "49/49 [==============================] - 0s 854us/step - loss: 0.7816 - auc: 0.5000\n",
      "194/194 [==============================] - 1s 1ms/step - loss: 0.6833 - auc: 0.5015\n",
      "49/49 [==============================] - 0s 833us/step - loss: 0.7826 - auc: 0.5000\n",
      "194/194 [==============================] - 1s 1ms/step - loss: 0.6929 - auc: 0.5117\n",
      "49/49 [==============================] - 0s 854us/step - loss: 0.6949 - auc: 0.5000\n",
      "194/194 [==============================] - 1s 1ms/step - loss: 0.6819 - auc: 0.5040\n",
      "49/49 [==============================] - 0s 896us/step - loss: 0.7965 - auc: 0.0000e+00\n",
      "194/194 [==============================] - 1s 1ms/step - loss: 0.6819 - auc: 0.4957\n",
      "49/49 [==============================] - 0s 854us/step - loss: 0.7954 - auc: 0.0000e+00\n",
      "194/194 [==============================] - 1s 1ms/step - loss: 0.3838 - auc: 0.9095\n",
      "49/49 [==============================] - 0s 896us/step - loss: 0.3894 - auc: 0.9596\n",
      "194/194 [==============================] - 1s 1ms/step - loss: 0.3840 - auc: 0.9092\n",
      "49/49 [==============================] - 0s 917us/step - loss: 0.3915 - auc: 0.9546\n",
      "194/194 [==============================] - 1s 1ms/step - loss: 0.4144 - auc: 0.8994\n",
      "49/49 [==============================] - 0s 896us/step - loss: 0.3313 - auc: 0.9437\n",
      "194/194 [==============================] - 1s 1ms/step - loss: 0.3879 - auc: 0.9057\n",
      "49/49 [==============================] - 0s 854us/step - loss: 0.3153 - auc: 0.0000e+00\n",
      "194/194 [==============================] - 1s 1ms/step - loss: 0.4047 - auc: 0.8944\n",
      "49/49 [==============================] - 0s 896us/step - loss: 0.4853 - auc: 0.0000e+00\n",
      "194/194 [==============================] - 1s 1ms/step - loss: 0.6916 - auc: 0.5049\n",
      "49/49 [==============================] - 1s 914us/step - loss: 0.7030 - auc: 0.5000\n",
      "194/194 [==============================] - 1s 1ms/step - loss: 0.6916 - auc: 0.4943\n",
      "49/49 [==============================] - 0s 833us/step - loss: 0.7030 - auc: 0.5000\n",
      "194/194 [==============================] - 1s 1ms/step - loss: 0.6932 - auc: 0.5000\n",
      "49/49 [==============================] - 0s 896us/step - loss: 0.6935 - auc: 0.5000\n",
      "194/194 [==============================] - 1s 1ms/step - loss: 0.6915 - auc: 0.5020\n",
      "49/49 [==============================] - 0s 854us/step - loss: 0.7042 - auc: 0.0000e+00\n",
      "194/194 [==============================] - 1s 1ms/step - loss: 0.6915 - auc: 0.5047\n",
      "49/49 [==============================] - 0s 896us/step - loss: 0.7039 - auc: 0.0000e+00\n",
      "194/194 [==============================] - 1s 1ms/step - loss: 0.6931 - auc: 0.5000\n",
      "49/49 [==============================] - 0s 854us/step - loss: 0.6934 - auc: 0.5000\n",
      "194/194 [==============================] - 1s 2ms/step - loss: 0.6931 - auc: 0.5000\n",
      "49/49 [==============================] - 0s 896us/step - loss: 0.6933 - auc: 0.5000\n",
      "194/194 [==============================] - 1s 1ms/step - loss: 0.6932 - auc: 0.5000\n",
      "49/49 [==============================] - 0s 938us/step - loss: 0.6931 - auc: 0.5000\n",
      "194/194 [==============================] - 1s 1ms/step - loss: 0.6931 - auc: 0.5000\n",
      "49/49 [==============================] - 0s 896us/step - loss: 0.6935 - auc: 0.0000e+00\n",
      "194/194 [==============================] - 1s 1ms/step - loss: 0.6931 - auc: 0.5000\n",
      "49/49 [==============================] - 0s 917us/step - loss: 0.6935 - auc: 0.0000e+00\n",
      "194/194 [==============================] - 1s 1ms/step - loss: 0.4219 - auc: 0.8818\n",
      "49/49 [==============================] - 0s 896us/step - loss: 0.4305 - auc: 0.9574\n",
      "194/194 [==============================] - 1s 1ms/step - loss: 0.4143 - auc: 0.8833\n",
      "49/49 [==============================] - 0s 896us/step - loss: 0.4536 - auc: 0.9543\n",
      "194/194 [==============================] - 1s 1ms/step - loss: 0.4191 - auc: 0.8955\n",
      "49/49 [==============================] - 0s 938us/step - loss: 0.2962 - auc: 0.9513\n",
      "194/194 [==============================] - 1s 1ms/step - loss: 0.4188 - auc: 0.8895\n",
      "49/49 [==============================] - 0s 875us/step - loss: 0.3337 - auc: 0.0000e+00\n",
      "194/194 [==============================] - 1s 1ms/step - loss: 0.4175 - auc: 0.8912\n",
      "49/49 [==============================] - 0s 854us/step - loss: 0.3497 - auc: 0.0000e+00\n",
      "194/194 [==============================] - 1s 1ms/step - loss: 0.5451 - auc: 0.8058\n",
      "49/49 [==============================] - 0s 896us/step - loss: 0.8364 - auc: 0.9463\n",
      "194/194 [==============================] - 1s 1ms/step - loss: 0.5423 - auc: 0.8059\n",
      "49/49 [==============================] - 0s 875us/step - loss: 0.7378 - auc: 0.9311\n",
      "194/194 [==============================] - 1s 1ms/step - loss: 0.5404 - auc: 0.8450\n",
      "49/49 [==============================] - 0s 875us/step - loss: 0.3949 - auc: 0.9138\n",
      "194/194 [==============================] - 1s 1ms/step - loss: 0.5579 - auc: 0.7932\n",
      "49/49 [==============================] - 0s 833us/step - loss: 0.5442 - auc: 0.0000e+00\n",
      "194/194 [==============================] - 1s 1ms/step - loss: 0.5513 - auc: 0.8190\n",
      "49/49 [==============================] - 0s 875us/step - loss: 0.3747 - auc: 0.0000e+00\n",
      "194/194 [==============================] - 1s 1ms/step - loss: 0.3863 - auc: 0.9026\n",
      "49/49 [==============================] - 0s 833us/step - loss: 0.3687 - auc: 0.9637\n",
      "194/194 [==============================] - 1s 1ms/step - loss: 0.3826 - auc: 0.9031\n",
      "49/49 [==============================] - 0s 854us/step - loss: 0.2496 - auc: 0.9606\n",
      "194/194 [==============================] - 1s 1ms/step - loss: 0.3904 - auc: 0.9105\n",
      "49/49 [==============================] - 0s 917us/step - loss: 0.2830 - auc: 0.9534\n",
      "194/194 [==============================] - 1s 1ms/step - loss: 0.3889 - auc: 0.9060\n",
      "49/49 [==============================] - 0s 875us/step - loss: 0.3116 - auc: 0.0000e+00\n",
      "194/194 [==============================] - 1s 1ms/step - loss: 0.3892 - auc: 0.9022\n",
      "49/49 [==============================] - 0s 917us/step - loss: 0.3577 - auc: 0.0000e+00\n",
      "194/194 [==============================] - 1s 1ms/step - loss: 0.6834 - auc: 0.5022\n",
      "49/49 [==============================] - 0s 854us/step - loss: 0.7807 - auc: 0.5000\n",
      "194/194 [==============================] - 1s 1ms/step - loss: 0.6835 - auc: 0.4885\n",
      "49/49 [==============================] - 0s 896us/step - loss: 0.7815 - auc: 0.5000\n",
      "194/194 [==============================] - 1s 2ms/step - loss: 0.6928 - auc: 0.5087\n",
      "49/49 [==============================] - 0s 938us/step - loss: 0.6948 - auc: 0.5000\n",
      "194/194 [==============================] - 1s 1ms/step - loss: 0.6818 - auc: 0.5062\n",
      "49/49 [==============================] - 0s 854us/step - loss: 0.7954 - auc: 0.0000e+00\n",
      "194/194 [==============================] - 1s 1ms/step - loss: 0.6819 - auc: 0.5039\n",
      "49/49 [==============================] - 0s 854us/step - loss: 0.7955 - auc: 0.0000e+00\n",
      "194/194 [==============================] - 1s 1ms/step - loss: 0.3813 - auc: 0.9073\n",
      "49/49 [==============================] - 0s 896us/step - loss: 0.4862 - auc: 0.9594\n",
      "194/194 [==============================] - 1s 1ms/step - loss: 0.3864 - auc: 0.9077\n",
      "49/49 [==============================] - 0s 854us/step - loss: 0.3532 - auc: 0.9531\n",
      "194/194 [==============================] - 1s 1ms/step - loss: 0.3945 - auc: 0.9103\n",
      "49/49 [==============================] - 0s 896us/step - loss: 0.3219 - auc: 0.9496\n",
      "194/194 [==============================] - 1s 1ms/step - loss: 0.4000 - auc: 0.8963\n",
      "49/49 [==============================] - 0s 896us/step - loss: 0.4781 - auc: 0.0000e+00\n",
      "194/194 [==============================] - 1s 1ms/step - loss: 0.3924 - auc: 0.9007\n",
      "49/49 [==============================] - 0s 846us/step - loss: 0.4866 - auc: 0.0000e+00\n",
      "194/194 [==============================] - 1s 1ms/step - loss: 0.6917 - auc: 0.4962\n",
      "49/49 [==============================] - 0s 875us/step - loss: 0.7028 - auc: 0.5000\n",
      "194/194 [==============================] - 1s 1ms/step - loss: 0.6916 - auc: 0.5068\n",
      "49/49 [==============================] - 0s 833us/step - loss: 0.7031 - auc: 0.5000\n",
      "194/194 [==============================] - 1s 1ms/step - loss: 0.6931 - auc: 0.5000\n",
      "49/49 [==============================] - 0s 896us/step - loss: 0.6935 - auc: 0.5000\n",
      "194/194 [==============================] - 1s 1ms/step - loss: 0.6915 - auc: 0.4956\n",
      "49/49 [==============================] - 0s 854us/step - loss: 0.7042 - auc: 0.0000e+00\n",
      "194/194 [==============================] - 1s 1ms/step - loss: 0.6915 - auc: 0.4924\n",
      "49/49 [==============================] - 0s 875us/step - loss: 0.7044 - auc: 0.0000e+00\n",
      "194/194 [==============================] - 1s 1ms/step - loss: 0.6931 - auc: 0.5000\n",
      "49/49 [==============================] - 0s 896us/step - loss: 0.6935 - auc: 0.5000\n",
      "194/194 [==============================] - 1s 1ms/step - loss: 0.6931 - auc: 0.5000\n",
      "49/49 [==============================] - 0s 833us/step - loss: 0.6934 - auc: 0.5000\n",
      "194/194 [==============================] - 1s 1ms/step - loss: 0.6931 - auc: 0.5000\n",
      "49/49 [==============================] - 0s 938us/step - loss: 0.6931 - auc: 0.5000\n",
      "194/194 [==============================] - 1s 1ms/step - loss: 0.6931 - auc: 0.5000\n",
      "49/49 [==============================] - 0s 1ms/step - loss: 0.6929 - auc: 0.0000e+00\n",
      "194/194 [==============================] - 1s 1ms/step - loss: 0.6931 - auc: 0.5000\n",
      "49/49 [==============================] - 0s 916us/step - loss: 0.6934 - auc: 0.0000e+00\n",
      "194/194 [==============================] - 1s 1ms/step - loss: 0.4131 - auc: 0.8852\n",
      "49/49 [==============================] - 0s 812us/step - loss: 0.4120 - auc: 0.9592\n",
      "194/194 [==============================] - 1s 1ms/step - loss: 0.4313 - auc: 0.8739\n",
      "49/49 [==============================] - 0s 854us/step - loss: 0.3712 - auc: 0.9558\n",
      "194/194 [==============================] - 1s 1ms/step - loss: 0.4289 - auc: 0.8940\n",
      "49/49 [==============================] - 0s 854us/step - loss: 0.2962 - auc: 0.9487\n",
      "194/194 [==============================] - 1s 1ms/step - loss: 0.4140 - auc: 0.8904\n",
      "49/49 [==============================] - 0s 875us/step - loss: 0.3333 - auc: 0.0000e+00\n",
      "194/194 [==============================] - 1s 1ms/step - loss: 0.4225 - auc: 0.8821\n",
      "49/49 [==============================] - 0s 854us/step - loss: 0.3797 - auc: 0.0000e+00\n",
      "194/194 [==============================] - 1s 2ms/step - loss: 0.5421 - auc: 0.8065\n",
      "49/49 [==============================] - 0s 917us/step - loss: 0.7541 - auc: 0.9439\n",
      "194/194 [==============================] - 1s 1ms/step - loss: 0.5390 - auc: 0.8032\n",
      "49/49 [==============================] - 0s 813us/step - loss: 0.6537 - auc: 0.9238\n",
      "194/194 [==============================] - 1s 1ms/step - loss: 0.5476 - auc: 0.8439\n",
      "49/49 [==============================] - 0s 875us/step - loss: 0.4112 - auc: 0.9132\n",
      "194/194 [==============================] - 1s 1ms/step - loss: 0.5232 - auc: 0.8324\n",
      "49/49 [==============================] - 0s 896us/step - loss: 0.4959 - auc: 0.0000e+00\n",
      "194/194 [==============================] - 1s 1ms/step - loss: 0.5358 - auc: 0.8314\n",
      "49/49 [==============================] - 0s 875us/step - loss: 0.5168 - auc: 0.0000e+00\n",
      "194/194 [==============================] - 1s 1ms/step - loss: 0.3881 - auc: 0.9010\n",
      "49/49 [==============================] - 0s 813us/step - loss: 0.2786 - auc: 0.9627\n",
      "194/194 [==============================] - 1s 2ms/step - loss: 0.3913 - auc: 0.9010\n",
      "49/49 [==============================] - 0s 875us/step - loss: 0.3398 - auc: 0.9606\n",
      "194/194 [==============================] - 1s 1ms/step - loss: 0.3928 - auc: 0.9082\n",
      "49/49 [==============================] - 0s 917us/step - loss: 0.3021 - auc: 0.9505\n",
      "194/194 [==============================] - 1s 1ms/step - loss: 0.3921 - auc: 0.9032\n",
      "49/49 [==============================] - 0s 896us/step - loss: 0.3058 - auc: 0.0000e+00\n",
      "194/194 [==============================] - 1s 1ms/step - loss: 0.3964 - auc: 0.8988\n",
      "49/49 [==============================] - 0s 854us/step - loss: 0.2996 - auc: 0.0000e+00\n",
      "194/194 [==============================] - 1s 1ms/step - loss: 0.6835 - auc: 0.5000\n",
      "49/49 [==============================] - 0s 896us/step - loss: 0.7807 - auc: 0.5000\n",
      "194/194 [==============================] - 1s 1ms/step - loss: 0.6831 - auc: 0.4958\n",
      "49/49 [==============================] - 0s 917us/step - loss: 0.7820 - auc: 0.5000\n",
      "194/194 [==============================] - 1s 1ms/step - loss: 0.6928 - auc: 0.5162\n",
      "49/49 [==============================] - 0s 875us/step - loss: 0.6947 - auc: 0.5000\n",
      "194/194 [==============================] - 1s 1ms/step - loss: 0.6820 - auc: 0.4882\n",
      "49/49 [==============================] - 0s 896us/step - loss: 0.7938 - auc: 0.0000e+00\n",
      "194/194 [==============================] - 1s 1ms/step - loss: 0.6819 - auc: 0.4995\n",
      "49/49 [==============================] - 0s 854us/step - loss: 0.7941 - auc: 0.0000e+00\n",
      "194/194 [==============================] - 1s 1ms/step - loss: 0.3807 - auc: 0.9089\n",
      "49/49 [==============================] - 0s 855us/step - loss: 0.5170 - auc: 0.9610\n",
      "194/194 [==============================] - 1s 1ms/step - loss: 0.4012 - auc: 0.9066\n",
      "49/49 [==============================] - 0s 875us/step - loss: 0.5094 - auc: 0.9550\n",
      "194/194 [==============================] - 1s 1ms/step - loss: 0.4177 - auc: 0.9083\n",
      "49/49 [==============================] - 0s 917us/step - loss: 0.2986 - auc: 0.9462\n",
      "194/194 [==============================] - 1s 1ms/step - loss: 0.3881 - auc: 0.9043\n",
      "49/49 [==============================] - 0s 854us/step - loss: 0.4221 - auc: 0.0000e+00\n",
      "194/194 [==============================] - 1s 1ms/step - loss: 0.3996 - auc: 0.8961\n",
      "49/49 [==============================] - 0s 875us/step - loss: 0.3969 - auc: 0.0000e+00\n",
      "194/194 [==============================] - 1s 1ms/step - loss: 0.6917 - auc: 0.4994\n",
      "49/49 [==============================] - 0s 854us/step - loss: 0.7029 - auc: 0.5000\n",
      "194/194 [==============================] - 1s 1ms/step - loss: 0.6913 - auc: 0.5223\n",
      "49/49 [==============================] - 0s 917us/step - loss: 0.7037 - auc: 0.5000\n",
      "194/194 [==============================] - 1s 1ms/step - loss: 0.6931 - auc: 0.5000\n",
      "49/49 [==============================] - 0s 833us/step - loss: 0.6935 - auc: 0.5000\n",
      "194/194 [==============================] - 1s 1ms/step - loss: 0.6915 - auc: 0.4885\n",
      "49/49 [==============================] - 0s 875us/step - loss: 0.7044 - auc: 0.0000e+00\n",
      "194/194 [==============================] - 1s 2ms/step - loss: 0.6915 - auc: 0.5004\n",
      "49/49 [==============================] - 0s 896us/step - loss: 0.7041 - auc: 0.0000e+00\n",
      "194/194 [==============================] - 1s 1ms/step - loss: 0.6933 - auc: 0.5000\n",
      "49/49 [==============================] - 0s 833us/step - loss: 0.6932 - auc: 0.5000\n",
      "194/194 [==============================] - 1s 1ms/step - loss: 0.6933 - auc: 0.5000\n",
      "49/49 [==============================] - 1s 889us/step - loss: 0.6930 - auc: 0.5000\n",
      "194/194 [==============================] - 1s 1ms/step - loss: 0.6932 - auc: 0.5000\n",
      "49/49 [==============================] - 0s 854us/step - loss: 0.6932 - auc: 0.5000\n",
      "194/194 [==============================] - 1s 1ms/step - loss: 0.6931 - auc: 0.5000\n",
      "49/49 [==============================] - 0s 865us/step - loss: 0.6932 - auc: 0.0000e+00\n",
      "194/194 [==============================] - 1s 1ms/step - loss: 0.6931 - auc: 0.5000\n",
      "49/49 [==============================] - 0s 896us/step - loss: 0.6933 - auc: 0.0000e+00\n",
      "194/194 [==============================] - 1s 1ms/step - loss: 0.4164 - auc: 0.8861\n",
      "49/49 [==============================] - 0s 854us/step - loss: 0.3954 - auc: 0.9619\n",
      "194/194 [==============================] - 1s 1ms/step - loss: 0.4234 - auc: 0.8794\n",
      "49/49 [==============================] - 0s 875us/step - loss: 0.4426 - auc: 0.9519\n",
      "194/194 [==============================] - 1s 1ms/step - loss: 0.4224 - auc: 0.8936\n",
      "49/49 [==============================] - 0s 854us/step - loss: 0.2983 - auc: 0.9506\n",
      "194/194 [==============================] - 1s 1ms/step - loss: 0.4181 - auc: 0.8886\n",
      "49/49 [==============================] - 0s 854us/step - loss: 0.3887 - auc: 0.0000e+00\n",
      "194/194 [==============================] - 1s 1ms/step - loss: 0.4166 - auc: 0.8882\n",
      "49/49 [==============================] - 0s 896us/step - loss: 0.2417 - auc: 0.0000e+00\n",
      "194/194 [==============================] - 1s 1ms/step - loss: 0.5399 - auc: 0.8076\n",
      "49/49 [==============================] - 0s 854us/step - loss: 0.7187 - auc: 0.9444\n",
      "194/194 [==============================] - 1s 1ms/step - loss: 0.5405 - auc: 0.8056\n",
      "49/49 [==============================] - 0s 875us/step - loss: 0.6584 - auc: 0.9275\n",
      "194/194 [==============================] - 1s 1ms/step - loss: 0.5509 - auc: 0.8335\n",
      "49/49 [==============================] - 0s 833us/step - loss: 0.4023 - auc: 0.9162\n",
      "194/194 [==============================] - 1s 1ms/step - loss: 0.5352 - auc: 0.8349\n",
      "49/49 [==============================] - 0s 875us/step - loss: 0.4287 - auc: 0.0000e+00\n",
      "194/194 [==============================] - 1s 1ms/step - loss: 0.5364 - auc: 0.8342\n",
      "49/49 [==============================] - 0s 938us/step - loss: 0.4263 - auc: 0.0000e+00\n",
      "194/194 [==============================] - 2s 2ms/step - loss: 0.3843 - auc: 0.9073\n",
      "49/49 [==============================] - 0s 938us/step - loss: 0.3561 - auc: 0.9569\n",
      "194/194 [==============================] - 1s 2ms/step - loss: 0.3978 - auc: 0.8976\n",
      "49/49 [==============================] - 0s 854us/step - loss: 0.3637 - auc: 0.9609\n",
      "194/194 [==============================] - 1s 2ms/step - loss: 0.4003 - auc: 0.9083\n",
      "49/49 [==============================] - 0s 854us/step - loss: 0.2896 - auc: 0.9537\n",
      "194/194 [==============================] - 1s 1ms/step - loss: 0.3862 - auc: 0.9040\n",
      "49/49 [==============================] - 0s 834us/step - loss: 0.3878 - auc: 0.0000e+00\n",
      "194/194 [==============================] - 1s 2ms/step - loss: 0.3995 - auc: 0.8972\n",
      "49/49 [==============================] - 0s 896us/step - loss: 0.3767 - auc: 0.0000e+00\n",
      "194/194 [==============================] - 1s 1ms/step - loss: 0.6834 - auc: 0.5079\n",
      "49/49 [==============================] - 0s 917us/step - loss: 0.7816 - auc: 0.5000\n",
      "194/194 [==============================] - 1s 1ms/step - loss: 0.6833 - auc: 0.5029\n",
      "49/49 [==============================] - 0s 854us/step - loss: 0.7818 - auc: 0.5000\n",
      "194/194 [==============================] - 1s 1ms/step - loss: 0.6930 - auc: 0.4910\n",
      "49/49 [==============================] - 0s 854us/step - loss: 0.6949 - auc: 0.5000\n",
      "194/194 [==============================] - 1s 1ms/step - loss: 0.6819 - auc: 0.4967\n",
      "49/49 [==============================] - 0s 917us/step - loss: 0.7943 - auc: 0.0000e+00\n",
      "194/194 [==============================] - 1s 1ms/step - loss: 0.6818 - auc: 0.5090\n",
      "49/49 [==============================] - 0s 917us/step - loss: 0.7955 - auc: 0.0000e+00\n",
      "194/194 [==============================] - 1s 1ms/step - loss: 0.3820 - auc: 0.9068\n",
      "49/49 [==============================] - 0s 875us/step - loss: 0.4177 - auc: 0.9608\n",
      "194/194 [==============================] - 1s 1ms/step - loss: 0.3996 - auc: 0.9073\n",
      "49/49 [==============================] - 0s 875us/step - loss: 0.4264 - auc: 0.9537\n",
      "194/194 [==============================] - 1s 1ms/step - loss: 0.3896 - auc: 0.9109\n",
      "49/49 [==============================] - 0s 875us/step - loss: 0.3163 - auc: 0.9534\n",
      "194/194 [==============================] - 1s 1ms/step - loss: 0.3904 - auc: 0.9027\n",
      "49/49 [==============================] - 0s 854us/step - loss: 0.4243 - auc: 0.0000e+00\n",
      "194/194 [==============================] - 1s 1ms/step - loss: 0.3972 - auc: 0.8976\n",
      "49/49 [==============================] - 0s 917us/step - loss: 0.4211 - auc: 0.0000e+00\n",
      "194/194 [==============================] - 1s 1ms/step - loss: 0.6917 - auc: 0.4984\n",
      "49/49 [==============================] - 0s 898us/step - loss: 0.7030 - auc: 0.5000\n",
      "194/194 [==============================] - 1s 1ms/step - loss: 0.6917 - auc: 0.5011\n",
      "49/49 [==============================] - 0s 854us/step - loss: 0.7033 - auc: 0.5000\n",
      "194/194 [==============================] - 1s 1ms/step - loss: 0.6930 - auc: 0.5000\n",
      "49/49 [==============================] - 0s 917us/step - loss: 0.6935 - auc: 0.5000\n",
      "194/194 [==============================] - 1s 1ms/step - loss: 0.6915 - auc: 0.5010\n",
      "49/49 [==============================] - 0s 875us/step - loss: 0.7041 - auc: 0.0000e+00\n",
      "194/194 [==============================] - 1s 1ms/step - loss: 0.6915 - auc: 0.5089\n",
      "49/49 [==============================] - 0s 938us/step - loss: 0.7040 - auc: 0.0000e+00\n",
      "194/194 [==============================] - 1s 1ms/step - loss: 0.6931 - auc: 0.5000\n",
      "49/49 [==============================] - 0s 854us/step - loss: 0.6933 - auc: 0.5000\n",
      "194/194 [==============================] - 1s 1ms/step - loss: 0.6932 - auc: 0.5000\n",
      "49/49 [==============================] - 0s 875us/step - loss: 0.6933 - auc: 0.5000\n",
      "194/194 [==============================] - 1s 1ms/step - loss: 0.6931 - auc: 0.5000\n",
      "49/49 [==============================] - 0s 833us/step - loss: 0.6931 - auc: 0.5000\n",
      "194/194 [==============================] - 1s 1ms/step - loss: 0.6931 - auc: 0.5000\n",
      "49/49 [==============================] - 0s 833us/step - loss: 0.6933 - auc: 0.0000e+00\n",
      "194/194 [==============================] - 1s 1ms/step - loss: 0.6932 - auc: 0.5000\n",
      "49/49 [==============================] - 1s 895us/step - loss: 0.6932 - auc: 0.0000e+00\n",
      "194/194 [==============================] - 1s 1ms/step - loss: 0.4211 - auc: 0.8850\n",
      "49/49 [==============================] - 0s 896us/step - loss: 0.3824 - auc: 0.9589\n",
      "194/194 [==============================] - 1s 1ms/step - loss: 0.4234 - auc: 0.8795\n",
      "49/49 [==============================] - 0s 854us/step - loss: 0.4011 - auc: 0.9574\n",
      "194/194 [==============================] - 1s 1ms/step - loss: 0.4302 - auc: 0.8926\n",
      "49/49 [==============================] - 0s 854us/step - loss: 0.2813 - auc: 0.9536\n",
      "194/194 [==============================] - 1s 2ms/step - loss: 0.4041 - auc: 0.8971\n",
      "49/49 [==============================] - 0s 938us/step - loss: 0.3318 - auc: 0.0000e+00\n",
      "194/194 [==============================] - 1s 2ms/step - loss: 0.4223 - auc: 0.8855\n",
      "49/49 [==============================] - 0s 896us/step - loss: 0.3623 - auc: 0.0000e+00\n",
      "194/194 [==============================] - 1s 1ms/step - loss: 0.5336 - auc: 0.8124\n",
      "49/49 [==============================] - 0s 875us/step - loss: 0.6631 - auc: 0.9460\n",
      "194/194 [==============================] - 1s 1ms/step - loss: 0.5323 - auc: 0.8145\n",
      "49/49 [==============================] - 0s 1ms/step - loss: 0.6462 - auc: 0.9251\n",
      "194/194 [==============================] - 1s 1ms/step - loss: 0.5580 - auc: 0.8493\n",
      "49/49 [==============================] - 0s 896us/step - loss: 0.4499 - auc: 0.9130\n",
      "194/194 [==============================] - 1s 1ms/step - loss: 0.5489 - auc: 0.8129\n",
      "49/49 [==============================] - 0s 875us/step - loss: 0.5086 - auc: 0.0000e+00\n",
      "194/194 [==============================] - 1s 1ms/step - loss: 0.5406 - auc: 0.8237\n",
      "49/49 [==============================] - 0s 917us/step - loss: 0.4142 - auc: 0.0000e+00\n",
      "194/194 [==============================] - 1s 2ms/step - loss: 0.3767 - auc: 0.9058\n",
      "49/49 [==============================] - 0s 938us/step - loss: 0.3259 - auc: 0.9592\n",
      "194/194 [==============================] - 1s 1ms/step - loss: 0.3831 - auc: 0.9005\n",
      "49/49 [==============================] - 0s 896us/step - loss: 0.2916 - auc: 0.9579\n",
      "194/194 [==============================] - 2s 2ms/step - loss: 0.3916 - auc: 0.9105\n",
      "49/49 [==============================] - 0s 854us/step - loss: 0.2708 - auc: 0.9544\n",
      "194/194 [==============================] - 1s 1ms/step - loss: 0.3932 - auc: 0.9012\n",
      "49/49 [==============================] - 0s 896us/step - loss: 0.4117 - auc: 0.0000e+00\n",
      "194/194 [==============================] - 1s 2ms/step - loss: 0.3882 - auc: 0.9053\n",
      "49/49 [==============================] - 0s 875us/step - loss: 0.3964 - auc: 0.0000e+00\n",
      "97/97 [==============================] - 1s 2ms/step - loss: 0.6876 - auc: 0.5016\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.7412 - auc: 0.5000\n",
      "97/97 [==============================] - 1s 2ms/step - loss: 0.6875 - auc: 0.5031\n",
      "25/25 [==============================] - 0s 1000us/step - loss: 0.7420 - auc: 0.5000\n",
      "97/97 [==============================] - 1s 2ms/step - loss: 0.6930 - auc: 0.4997\n",
      "25/25 [==============================] - 0s 958us/step - loss: 0.6942 - auc: 0.5000\n",
      "97/97 [==============================] - 1s 2ms/step - loss: 0.6867 - auc: 0.5014\n",
      "25/25 [==============================] - 0s 959us/step - loss: 0.7489 - auc: 0.0000e+00\n",
      "97/97 [==============================] - 1s 2ms/step - loss: 0.6866 - auc: 0.5070\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.7492 - auc: 0.0000e+00\n",
      "97/97 [==============================] - 1s 2ms/step - loss: 0.4464 - auc: 0.8774\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.4620 - auc: 0.9538\n",
      "97/97 [==============================] - 1s 2ms/step - loss: 0.4474 - auc: 0.8765\n",
      "25/25 [==============================] - 0s 917us/step - loss: 0.4861 - auc: 0.9392\n",
      "97/97 [==============================] - 1s 2ms/step - loss: 0.4519 - auc: 0.8832\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3628 - auc: 0.9382\n",
      "97/97 [==============================] - 1s 2ms/step - loss: 0.4453 - auc: 0.8822\n",
      "25/25 [==============================] - 0s 959us/step - loss: 0.3837 - auc: 0.0000e+00\n",
      "97/97 [==============================] - 1s 2ms/step - loss: 0.4441 - auc: 0.8767\n",
      "25/25 [==============================] - 0s 959us/step - loss: 0.3088 - auc: 0.0000e+00\n",
      "97/97 [==============================] - 1s 2ms/step - loss: 0.6923 - auc: 0.4941\n",
      "25/25 [==============================] - 0s 958us/step - loss: 0.6996 - auc: 0.5000\n",
      "97/97 [==============================] - 1s 2ms/step - loss: 0.6923 - auc: 0.4866\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.6997 - auc: 0.5000\n",
      "97/97 [==============================] - 1s 2ms/step - loss: 0.6931 - auc: 0.5000\n",
      "25/25 [==============================] - 0s 981us/step - loss: 0.6934 - auc: 0.5000\n",
      "97/97 [==============================] - 1s 2ms/step - loss: 0.6921 - auc: 0.4984\n",
      "25/25 [==============================] - 0s 958us/step - loss: 0.7004 - auc: 0.0000e+00\n",
      "97/97 [==============================] - 1s 2ms/step - loss: 0.6921 - auc: 0.4868\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.7009 - auc: 0.0000e+00\n",
      "97/97 [==============================] - 1s 2ms/step - loss: 0.6933 - auc: 0.5000\n",
      "25/25 [==============================] - 0s 958us/step - loss: 0.6930 - auc: 0.5000\n",
      "97/97 [==============================] - 1s 2ms/step - loss: 0.6932 - auc: 0.5000\n",
      "25/25 [==============================] - 0s 1000us/step - loss: 0.6932 - auc: 0.5000\n",
      "97/97 [==============================] - 1s 2ms/step - loss: 0.6932 - auc: 0.5000\n",
      "25/25 [==============================] - 0s 958us/step - loss: 0.6932 - auc: 0.5000\n",
      "97/97 [==============================] - 1s 2ms/step - loss: 0.6931 - auc: 0.5000\n",
      "25/25 [==============================] - 0s 917us/step - loss: 0.6932 - auc: 0.0000e+00\n",
      "97/97 [==============================] - 1s 2ms/step - loss: 0.6931 - auc: 0.5000\n",
      "25/25 [==============================] - 0s 1000us/step - loss: 0.6935 - auc: 0.0000e+00\n",
      "97/97 [==============================] - 1s 2ms/step - loss: 0.5123 - auc: 0.8182\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.5154 - auc: 0.9500\n",
      "97/97 [==============================] - 1s 2ms/step - loss: 0.5338 - auc: 0.7926\n",
      "25/25 [==============================] - 0s 959us/step - loss: 0.4348 - auc: 0.9194\n",
      "97/97 [==============================] - 1s 2ms/step - loss: 0.5046 - auc: 0.8494\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3477 - auc: 0.9331\n",
      "97/97 [==============================] - 1s 2ms/step - loss: 0.5098 - auc: 0.8339\n",
      "25/25 [==============================] - 0s 932us/step - loss: 0.4094 - auc: 0.0000e+00\n",
      "97/97 [==============================] - 1s 2ms/step - loss: 0.5146 - auc: 0.8401\n",
      "25/25 [==============================] - 0s 1000us/step - loss: 0.4432 - auc: 0.0000e+00\n",
      "97/97 [==============================] - 1s 2ms/step - loss: 0.5965 - auc: 0.7167\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.9260 - auc: 0.9300\n",
      "97/97 [==============================] - 1s 2ms/step - loss: 0.6096 - auc: 0.7028\n",
      "25/25 [==============================] - 0s 916us/step - loss: 0.9059 - auc: 0.9171\n",
      "97/97 [==============================] - 1s 2ms/step - loss: 0.6199 - auc: 0.7845\n",
      "25/25 [==============================] - 0s 958us/step - loss: 0.5265 - auc: 0.9066\n",
      "97/97 [==============================] - 1s 2ms/step - loss: 0.6364 - auc: 0.7795\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.6214 - auc: 0.0000e+00\n",
      "97/97 [==============================] - 1s 2ms/step - loss: 0.6267 - auc: 0.7492\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.6865 - auc: 0.0000e+00\n",
      "97/97 [==============================] - 1s 2ms/step - loss: 0.4806 - auc: 0.8559\n",
      "25/25 [==============================] - 0s 959us/step - loss: 0.6097 - auc: 0.9555\n",
      "97/97 [==============================] - 1s 2ms/step - loss: 0.4671 - auc: 0.8554\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3666 - auc: 0.9432\n",
      "97/97 [==============================] - 1s 2ms/step - loss: 0.4679 - auc: 0.8742\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3171 - auc: 0.9429\n",
      "97/97 [==============================] - 1s 2ms/step - loss: 0.4640 - auc: 0.8677\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3382 - auc: 0.0000e+00\n",
      "97/97 [==============================] - 1s 2ms/step - loss: 0.4666 - auc: 0.8633\n",
      "25/25 [==============================] - 1s 1ms/step - loss: 0.4098 - auc: 0.0000e+00\n",
      "97/97 [==============================] - 1s 2ms/step - loss: 0.6877 - auc: 0.4885\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.7407 - auc: 0.5000\n",
      "97/97 [==============================] - 1s 2ms/step - loss: 0.6874 - auc: 0.4990\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.7422 - auc: 0.5000\n",
      "97/97 [==============================] - 1s 2ms/step - loss: 0.6930 - auc: 0.5082\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.6941 - auc: 0.5000\n",
      "97/97 [==============================] - 1s 2ms/step - loss: 0.6867 - auc: 0.4968\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.7490 - auc: 0.0000e+00\n",
      "97/97 [==============================] - 1s 2ms/step - loss: 0.6866 - auc: 0.5035\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.7492 - auc: 0.0000e+00\n",
      "97/97 [==============================] - 1s 2ms/step - loss: 0.4403 - auc: 0.8746\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.4804 - auc: 0.9554\n",
      "97/97 [==============================] - 1s 2ms/step - loss: 0.4692 - auc: 0.8806\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.4811 - auc: 0.9322\n",
      "97/97 [==============================] - 1s 2ms/step - loss: 0.4546 - auc: 0.8818\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3554 - auc: 0.9374\n",
      "97/97 [==============================] - 1s 2ms/step - loss: 0.4542 - auc: 0.8742\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.4367 - auc: 0.0000e+00\n",
      "97/97 [==============================] - 1s 2ms/step - loss: 0.4511 - auc: 0.8753\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3973 - auc: 0.0000e+00\n",
      "97/97 [==============================] - 1s 2ms/step - loss: 0.6924 - auc: 0.4878\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.6993 - auc: 0.4864\n",
      "97/97 [==============================] - 1s 2ms/step - loss: 0.6922 - auc: 0.4948\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.6997 - auc: 0.5000\n",
      "97/97 [==============================] - 1s 2ms/step - loss: 0.6930 - auc: 0.5000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.6934 - auc: 0.5000\n",
      "97/97 [==============================] - 1s 2ms/step - loss: 0.6921 - auc: 0.4921\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.7007 - auc: 0.0000e+00\n",
      "97/97 [==============================] - 1s 2ms/step - loss: 0.6921 - auc: 0.4866\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.7004 - auc: 0.0000e+00\n",
      "97/97 [==============================] - 1s 2ms/step - loss: 0.6931 - auc: 0.5000\n",
      "25/25 [==============================] - 0s 959us/step - loss: 0.6933 - auc: 0.5000\n",
      "97/97 [==============================] - 1s 2ms/step - loss: 0.6932 - auc: 0.5000\n",
      "25/25 [==============================] - 0s 958us/step - loss: 0.6931 - auc: 0.5000\n",
      "97/97 [==============================] - 1s 2ms/step - loss: 0.6932 - auc: 0.5000\n",
      "25/25 [==============================] - 0s 1000us/step - loss: 0.6932 - auc: 0.5000\n",
      "97/97 [==============================] - 1s 3ms/step - loss: 0.6931 - auc: 0.5000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.6932 - auc: 0.0000e+00\n",
      "97/97 [==============================] - 1s 2ms/step - loss: 0.6932 - auc: 0.5000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.6929 - auc: 0.0000e+00\n",
      "97/97 [==============================] - 1s 2ms/step - loss: 0.5137 - auc: 0.8130\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.5253 - auc: 0.9490\n",
      "97/97 [==============================] - 1s 2ms/step - loss: 0.5323 - auc: 0.7978\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.5035 - auc: 0.9284\n",
      "97/97 [==============================] - 1s 2ms/step - loss: 0.5241 - auc: 0.8356\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3742 - auc: 0.9356\n",
      "97/97 [==============================] - 1s 2ms/step - loss: 0.5116 - auc: 0.8325\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.4157 - auc: 0.0000e+00\n",
      "97/97 [==============================] - 1s 2ms/step - loss: 0.5106 - auc: 0.8354\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.4845 - auc: 0.0000e+00\n",
      "97/97 [==============================] - 1s 2ms/step - loss: 0.6197 - auc: 0.6870\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.9781 - auc: 0.9097\n",
      "97/97 [==============================] - 1s 2ms/step - loss: 0.6204 - auc: 0.6874\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.9137 - auc: 0.9002\n",
      "97/97 [==============================] - 1s 2ms/step - loss: 0.6304 - auc: 0.7916\n",
      "25/25 [==============================] - 1s 1ms/step - loss: 0.5274 - auc: 0.8959\n",
      "97/97 [==============================] - 1s 2ms/step - loss: 0.6314 - auc: 0.7889\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.6072 - auc: 0.0000e+00\n",
      "97/97 [==============================] - 1s 2ms/step - loss: 0.6370 - auc: 0.7707\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.5677 - auc: 0.0000e+00\n",
      "97/97 [==============================] - 1s 3ms/step - loss: 0.4568 - auc: 0.8603\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.4724 - auc: 0.9573\n",
      "97/97 [==============================] - 1s 2ms/step - loss: 0.4619 - auc: 0.8559\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3850 - auc: 0.9452\n",
      "97/97 [==============================] - 1s 2ms/step - loss: 0.4808 - auc: 0.8714\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3272 - auc: 0.9414\n",
      "97/97 [==============================] - 1s 2ms/step - loss: 0.4646 - auc: 0.8637\n",
      "25/25 [==============================] - 0s 1000us/step - loss: 0.5187 - auc: 0.0000e+00\n",
      "97/97 [==============================] - 1s 2ms/step - loss: 0.4608 - auc: 0.8634\n",
      "25/25 [==============================] - 0s 958us/step - loss: 0.3633 - auc: 0.0000e+00\n",
      "97/97 [==============================] - 1s 2ms/step - loss: 0.6876 - auc: 0.5011\n",
      "25/25 [==============================] - 0s 958us/step - loss: 0.7414 - auc: 0.5000\n",
      "97/97 [==============================] - 1s 2ms/step - loss: 0.6876 - auc: 0.4974\n",
      "25/25 [==============================] - 0s 971us/step - loss: 0.7420 - auc: 0.5000\n",
      "97/97 [==============================] - 1s 2ms/step - loss: 0.6929 - auc: 0.5209\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.6941 - auc: 0.5000\n",
      "97/97 [==============================] - 1s 2ms/step - loss: 0.6867 - auc: 0.5091\n",
      "25/25 [==============================] - 0s 959us/step - loss: 0.7488 - auc: 0.0000e+00\n",
      "97/97 [==============================] - 1s 2ms/step - loss: 0.6867 - auc: 0.5087\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.7488 - auc: 0.0000e+00\n",
      "97/97 [==============================] - 1s 2ms/step - loss: 0.4648 - auc: 0.8829\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.5328 - auc: 0.9459\n",
      "97/97 [==============================] - 1s 2ms/step - loss: 0.4516 - auc: 0.8763\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.4616 - auc: 0.9418\n",
      "97/97 [==============================] - 1s 2ms/step - loss: 0.4476 - auc: 0.8880\n",
      "25/25 [==============================] - 0s 917us/step - loss: 0.3250 - auc: 0.9394\n",
      "97/97 [==============================] - 1s 2ms/step - loss: 0.4551 - auc: 0.8722\n",
      "25/25 [==============================] - 0s 959us/step - loss: 0.4258 - auc: 0.0000e+00\n",
      "97/97 [==============================] - 1s 2ms/step - loss: 0.4471 - auc: 0.8773\n",
      "25/25 [==============================] - 0s 959us/step - loss: 0.3870 - auc: 0.0000e+00\n",
      "97/97 [==============================] - 1s 2ms/step - loss: 0.6924 - auc: 0.4744\n",
      "25/25 [==============================] - 0s 958us/step - loss: 0.6996 - auc: 0.5000\n",
      "97/97 [==============================] - 1s 2ms/step - loss: 0.6922 - auc: 0.5064\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.6999 - auc: 0.5000\n",
      "97/97 [==============================] - 1s 2ms/step - loss: 0.6931 - auc: 0.5000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.6934 - auc: 0.5000\n",
      "97/97 [==============================] - 1s 2ms/step - loss: 0.6921 - auc: 0.4936\n",
      "25/25 [==============================] - 0s 1000us/step - loss: 0.7006 - auc: 0.0000e+00\n",
      "97/97 [==============================] - 1s 2ms/step - loss: 0.6921 - auc: 0.4887\n",
      "25/25 [==============================] - 0s 958us/step - loss: 0.7006 - auc: 0.0000e+00\n",
      "97/97 [==============================] - 1s 2ms/step - loss: 0.6932 - auc: 0.5000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.6932 - auc: 0.5000\n",
      "97/97 [==============================] - 1s 2ms/step - loss: 0.6930 - auc: 0.5000\n",
      "25/25 [==============================] - 0s 958us/step - loss: 0.6935 - auc: 0.5000\n",
      "97/97 [==============================] - 1s 2ms/step - loss: 0.6931 - auc: 0.5000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.6932 - auc: 0.5000\n",
      "97/97 [==============================] - 1s 2ms/step - loss: 0.6931 - auc: 0.5000\n",
      "25/25 [==============================] - 0s 958us/step - loss: 0.6932 - auc: 0.0000e+00\n",
      "97/97 [==============================] - 1s 2ms/step - loss: 0.6931 - auc: 0.5000\n",
      "25/25 [==============================] - 0s 999us/step - loss: 0.6936 - auc: 0.0000e+00\n",
      "97/97 [==============================] - 1s 2ms/step - loss: 0.5127 - auc: 0.8164\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.5373 - auc: 0.9511\n",
      "97/97 [==============================] - 1s 2ms/step - loss: 0.5314 - auc: 0.8037\n",
      "25/25 [==============================] - 0s 958us/step - loss: 0.5922 - auc: 0.9292\n",
      "97/97 [==============================] - 1s 2ms/step - loss: 0.5153 - auc: 0.8407\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3428 - auc: 0.9327\n",
      "97/97 [==============================] - 1s 2ms/step - loss: 0.4973 - auc: 0.8447\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.4193 - auc: 0.0000e+00\n",
      "97/97 [==============================] - 1s 2ms/step - loss: 0.5072 - auc: 0.8366\n",
      "25/25 [==============================] - 0s 959us/step - loss: 0.3937 - auc: 0.0000e+00\n",
      "97/97 [==============================] - 1s 2ms/step - loss: 0.6081 - auc: 0.7157\n",
      "25/25 [==============================] - 0s 916us/step - loss: 0.8793 - auc: 0.9160\n",
      "97/97 [==============================] - 1s 2ms/step - loss: 0.6093 - auc: 0.6910\n",
      "25/25 [==============================] - 0s 959us/step - loss: 0.9311 - auc: 0.9126\n",
      "97/97 [==============================] - 1s 2ms/step - loss: 0.6368 - auc: 0.7709\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.5398 - auc: 0.8857\n",
      "97/97 [==============================] - 1s 2ms/step - loss: 0.6299 - auc: 0.7426\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.7134 - auc: 0.0000e+00\n",
      "97/97 [==============================] - 1s 2ms/step - loss: 0.6346 - auc: 0.7566\n",
      "25/25 [==============================] - 0s 917us/step - loss: 0.6741 - auc: 0.0000e+00\n",
      "97/97 [==============================] - 1s 2ms/step - loss: 0.4660 - auc: 0.8483\n",
      "25/25 [==============================] - 0s 959us/step - loss: 0.4542 - auc: 0.9555\n",
      "97/97 [==============================] - 1s 2ms/step - loss: 0.4630 - auc: 0.8501\n",
      "25/25 [==============================] - 0s 1000us/step - loss: 0.4376 - auc: 0.9428\n",
      "97/97 [==============================] - 1s 2ms/step - loss: 0.4685 - auc: 0.8721\n",
      "25/25 [==============================] - 0s 959us/step - loss: 0.3306 - auc: 0.9381\n",
      "97/97 [==============================] - 1s 2ms/step - loss: 0.4640 - auc: 0.8787\n",
      "25/25 [==============================] - 0s 958us/step - loss: 0.5064 - auc: 0.0000e+00\n",
      "97/97 [==============================] - 1s 2ms/step - loss: 0.4743 - auc: 0.8541\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3456 - auc: 0.0000e+00\n",
      "97/97 [==============================] - 1s 2ms/step - loss: 0.6875 - auc: 0.4985\n",
      "25/25 [==============================] - 0s 959us/step - loss: 0.7412 - auc: 0.5000\n",
      "97/97 [==============================] - 1s 2ms/step - loss: 0.6875 - auc: 0.4956\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.7418 - auc: 0.5000\n",
      "97/97 [==============================] - 1s 2ms/step - loss: 0.6930 - auc: 0.5242\n",
      "25/25 [==============================] - 0s 917us/step - loss: 0.6941 - auc: 0.5000\n",
      "97/97 [==============================] - 1s 2ms/step - loss: 0.6867 - auc: 0.4940\n",
      "25/25 [==============================] - 0s 959us/step - loss: 0.7486 - auc: 0.0000e+00\n",
      "97/97 [==============================] - 1s 2ms/step - loss: 0.6867 - auc: 0.4950\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.7483 - auc: 0.0000e+00\n",
      "97/97 [==============================] - 1s 2ms/step - loss: 0.4645 - auc: 0.8793\n",
      "25/25 [==============================] - 0s 945us/step - loss: 0.5828 - auc: 0.9537\n",
      "97/97 [==============================] - 1s 2ms/step - loss: 0.4559 - auc: 0.8706\n",
      "25/25 [==============================] - 0s 959us/step - loss: 0.4476 - auc: 0.9380\n",
      "97/97 [==============================] - 1s 2ms/step - loss: 0.4499 - auc: 0.8897\n",
      "25/25 [==============================] - 0s 1000us/step - loss: 0.3530 - auc: 0.9362\n",
      "97/97 [==============================] - 1s 2ms/step - loss: 0.4506 - auc: 0.8777\n",
      "25/25 [==============================] - 0s 958us/step - loss: 0.3782 - auc: 0.0000e+00\n",
      "97/97 [==============================] - 1s 2ms/step - loss: 0.4452 - auc: 0.8814\n",
      "25/25 [==============================] - 0s 958us/step - loss: 0.3006 - auc: 0.0000e+00\n",
      "97/97 [==============================] - 1s 2ms/step - loss: 0.6923 - auc: 0.4919\n",
      "25/25 [==============================] - 0s 1000us/step - loss: 0.6996 - auc: 0.5000\n",
      "97/97 [==============================] - 1s 2ms/step - loss: 0.6922 - auc: 0.4951\n",
      "25/25 [==============================] - 0s 958us/step - loss: 0.7001 - auc: 0.5000\n",
      "97/97 [==============================] - 1s 2ms/step - loss: 0.6932 - auc: 0.5000\n",
      "25/25 [==============================] - 0s 972us/step - loss: 0.6934 - auc: 0.5000\n",
      "97/97 [==============================] - 1s 2ms/step - loss: 0.6921 - auc: 0.4970\n",
      "25/25 [==============================] - 0s 1000us/step - loss: 0.7005 - auc: 0.0000e+00\n",
      "97/97 [==============================] - 1s 2ms/step - loss: 0.6921 - auc: 0.4973\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.7007 - auc: 0.0000e+00\n",
      "97/97 [==============================] - 1s 2ms/step - loss: 0.6932 - auc: 0.5000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.6932 - auc: 0.5000\n",
      "97/97 [==============================] - 1s 2ms/step - loss: 0.6931 - auc: 0.5000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.6934 - auc: 0.5000\n",
      "97/97 [==============================] - 1s 2ms/step - loss: 0.6932 - auc: 0.5000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.6932 - auc: 0.5000\n",
      "97/97 [==============================] - 1s 2ms/step - loss: 0.6932 - auc: 0.5000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.6935 - auc: 0.0000e+00\n",
      "97/97 [==============================] - 1s 2ms/step - loss: 0.6931 - auc: 0.5000\n",
      "25/25 [==============================] - 0s 916us/step - loss: 0.6930 - auc: 0.0000e+00\n",
      "97/97 [==============================] - 1s 2ms/step - loss: 0.5068 - auc: 0.8216\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.5392 - auc: 0.9496\n",
      "97/97 [==============================] - 1s 2ms/step - loss: 0.5167 - auc: 0.8110\n",
      "25/25 [==============================] - 0s 958us/step - loss: 0.5174 - auc: 0.9206\n",
      "97/97 [==============================] - 1s 2ms/step - loss: 0.5145 - auc: 0.8454\n",
      "25/25 [==============================] - 0s 958us/step - loss: 0.3548 - auc: 0.9263\n",
      "97/97 [==============================] - 1s 2ms/step - loss: 0.5005 - auc: 0.8389\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.4574 - auc: 0.0000e+00\n",
      "97/97 [==============================] - 1s 2ms/step - loss: 0.5143 - auc: 0.8243\n",
      "25/25 [==============================] - 0s 916us/step - loss: 0.4803 - auc: 0.0000e+00\n",
      "97/97 [==============================] - 1s 2ms/step - loss: 0.6034 - auc: 0.7025\n",
      "25/25 [==============================] - 0s 958us/step - loss: 0.9417 - auc: 0.9229\n",
      "97/97 [==============================] - 1s 2ms/step - loss: 0.6125 - auc: 0.7135\n",
      "25/25 [==============================] - 0s 959us/step - loss: 0.7972 - auc: 0.8919\n",
      "97/97 [==============================] - 1s 2ms/step - loss: 0.6490 - auc: 0.7640\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.5646 - auc: 0.8770\n",
      "97/97 [==============================] - 1s 2ms/step - loss: 0.6412 - auc: 0.7761\n",
      "25/25 [==============================] - 0s 958us/step - loss: 0.5757 - auc: 0.0000e+00\n",
      "97/97 [==============================] - 1s 2ms/step - loss: 0.6338 - auc: 0.7197\n",
      "25/25 [==============================] - 0s 1000us/step - loss: 0.7756 - auc: 0.0000e+00\n",
      "97/97 [==============================] - 1s 2ms/step - loss: 0.4664 - auc: 0.8525\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.4614 - auc: 0.9579\n",
      "97/97 [==============================] - 1s 2ms/step - loss: 0.4825 - auc: 0.8505\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.5275 - auc: 0.9402\n",
      "97/97 [==============================] - 1s 2ms/step - loss: 0.4558 - auc: 0.8782\n",
      "25/25 [==============================] - 1s 1ms/step - loss: 0.3090 - auc: 0.9435\n",
      "97/97 [==============================] - 1s 2ms/step - loss: 0.4684 - auc: 0.8670\n",
      "25/25 [==============================] - 0s 937us/step - loss: 0.3489 - auc: 0.0000e+00\n",
      "97/97 [==============================] - 1s 2ms/step - loss: 0.4691 - auc: 0.8577\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3484 - auc: 0.0000e+00\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.6917 - auc: 0.5071\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7066 - auc: 0.5000\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.6914 - auc: 0.5010\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7071 - auc: 0.5779\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.6932 - auc: 0.5000\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6935 - auc: 0.5000\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.6914 - auc: 0.4996\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7087 - auc: 0.0000e+00\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.6914 - auc: 0.4957\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7087 - auc: 0.0000e+00\n",
      "25/25 [==============================] - 1s 2ms/step - loss: 0.6067 - auc: 0.7413\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7864 - auc: 0.9214\n",
      "25/25 [==============================] - 1s 2ms/step - loss: 0.6071 - auc: 0.7217\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7651 - auc: 0.9230\n",
      "25/25 [==============================] - 1s 2ms/step - loss: 0.6249 - auc: 0.7814\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5597 - auc: 0.9140\n",
      "25/25 [==============================] - 1s 2ms/step - loss: 0.6241 - auc: 0.8147\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4810 - auc: 0.0000e+00\n",
      "25/25 [==============================] - 1s 2ms/step - loss: 0.6281 - auc: 0.8303\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4625 - auc: 0.0000e+00\n",
      "25/25 [==============================] - 1s 3ms/step - loss: 0.6928 - auc: 0.5000\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6959 - auc: 0.5000\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6929 - auc: 0.5000\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6958 - auc: 0.5000\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6931 - auc: 0.5000\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6932 - auc: 0.5000\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6928 - auc: 0.5000\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6961 - auc: 0.0000e+00\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6927 - auc: 0.5000\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6959 - auc: 0.0000e+00\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6932 - auc: 0.5000\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6931 - auc: 0.5000\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.6932 - auc: 0.5000\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6933 - auc: 0.5000\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6931 - auc: 0.5000\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6931 - auc: 0.5000\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6932 - auc: 0.5000\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6928 - auc: 0.0000e+00\n",
      "25/25 [==============================] - 1s 3ms/step - loss: 0.6931 - auc: 0.5000\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6933 - auc: 0.0000e+00\n",
      "25/25 [==============================] - 1s 3ms/step - loss: 0.6768 - auc: 0.6018\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8035 - auc: 0.8012\n",
      "25/25 [==============================] - 1s 3ms/step - loss: 0.6751 - auc: 0.6209\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8014 - auc: 0.8146\n",
      "25/25 [==============================] - 1s 3ms/step - loss: 0.6867 - auc: 0.7006\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6700 - auc: 0.8555\n",
      "25/25 [==============================] - 1s 3ms/step - loss: 0.6831 - auc: 0.6390\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7252 - auc: 0.0000e+00\n",
      "25/25 [==============================] - 1s 3ms/step - loss: 0.6838 - auc: 0.7642\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6541 - auc: 0.0000e+00\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6877 - auc: 0.6010\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7187 - auc: 0.7969\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6895 - auc: 0.5789\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7126 - auc: 0.8260\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6907 - auc: 0.6804\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6857 - auc: 0.8552\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6889 - auc: 0.7000\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6930 - auc: 0.0000e+00\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6889 - auc: 0.6624\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7022 - auc: 0.0000e+00\n",
      "25/25 [==============================] - 1s 3ms/step - loss: 0.6666 - auc: 0.6807\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7972 - auc: 0.8466\n",
      "25/25 [==============================] - 1s 3ms/step - loss: 0.6599 - auc: 0.6709\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8683 - auc: 0.8485\n",
      "25/25 [==============================] - 1s 3ms/step - loss: 0.6729 - auc: 0.7067\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6210 - auc: 0.8611\n",
      "25/25 [==============================] - 1s 3ms/step - loss: 0.6721 - auc: 0.7363\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6203 - auc: 0.0000e+00\n",
      "25/25 [==============================] - 1s 3ms/step - loss: 0.6707 - auc: 0.7163\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7319 - auc: 0.0000e+00\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.6914 - auc: 0.5071\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7067 - auc: 0.5269\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.6915 - auc: 0.5065\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7069 - auc: 0.5347\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6931 - auc: 0.5000\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6934 - auc: 0.5000\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6914 - auc: 0.5036\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7084 - auc: 0.0000e+00\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.6914 - auc: 0.5036\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7085 - auc: 0.0000e+00\n",
      "25/25 [==============================] - 1s 3ms/step - loss: 0.5997 - auc: 0.7234\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9407 - auc: 0.9207\n",
      "25/25 [==============================] - 1s 3ms/step - loss: 0.6111 - auc: 0.7268\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8400 - auc: 0.9192\n",
      "25/25 [==============================] - 1s 2ms/step - loss: 0.6278 - auc: 0.7851\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5264 - auc: 0.9017\n",
      "25/25 [==============================] - 1s 2ms/step - loss: 0.6222 - auc: 0.7730\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6109 - auc: 0.0000e+00\n",
      "25/25 [==============================] - 1s 2ms/step - loss: 0.6306 - auc: 0.7792\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5851 - auc: 0.0000e+00\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.6927 - auc: 0.5000\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6961 - auc: 0.5000\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.6927 - auc: 0.5000\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6959 - auc: 0.5000\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.6931 - auc: 0.5000\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6932 - auc: 0.5000\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6928 - auc: 0.5000\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6962 - auc: 0.0000e+00\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.6927 - auc: 0.5000\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6964 - auc: 0.0000e+00\n",
      "25/25 [==============================] - 1s 2ms/step - loss: 0.6931 - auc: 0.5000\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6932 - auc: 0.5000\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6932 - auc: 0.5000\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6931 - auc: 0.5000\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6931 - auc: 0.5000\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6931 - auc: 0.5000\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6931 - auc: 0.5000\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6930 - auc: 0.0000e+00\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.6932 - auc: 0.5000\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6926 - auc: 0.0000e+00\n",
      "25/25 [==============================] - 1s 3ms/step - loss: 0.6811 - auc: 0.6505\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7510 - auc: 0.8161\n",
      "25/25 [==============================] - 1s 2ms/step - loss: 0.6796 - auc: 0.6099\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7694 - auc: 0.8233\n",
      "25/25 [==============================] - 1s 2ms/step - loss: 0.6824 - auc: 0.7180\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6567 - auc: 0.8560\n",
      "25/25 [==============================] - 1s 2ms/step - loss: 0.6848 - auc: 0.7016\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6947 - auc: 0.0000e+00\n",
      "25/25 [==============================] - 1s 2ms/step - loss: 0.6838 - auc: 0.7346\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6769 - auc: 0.0000e+00\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.6879 - auc: 0.6030\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7177 - auc: 0.8275\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.6871 - auc: 0.6010\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7219 - auc: 0.8232\n",
      "25/25 [==============================] - 1s 2ms/step - loss: 0.6907 - auc: 0.6692\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6866 - auc: 0.8421\n",
      "25/25 [==============================] - 1s 3ms/step - loss: 0.6897 - auc: 0.7176\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6850 - auc: 0.0000e+00\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6877 - auc: 0.6323\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7121 - auc: 0.0000e+00\n",
      "25/25 [==============================] - 1s 3ms/step - loss: 0.6636 - auc: 0.6679\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8635 - auc: 0.8485\n",
      "25/25 [==============================] - 1s 3ms/step - loss: 0.6580 - auc: 0.6147\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9009 - auc: 0.8600\n",
      "25/25 [==============================] - 1s 3ms/step - loss: 0.6767 - auc: 0.7595\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6096 - auc: 0.8857\n",
      "25/25 [==============================] - 1s 3ms/step - loss: 0.6709 - auc: 0.7223\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6865 - auc: 0.0000e+00\n",
      "25/25 [==============================] - 1s 2ms/step - loss: 0.6730 - auc: 0.7786\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5539 - auc: 0.0000e+00\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.6916 - auc: 0.5013\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7066 - auc: 0.5000\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.6915 - auc: 0.5045\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7070 - auc: 0.5258\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.6932 - auc: 0.5000\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6935 - auc: 0.5000\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.6914 - auc: 0.4985\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7084 - auc: 0.0000e+00\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.6914 - auc: 0.4880\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7091 - auc: 0.0000e+00\n",
      "25/25 [==============================] - 1s 2ms/step - loss: 0.6014 - auc: 0.7332\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8745 - auc: 0.9254\n",
      "25/25 [==============================] - 1s 3ms/step - loss: 0.5990 - auc: 0.7396\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8425 - auc: 0.9240\n",
      "25/25 [==============================] - 1s 3ms/step - loss: 0.6285 - auc: 0.7832\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5106 - auc: 0.9001\n",
      "25/25 [==============================] - 1s 3ms/step - loss: 0.6200 - auc: 0.7891\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6773 - auc: 0.0000e+00\n",
      "25/25 [==============================] - 1s 3ms/step - loss: 0.6331 - auc: 0.7712\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5469 - auc: 0.0000e+00\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6928 - auc: 0.5000\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6959 - auc: 0.5000\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.6928 - auc: 0.5000\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6959 - auc: 0.5000\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6931 - auc: 0.5000\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6932 - auc: 0.5000\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.6928 - auc: 0.5000\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6963 - auc: 0.0000e+00\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6928 - auc: 0.5000\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6963 - auc: 0.0000e+00\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6930 - auc: 0.5000\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6934 - auc: 0.5000\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6932 - auc: 0.5000\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6931 - auc: 0.5000\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.6931 - auc: 0.5000\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6931 - auc: 0.5000\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.6932 - auc: 0.5000\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6926 - auc: 0.0000e+00\n",
      "25/25 [==============================] - 1s 3ms/step - loss: 0.6932 - auc: 0.5000\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6935 - auc: 0.0000e+00\n",
      "25/25 [==============================] - 1s 3ms/step - loss: 0.6824 - auc: 0.6054\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7539 - auc: 0.8086\n",
      "25/25 [==============================] - 1s 3ms/step - loss: 0.6756 - auc: 0.6213\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7992 - auc: 0.8169\n",
      "25/25 [==============================] - 1s 3ms/step - loss: 0.6831 - auc: 0.6902\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6626 - auc: 0.8587\n",
      "25/25 [==============================] - 1s 3ms/step - loss: 0.6845 - auc: 0.7405\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6636 - auc: 0.0000e+00\n",
      "25/25 [==============================] - 1s 3ms/step - loss: 0.6843 - auc: 0.7297\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6775 - auc: 0.0000e+00\n",
      "25/25 [==============================] - 1s 3ms/step - loss: 0.6877 - auc: 0.6047\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7194 - auc: 0.8331\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.6874 - auc: 0.6385\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7152 - auc: 0.8248\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6896 - auc: 0.6805\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6856 - auc: 0.8485\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.6894 - auc: 0.5849\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7102 - auc: 0.0000e+00\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.6891 - auc: 0.6424\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7054 - auc: 0.0000e+00\n",
      "25/25 [==============================] - 1s 2ms/step - loss: 0.6539 - auc: 0.6532\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.9330 - auc: 0.8665\n",
      "25/25 [==============================] - 1s 2ms/step - loss: 0.6614 - auc: 0.6502\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8643 - auc: 0.8610\n",
      "25/25 [==============================] - 1s 3ms/step - loss: 0.6718 - auc: 0.7386\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6037 - auc: 0.8744\n",
      "25/25 [==============================] - 1s 3ms/step - loss: 0.6765 - auc: 0.7398\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6186 - auc: 0.0000e+00\n",
      "25/25 [==============================] - 1s 3ms/step - loss: 0.6737 - auc: 0.7076\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7453 - auc: 0.0000e+00\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.6916 - auc: 0.5092\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7061 - auc: 0.5000\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6915 - auc: 0.5041\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7070 - auc: 0.5437\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.6932 - auc: 0.5000\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6935 - auc: 0.5000\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.6914 - auc: 0.5028\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7086 - auc: 0.0000e+00\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.6914 - auc: 0.4974\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7081 - auc: 0.0000e+00\n",
      "25/25 [==============================] - 1s 2ms/step - loss: 0.6071 - auc: 0.7274\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8995 - auc: 0.9187\n",
      "25/25 [==============================] - 1s 2ms/step - loss: 0.5946 - auc: 0.7406\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.9473 - auc: 0.9238\n",
      "25/25 [==============================] - 1s 2ms/step - loss: 0.6251 - auc: 0.8037\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5108 - auc: 0.9000\n",
      "25/25 [==============================] - 1s 2ms/step - loss: 0.6225 - auc: 0.7736\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7124 - auc: 0.0000e+00\n",
      "25/25 [==============================] - 1s 3ms/step - loss: 0.6223 - auc: 0.7798\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6283 - auc: 0.0000e+00\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6927 - auc: 0.5000\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6961 - auc: 0.5000\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.6926 - auc: 0.5000\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6961 - auc: 0.5000\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6930 - auc: 0.5000\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6932 - auc: 0.5000\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6927 - auc: 0.5000\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6962 - auc: 0.0000e+00\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6927 - auc: 0.5000\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6960 - auc: 0.0000e+00\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6932 - auc: 0.5000\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6931 - auc: 0.5000\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.6930 - auc: 0.5000\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6934 - auc: 0.5000\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.6932 - auc: 0.5000\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6932 - auc: 0.5000\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.6931 - auc: 0.5000\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6932 - auc: 0.0000e+00\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.6931 - auc: 0.5000\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6934 - auc: 0.0000e+00\n",
      "25/25 [==============================] - 1s 2ms/step - loss: 0.6807 - auc: 0.6070\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7648 - auc: 0.8150\n",
      "25/25 [==============================] - 1s 2ms/step - loss: 0.6762 - auc: 0.6275\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7829 - auc: 0.8346\n",
      "25/25 [==============================] - 1s 2ms/step - loss: 0.6872 - auc: 0.7056\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6722 - auc: 0.8491\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.6815 - auc: 0.7214\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7061 - auc: 0.0000e+00\n",
      "25/25 [==============================] - 1s 3ms/step - loss: 0.6840 - auc: 0.7178\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6878 - auc: 0.0000e+00\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6871 - auc: 0.6204\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7190 - auc: 0.8382\n",
      "25/25 [==============================] - 1s 3ms/step - loss: 0.6854 - auc: 0.6199\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7282 - auc: 0.8324\n",
      "25/25 [==============================] - 1s 3ms/step - loss: 0.6906 - auc: 0.6710\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6874 - auc: 0.8594\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6888 - auc: 0.6584\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7047 - auc: 0.0000e+00\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6899 - auc: 0.7035\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6885 - auc: 0.0000e+00\n",
      "25/25 [==============================] - 1s 3ms/step - loss: 0.6677 - auc: 0.6452\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8351 - auc: 0.8413\n",
      "25/25 [==============================] - 1s 3ms/step - loss: 0.6594 - auc: 0.6522\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8989 - auc: 0.8607\n",
      "25/25 [==============================] - 1s 3ms/step - loss: 0.6740 - auc: 0.7248\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6234 - auc: 0.8759\n",
      "25/25 [==============================] - 1s 3ms/step - loss: 0.6772 - auc: 0.7657\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5836 - auc: 0.0000e+00\n",
      "25/25 [==============================] - 1s 3ms/step - loss: 0.6710 - auc: 0.7314\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6784 - auc: 0.0000e+00\n",
      "484/484 [==============================] - 1s 1ms/step - loss: 0.3224 - auc: 0.9376\n"
     ]
    }
   ],
   "source": [
    "optimizer = ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\n",
    "epochs = [50, 100, 150,200]\n",
    "batches = [32,64,128,512]\n",
    "\n",
    "#learn_rate = [0.001, 0.01, 0.1, 0.2, 0.3]#\n",
    "####### Grid Search  Parameter set parameter value \n",
    "model22 = KerasRegressor(build_fn=model_deep)\n",
    "#model = KerasRegressor(build_fn=create_model, epochs=100, batch_size=10, verbose=0)\n",
    "#epochs = 200,batch_size=512\n",
    "param_grid = dict(optimizer= optimizer, nb_epoch=epochs, batch_size=batches)\n",
    "grid = GridSearchCV(estimator=model22, param_grid=param_grid,n_jobs=1)\n",
    "grid_result = grid.fit(x_b, y_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc645d0-cffc-4be2-b163-eefd11cc48cd",
   "metadata": {},
   "source": [
    "## Show result with  grid search approch  with best parameter set  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5c44a2b0-4b70-4f48-800d-535045498731",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: -0.290086 using {'batch_size': 32, 'nb_epoch': 50, 'optimizer': 'Nadam'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7df991-f947-4aeb-9b61-5ec8d5d8541f",
   "metadata": {},
   "source": [
    "## Running Model  with grid search  parameter and applies with  imbalance pre-paring process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "8d41805b-e582-444c-89e1-4e98c5845b6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deep_learning-under_sample\n",
      "Epoch 1/50\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2098 - auc: 0.6345\n",
      "Epoch 2/50\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.0982 - auc: 0.8965\n",
      "Epoch 3/50\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.0853 - auc: 0.9223\n",
      "Epoch 4/50\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.0784 - auc: 0.9464\n",
      "Epoch 5/50\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.0720 - auc: 0.9545\n",
      "Epoch 6/50\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.0699 - auc: 0.9528\n",
      "Epoch 7/50\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.0659 - auc: 0.9565\n",
      "Epoch 8/50\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.0643 - auc: 0.9594\n",
      "Epoch 9/50\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.0628 - auc: 0.9617\n",
      "Epoch 10/50\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.0592 - auc: 0.9670\n",
      "Epoch 11/50\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.0581 - auc: 0.9689\n",
      "Epoch 12/50\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.0557 - auc: 0.9682\n",
      "Epoch 13/50\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.0577 - auc: 0.9656\n",
      "Epoch 14/50\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.0562 - auc: 0.9665\n",
      "Epoch 15/50\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.0507 - auc: 0.9759\n",
      "Epoch 16/50\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.0495 - auc: 0.9714\n",
      "Epoch 17/50\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.0511 - auc: 0.9727\n",
      "Epoch 18/50\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.0483 - auc: 0.9755\n",
      "Epoch 19/50\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.0534 - auc: 0.9692\n",
      "Epoch 20/50\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.0488 - auc: 0.9729\n",
      "Epoch 21/50\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.0478 - auc: 0.9757\n",
      "Epoch 22/50\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.0492 - auc: 0.9732\n",
      "Epoch 23/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0479 - auc: 0.9721\n",
      "Epoch 24/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0504 - auc: 0.9737\n",
      "Epoch 25/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0453 - auc: 0.9772\n",
      "Epoch 26/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0476 - auc: 0.9748\n",
      "Epoch 27/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0463 - auc: 0.9739\n",
      "Epoch 28/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0454 - auc: 0.9776\n",
      "Epoch 29/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0473 - auc: 0.9742\n",
      "Epoch 30/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0468 - auc: 0.9744\n",
      "Epoch 31/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0463 - auc: 0.9751\n",
      "Epoch 32/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0433 - auc: 0.9786\n",
      "Epoch 33/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0444 - auc: 0.9745\n",
      "Epoch 34/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0420 - auc: 0.9799\n",
      "Epoch 35/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0410 - auc: 0.9777\n",
      "Epoch 36/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0437 - auc: 0.9754\n",
      "Epoch 37/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0421 - auc: 0.9799\n",
      "Epoch 38/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0456 - auc: 0.9754\n",
      "Epoch 39/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0422 - auc: 0.9764\n",
      "Epoch 40/50\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.0411 - auc: 0.9800\n",
      "Epoch 41/50\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.0413 - auc: 0.9783\n",
      "Epoch 42/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0430 - auc: 0.9742\n",
      "Epoch 43/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0429 - auc: 0.9752\n",
      "Epoch 44/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0407 - auc: 0.9817\n",
      "Epoch 45/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0416 - auc: 0.9821\n",
      "Epoch 46/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0400 - auc: 0.9820\n",
      "Epoch 47/50\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.0398 - auc: 0.9807\n",
      "Epoch 48/50\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.0421 - auc: 0.9792\n",
      "Epoch 49/50\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.0402 - auc: 0.9855\n",
      "Epoch 50/50\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.0391 - auc: 0.9770\n",
      "---Done---\n",
      "deep_learning-over_sample\n",
      "Epoch 1/50\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.2023 - auc: 0.6402\n",
      "Epoch 2/50\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.0980 - auc: 0.8968\n",
      "Epoch 3/50\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.0840 - auc: 0.9303\n",
      "Epoch 4/50\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.0749 - auc: 0.9482\n",
      "Epoch 5/50\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.0730 - auc: 0.9538\n",
      "Epoch 6/50\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.0689 - auc: 0.9583\n",
      "Epoch 7/50\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.0669 - auc: 0.9599\n",
      "Epoch 8/50\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.0674 - auc: 0.9551\n",
      "Epoch 9/50\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.0628 - auc: 0.9605\n",
      "Epoch 10/50\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.0627 - auc: 0.9644\n",
      "Epoch 11/50\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.0639 - auc: 0.9607\n",
      "Epoch 12/50\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.0609 - auc: 0.9668\n",
      "Epoch 13/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0552 - auc: 0.9688\n",
      "Epoch 14/50\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.0587 - auc: 0.9664\n",
      "Epoch 15/50\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.0557 - auc: 0.9692\n",
      "Epoch 16/50\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.0559 - auc: 0.9712\n",
      "Epoch 17/50\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.0553 - auc: 0.9665\n",
      "Epoch 18/50\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.0583 - auc: 0.9676\n",
      "Epoch 19/50\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.0539 - auc: 0.9706\n",
      "Epoch 20/50\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.0515 - auc: 0.9721\n",
      "Epoch 21/50\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.0527 - auc: 0.9695\n",
      "Epoch 22/50\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.0528 - auc: 0.9705\n",
      "Epoch 23/50\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.0488 - auc: 0.9766\n",
      "Epoch 24/50\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.0512 - auc: 0.9739\n",
      "Epoch 25/50\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.0479 - auc: 0.9765\n",
      "Epoch 26/50\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.0454 - auc: 0.9789\n",
      "Epoch 27/50\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.0481 - auc: 0.9767\n",
      "Epoch 28/50\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.0474 - auc: 0.9717\n",
      "Epoch 29/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0500 - auc: 0.9706\n",
      "Epoch 30/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0479 - auc: 0.9762\n",
      "Epoch 31/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0436 - auc: 0.9776\n",
      "Epoch 32/50\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.0441 - auc: 0.9775\n",
      "Epoch 33/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0465 - auc: 0.9755\n",
      "Epoch 34/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0459 - auc: 0.9751\n",
      "Epoch 35/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0469 - auc: 0.9784\n",
      "Epoch 36/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0433 - auc: 0.9734\n",
      "Epoch 37/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0439 - auc: 0.9834\n",
      "Epoch 38/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0445 - auc: 0.9742\n",
      "Epoch 39/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0429 - auc: 0.9773\n",
      "Epoch 40/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0422 - auc: 0.9763\n",
      "Epoch 41/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0453 - auc: 0.9817\n",
      "Epoch 42/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0419 - auc: 0.9795\n",
      "Epoch 43/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0455 - auc: 0.9787\n",
      "Epoch 44/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0440 - auc: 0.9790\n",
      "Epoch 45/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0454 - auc: 0.9733\n",
      "Epoch 46/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0398 - auc: 0.9800\n",
      "Epoch 47/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0424 - auc: 0.9827\n",
      "Epoch 48/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0395 - auc: 0.9809\n",
      "Epoch 49/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0387 - auc: 0.9834\n",
      "Epoch 50/50\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.0433 - auc: 0.9821\n",
      "---Done---\n",
      "deep_learning-SMOTE\n",
      "Epoch 1/50\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2114 - auc: 0.6150\n",
      "Epoch 2/50\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.1014 - auc: 0.8856\n",
      "Epoch 3/50\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.0913 - auc: 0.9145\n",
      "Epoch 4/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0803 - auc: 0.9330\n",
      "Epoch 5/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0726 - auc: 0.9524\n",
      "Epoch 6/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0713 - auc: 0.9497\n",
      "Epoch 7/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0650 - auc: 0.9565\n",
      "Epoch 8/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0624 - auc: 0.9618\n",
      "Epoch 9/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0616 - auc: 0.9633\n",
      "Epoch 10/50\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.0600 - auc: 0.9660\n",
      "Epoch 11/50\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.0573 - auc: 0.9679\n",
      "Epoch 12/50\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.0554 - auc: 0.9695\n",
      "Epoch 13/50\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.0541 - auc: 0.9664\n",
      "Epoch 14/50\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.0538 - auc: 0.9677\n",
      "Epoch 15/50\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.0558 - auc: 0.9674\n",
      "Epoch 16/50\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.0525 - auc: 0.9734\n",
      "Epoch 17/50\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.0547 - auc: 0.9707\n",
      "Epoch 18/50\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.0502 - auc: 0.9705\n",
      "Epoch 19/50\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.0504 - auc: 0.9725\n",
      "Epoch 20/50\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.0471 - auc: 0.9749\n",
      "Epoch 21/50\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.0510 - auc: 0.9684\n",
      "Epoch 22/50\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.0514 - auc: 0.9668\n",
      "Epoch 23/50\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.0473 - auc: 0.9774\n",
      "Epoch 24/50\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.0466 - auc: 0.9721\n",
      "Epoch 25/50\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.0504 - auc: 0.9760\n",
      "Epoch 26/50\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.0464 - auc: 0.9731\n",
      "Epoch 27/50\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.0456 - auc: 0.9771\n",
      "Epoch 28/50\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.0449 - auc: 0.9755\n",
      "Epoch 29/50\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.0468 - auc: 0.9739\n",
      "Epoch 30/50\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.0459 - auc: 0.9765\n",
      "Epoch 31/50\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.0449 - auc: 0.9734\n",
      "Epoch 32/50\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.0465 - auc: 0.9749\n",
      "Epoch 33/50\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.0442 - auc: 0.9779\n",
      "Epoch 34/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0474 - auc: 0.9781\n",
      "Epoch 35/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0438 - auc: 0.9797\n",
      "Epoch 36/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0460 - auc: 0.9734\n",
      "Epoch 37/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0445 - auc: 0.9782\n",
      "Epoch 38/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0408 - auc: 0.9781\n",
      "Epoch 39/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0436 - auc: 0.9793\n",
      "Epoch 40/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0459 - auc: 0.9737\n",
      "Epoch 41/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0434 - auc: 0.9783\n",
      "Epoch 42/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0437 - auc: 0.9786\n",
      "Epoch 43/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0398 - auc: 0.9816\n",
      "Epoch 44/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0429 - auc: 0.9753\n",
      "Epoch 45/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0418 - auc: 0.9810\n",
      "Epoch 46/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0397 - auc: 0.9825\n",
      "Epoch 47/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0389 - auc: 0.9836\n",
      "Epoch 48/50\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.0380 - auc: 0.9831\n",
      "Epoch 49/50\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.0429 - auc: 0.9798\n",
      "Epoch 50/50\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.0388 - auc: 0.9802\n",
      "---Done---\n",
      "deep_learning-SMOTE_TOMEK\n",
      "Epoch 1/50\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2097 - auc: 0.6208\n",
      "Epoch 2/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0985 - auc: 0.8969\n",
      "Epoch 3/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0821 - auc: 0.9311\n",
      "Epoch 4/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0750 - auc: 0.9426\n",
      "Epoch 5/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0705 - auc: 0.9548\n",
      "Epoch 6/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0688 - auc: 0.9546\n",
      "Epoch 7/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0664 - auc: 0.9597\n",
      "Epoch 8/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0625 - auc: 0.9612\n",
      "Epoch 9/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0626 - auc: 0.9611\n",
      "Epoch 10/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0605 - auc: 0.9687\n",
      "Epoch 11/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0626 - auc: 0.9620\n",
      "Epoch 12/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0586 - auc: 0.9611\n",
      "Epoch 13/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0576 - auc: 0.9668\n",
      "Epoch 14/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0573 - auc: 0.9647\n",
      "Epoch 15/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0574 - auc: 0.9605\n",
      "Epoch 16/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0545 - auc: 0.9694\n",
      "Epoch 17/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0554 - auc: 0.9709\n",
      "Epoch 18/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0531 - auc: 0.9688\n",
      "Epoch 19/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0536 - auc: 0.9669\n",
      "Epoch 20/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0490 - auc: 0.9719\n",
      "Epoch 21/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0506 - auc: 0.9736\n",
      "Epoch 22/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0516 - auc: 0.9743\n",
      "Epoch 23/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0487 - auc: 0.9751\n",
      "Epoch 24/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0463 - auc: 0.9765\n",
      "Epoch 25/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0493 - auc: 0.9738\n",
      "Epoch 26/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0480 - auc: 0.9747\n",
      "Epoch 27/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0498 - auc: 0.9716\n",
      "Epoch 28/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0444 - auc: 0.9787\n",
      "Epoch 29/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0440 - auc: 0.9802\n",
      "Epoch 30/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0452 - auc: 0.9755\n",
      "Epoch 31/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0473 - auc: 0.9734\n",
      "Epoch 32/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0431 - auc: 0.9826\n",
      "Epoch 33/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0433 - auc: 0.9807\n",
      "Epoch 34/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0458 - auc: 0.9773\n",
      "Epoch 35/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0435 - auc: 0.9752\n",
      "Epoch 36/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0429 - auc: 0.9763\n",
      "Epoch 37/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0419 - auc: 0.9819\n",
      "Epoch 38/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0448 - auc: 0.9760\n",
      "Epoch 39/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0439 - auc: 0.9787\n",
      "Epoch 40/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0413 - auc: 0.9783\n",
      "Epoch 41/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0418 - auc: 0.9777\n",
      "Epoch 42/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0416 - auc: 0.9804\n",
      "Epoch 43/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0436 - auc: 0.9782\n",
      "Epoch 44/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0394 - auc: 0.9845\n",
      "Epoch 45/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0394 - auc: 0.9786\n",
      "Epoch 46/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0421 - auc: 0.9817\n",
      "Epoch 47/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0398 - auc: 0.9815\n",
      "Epoch 48/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0442 - auc: 0.9760\n",
      "Epoch 49/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0406 - auc: 0.9827\n",
      "Epoch 50/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0418 - auc: 0.9786\n",
      "---Done---\n",
      "deep_learning-None\n",
      "Epoch 1/50\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2187 - auc: 0.5874\n",
      "Epoch 2/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0996 - auc: 0.8950\n",
      "Epoch 3/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0861 - auc: 0.9278\n",
      "Epoch 4/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0753 - auc: 0.9490\n",
      "Epoch 5/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0708 - auc: 0.9551\n",
      "Epoch 6/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0688 - auc: 0.9601\n",
      "Epoch 7/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0671 - auc: 0.9582\n",
      "Epoch 8/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0635 - auc: 0.9584\n",
      "Epoch 9/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0647 - auc: 0.9566\n",
      "Epoch 10/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0625 - auc: 0.9630\n",
      "Epoch 11/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0590 - auc: 0.9665\n",
      "Epoch 12/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0604 - auc: 0.9624\n",
      "Epoch 13/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0588 - auc: 0.9669\n",
      "Epoch 14/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0590 - auc: 0.9611\n",
      "Epoch 15/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0559 - auc: 0.9639\n",
      "Epoch 16/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0550 - auc: 0.9719\n",
      "Epoch 17/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0564 - auc: 0.9680\n",
      "Epoch 18/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0547 - auc: 0.9673\n",
      "Epoch 19/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0544 - auc: 0.9719\n",
      "Epoch 20/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0496 - auc: 0.9708\n",
      "Epoch 21/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0488 - auc: 0.9711\n",
      "Epoch 22/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0505 - auc: 0.9782\n",
      "Epoch 23/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0524 - auc: 0.9729\n",
      "Epoch 24/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0499 - auc: 0.9745\n",
      "Epoch 25/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0489 - auc: 0.9705\n",
      "Epoch 26/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0495 - auc: 0.9742\n",
      "Epoch 27/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0499 - auc: 0.9778\n",
      "Epoch 28/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0480 - auc: 0.9735\n",
      "Epoch 29/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0489 - auc: 0.9753\n",
      "Epoch 30/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0493 - auc: 0.9735\n",
      "Epoch 31/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0486 - auc: 0.9717\n",
      "Epoch 32/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0477 - auc: 0.9759\n",
      "Epoch 33/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0462 - auc: 0.9757\n",
      "Epoch 34/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0484 - auc: 0.9751\n",
      "Epoch 35/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0497 - auc: 0.9753\n",
      "Epoch 36/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0451 - auc: 0.9784\n",
      "Epoch 37/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0444 - auc: 0.9764\n",
      "Epoch 38/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0460 - auc: 0.9785\n",
      "Epoch 39/50\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.0460 - auc: 0.9783\n",
      "Epoch 40/50\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.0451 - auc: 0.9763\n",
      "Epoch 41/50\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.0435 - auc: 0.9752\n",
      "Epoch 42/50\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.0477 - auc: 0.9733\n",
      "Epoch 43/50\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.0419 - auc: 0.9779\n",
      "Epoch 44/50\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.0453 - auc: 0.9721\n",
      "Epoch 45/50\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.0433 - auc: 0.9713\n",
      "Epoch 46/50\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.0444 - auc: 0.9766\n",
      "Epoch 47/50\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.0406 - auc: 0.9752\n",
      "Epoch 48/50\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.0432 - auc: 0.9757\n",
      "Epoch 49/50\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.0407 - auc: 0.9790\n",
      "Epoch 50/50\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.0439 - auc: 0.9779\n",
      "---Done---\n"
     ]
    }
   ],
   "source": [
    "## created table best  parameter  \n",
    "df_result_dl = pd.DataFrame(columns =  ['Model_N','Imbalance','accuracy','auc','tp','tn','fn','fp'])\n",
    "model_dl = ['deep_learning'] \n",
    "imbalance_list = ['under_sample','over_sample','SMOTE','SMOTE_TOMEK',None]\n",
    "for i in range(len(model_dl)) :\n",
    "    for j in range(len(imbalance_list)) :\n",
    "        df_result_dl.loc[counter,'Model_N'] = model_dl[i] \n",
    "        df_result_dl.loc[counter,'Imbalance'] = imbalance_list[j] \n",
    "        counter += 1    \n",
    "        \n",
    "for i , j  in df_result_dl.iterrows():\n",
    "    #print(j)\n",
    "        print(f\"{j['Model_N']}-{j['Imbalance']}\")\n",
    "        x_b,y_b = imbalance( x_train_s , y_train_s ,j['Imbalance'] )  #x,y = imbalance( x_train , y_train , 'over_sample')\n",
    "        x_train_after  = x_b\n",
    "        y_train_after = y_b\n",
    "        x_test_after = x_test_s\n",
    "        y_test_after = y_test_s       \n",
    "        \n",
    "        #predict = fn_model(j['Model_N'],x_train_after,y_train_after,x_test_after,y_test_after) \n",
    "        \n",
    "        ### model architecture \n",
    "        model = Sequential()  \n",
    "        model.add(Dense(256, kernel_initializer='uniform',activation='relu',input_dim= x_train_s.shape[1]))\n",
    "        model.add(Dense(128,activation='relu'))\n",
    "        model.add(Dense(64, kernel_initializer='uniform',activation='relu'))\n",
    "        #model.add(Dropout(0.2))\n",
    "        model.add(Dense(32, kernel_initializer='uniform',activation='relu')) \n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(Dense(1, kernel_initializer='uniform',activation='sigmoid')) \n",
    "        \n",
    "        model.compile(optimizer='Nadam', loss='binary_crossentropy', metrics=['AUC']) \n",
    "        model_fit = model.fit(x = x_train_s ,y = y_train_s, epochs = 50, batch_size=32)\n",
    "        sc = StandardScaler()\n",
    "        X_test = sc.fit_transform(x_test_after)\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        auc = metrics.roc_auc_score(y_test_after, y_pred)\n",
    "        y_expect = y_pred > 0.5\n",
    "        tn, fp, fn, tp  = confusion_matrix(y_test_after, y_expect).ravel()\n",
    "        accuracy = accuracy_score(y_test_after, y_expect)\n",
    "        df_result_dl.loc[i,'accuracy'] = accuracy\n",
    "        df_result_dl.loc[i,'auc'] = auc\n",
    "        df_result_dl.loc[i, 'tp'] = tp \n",
    "        df_result_dl.loc[i, 'tn'] = tn\n",
    "        df_result_dl.loc[i, 'fn'] = fn\n",
    "        df_result_dl.loc[i, 'fp'] = fp\n",
    "        print('---Done---')\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "b2e2c397-1fa1-4b45-8fd4-57ca87f44d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result_dl\n",
    "df_result_dl['pecision'] = df_result_dl['tp'] / (df_result_dl['tp'] + df_result_dl['fp']) \n",
    "df_result_dl['recall'] = df_result_dl['tp'] / (df_result_dl['tp']+df_result_dl['fn'])\n",
    "df_result_dl['F1'] = ((df_result_dl['recall']*df_result_dl['pecision'] )/ (df_result_dl['recall']+df_result_dl['pecision']))*2\n",
    "df_result_dl.to_csv('deep_leaning.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57701b7e-9789-4df7-aca1-70522ff03966",
   "metadata": {},
   "source": [
    "## Show Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "6c8fc94d-4c1c-49a2-9731-26ab43209146",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2268\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_6842 (Dense)          (None, 256)               3584      \n",
      "                                                                 \n",
      " dense_6843 (Dense)          (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_6844 (Dense)          (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_6845 (Dense)          (None, 32)                2080      \n",
      "                                                                 \n",
      " dropout_3383 (Dropout)      (None, 32)                0         \n",
      "                                                                 \n",
      " dense_6846 (Dense)          (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 46,849\n",
      "Trainable params: 46,849\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "5ec3c42c-d310-4def-ab33-d84dd5868d3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) ', 'for plot_model/model_to_dot to work.')\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf.keras.utils.plot_model(model, './image_model.png') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe3d7b5-edc1-4eca-8d96-090aab326f3a",
   "metadata": {},
   "source": [
    "## Model Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "6ed5d084-798c-4cc6-9e9e-fa543f45e5a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model_N</th>\n",
       "      <th>Imbalance</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>auc</th>\n",
       "      <th>tp</th>\n",
       "      <th>tn</th>\n",
       "      <th>fn</th>\n",
       "      <th>fp</th>\n",
       "      <th>pecision</th>\n",
       "      <th>recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>deep_learning</td>\n",
       "      <td>under_sample</td>\n",
       "      <td>0.9805</td>\n",
       "      <td>0.963788</td>\n",
       "      <td>39</td>\n",
       "      <td>1922</td>\n",
       "      <td>37</td>\n",
       "      <td>2</td>\n",
       "      <td>0.95122</td>\n",
       "      <td>0.513158</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>deep_learning</td>\n",
       "      <td>over_sample</td>\n",
       "      <td>0.9805</td>\n",
       "      <td>0.973356</td>\n",
       "      <td>46</td>\n",
       "      <td>1915</td>\n",
       "      <td>30</td>\n",
       "      <td>9</td>\n",
       "      <td>0.836364</td>\n",
       "      <td>0.605263</td>\n",
       "      <td>0.70229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>deep_learning</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>0.974</td>\n",
       "      <td>0.96372</td>\n",
       "      <td>24</td>\n",
       "      <td>1924</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>deep_learning</td>\n",
       "      <td>SMOTE_TOMEK</td>\n",
       "      <td>0.9765</td>\n",
       "      <td>0.966018</td>\n",
       "      <td>33</td>\n",
       "      <td>1920</td>\n",
       "      <td>43</td>\n",
       "      <td>4</td>\n",
       "      <td>0.891892</td>\n",
       "      <td>0.434211</td>\n",
       "      <td>0.584071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>deep_learning</td>\n",
       "      <td>None</td>\n",
       "      <td>0.978</td>\n",
       "      <td>0.965498</td>\n",
       "      <td>38</td>\n",
       "      <td>1918</td>\n",
       "      <td>38</td>\n",
       "      <td>6</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Model_N     Imbalance accuracy       auc  tp    tn  fn fp  pecision  \\\n",
       "85  deep_learning  under_sample   0.9805  0.963788  39  1922  37  2   0.95122   \n",
       "86  deep_learning   over_sample   0.9805  0.973356  46  1915  30  9  0.836364   \n",
       "87  deep_learning         SMOTE    0.974   0.96372  24  1924  52  0       1.0   \n",
       "88  deep_learning   SMOTE_TOMEK   0.9765  0.966018  33  1920  43  4  0.891892   \n",
       "89  deep_learning          None    0.978  0.965498  38  1918  38  6  0.863636   \n",
       "\n",
       "      recall        F1  \n",
       "85  0.513158  0.666667  \n",
       "86  0.605263   0.70229  \n",
       "87  0.315789      0.48  \n",
       "88  0.434211  0.584071  \n",
       "89       0.5  0.633333  "
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df['LanguageWantToWorkWith'][1:20]\n",
    "df_result_dl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0ac959c5-7db2-4ca7-b5f0-84eaecc89422",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_27149_row0_col2 {\n",
       "  width: 10em;\n",
       "  height: 80%;\n",
       "  background: linear-gradient(90deg,lightskyblue 100.0%, transparent 100.0%);\n",
       "}\n",
       "#T_27149_row0_col3, #T_27149_row4_col2, #T_27149_row4_col4, #T_27149_row4_col5 {\n",
       "  width: 10em;\n",
       "  height: 80%;\n",
       "}\n",
       "#T_27149_row0_col4 {\n",
       "  width: 10em;\n",
       "  height: 80%;\n",
       "  background: linear-gradient(90deg,orange 100.0%, transparent 100.0%);\n",
       "}\n",
       "#T_27149_row0_col5 {\n",
       "  width: 10em;\n",
       "  height: 80%;\n",
       "  background: linear-gradient(90deg,red 100.0%, transparent 100.0%);\n",
       "}\n",
       "#T_27149_row1_col2 {\n",
       "  width: 10em;\n",
       "  height: 80%;\n",
       "  background: linear-gradient(90deg,lightskyblue 23.8%, transparent 23.8%);\n",
       "}\n",
       "#T_27149_row1_col3 {\n",
       "  width: 10em;\n",
       "  height: 80%;\n",
       "  background: linear-gradient(90deg,lightgreen 33.9%, transparent 33.9%);\n",
       "}\n",
       "#T_27149_row1_col4 {\n",
       "  width: 10em;\n",
       "  height: 80%;\n",
       "  background: linear-gradient(90deg,orange 40.9%, transparent 40.9%);\n",
       "}\n",
       "#T_27149_row1_col5 {\n",
       "  width: 10em;\n",
       "  height: 80%;\n",
       "  background: linear-gradient(90deg,red 46.8%, transparent 46.8%);\n",
       "}\n",
       "#T_27149_row2_col2 {\n",
       "  width: 10em;\n",
       "  height: 80%;\n",
       "  background: linear-gradient(90deg,lightskyblue 18.5%, transparent 18.5%);\n",
       "}\n",
       "#T_27149_row2_col3 {\n",
       "  width: 10em;\n",
       "  height: 80%;\n",
       "  background: linear-gradient(90deg,lightgreen 16.7%, transparent 16.7%);\n",
       "}\n",
       "#T_27149_row2_col4 {\n",
       "  width: 10em;\n",
       "  height: 80%;\n",
       "  background: linear-gradient(90deg,orange 63.6%, transparent 63.6%);\n",
       "}\n",
       "#T_27149_row2_col5 {\n",
       "  width: 10em;\n",
       "  height: 80%;\n",
       "  background: linear-gradient(90deg,red 69.0%, transparent 69.0%);\n",
       "}\n",
       "#T_27149_row3_col2 {\n",
       "  width: 10em;\n",
       "  height: 80%;\n",
       "  background: linear-gradient(90deg,lightskyblue 0.7%, transparent 0.7%);\n",
       "}\n",
       "#T_27149_row3_col3 {\n",
       "  width: 10em;\n",
       "  height: 80%;\n",
       "  background: linear-gradient(90deg,lightgreen 70.2%, transparent 70.2%);\n",
       "}\n",
       "#T_27149_row3_col4 {\n",
       "  width: 10em;\n",
       "  height: 80%;\n",
       "  background: linear-gradient(90deg,orange 68.2%, transparent 68.2%);\n",
       "}\n",
       "#T_27149_row3_col5 {\n",
       "  width: 10em;\n",
       "  height: 80%;\n",
       "  background: linear-gradient(90deg,red 84.0%, transparent 84.0%);\n",
       "}\n",
       "#T_27149_row4_col3 {\n",
       "  width: 10em;\n",
       "  height: 80%;\n",
       "  background: linear-gradient(90deg,lightgreen 100.0%, transparent 100.0%);\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_27149_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >Model_N</th>\n",
       "      <th class=\"col_heading level0 col1\" >Imbalance</th>\n",
       "      <th class=\"col_heading level0 col2\" >auc</th>\n",
       "      <th class=\"col_heading level0 col3\" >precision</th>\n",
       "      <th class=\"col_heading level0 col4\" >recall</th>\n",
       "      <th class=\"col_heading level0 col5\" >F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_27149_level0_row0\" class=\"row_heading level0 row0\" >1</th>\n",
       "      <td id=\"T_27149_row0_col0\" class=\"data row0 col0\" >deep_learning</td>\n",
       "      <td id=\"T_27149_row0_col1\" class=\"data row0 col1\" >over_sample</td>\n",
       "      <td id=\"T_27149_row0_col2\" class=\"data row0 col2\" >97.34%</td>\n",
       "      <td id=\"T_27149_row0_col3\" class=\"data row0 col3\" >0.836</td>\n",
       "      <td id=\"T_27149_row0_col4\" class=\"data row0 col4\" >0.605</td>\n",
       "      <td id=\"T_27149_row0_col5\" class=\"data row0 col5\" >0.702290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_27149_level0_row1\" class=\"row_heading level0 row1\" >3</th>\n",
       "      <td id=\"T_27149_row1_col0\" class=\"data row1 col0\" >deep_learning</td>\n",
       "      <td id=\"T_27149_row1_col1\" class=\"data row1 col1\" >SMOTE_TOMEK</td>\n",
       "      <td id=\"T_27149_row1_col2\" class=\"data row1 col2\" >96.60%</td>\n",
       "      <td id=\"T_27149_row1_col3\" class=\"data row1 col3\" >0.892</td>\n",
       "      <td id=\"T_27149_row1_col4\" class=\"data row1 col4\" >0.434</td>\n",
       "      <td id=\"T_27149_row1_col5\" class=\"data row1 col5\" >0.584071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_27149_level0_row2\" class=\"row_heading level0 row2\" >4</th>\n",
       "      <td id=\"T_27149_row2_col0\" class=\"data row2 col0\" >deep_learning</td>\n",
       "      <td id=\"T_27149_row2_col1\" class=\"data row2 col1\" >nan</td>\n",
       "      <td id=\"T_27149_row2_col2\" class=\"data row2 col2\" >96.55%</td>\n",
       "      <td id=\"T_27149_row2_col3\" class=\"data row2 col3\" >0.864</td>\n",
       "      <td id=\"T_27149_row2_col4\" class=\"data row2 col4\" >0.5</td>\n",
       "      <td id=\"T_27149_row2_col5\" class=\"data row2 col5\" >0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_27149_level0_row3\" class=\"row_heading level0 row3\" >0</th>\n",
       "      <td id=\"T_27149_row3_col0\" class=\"data row3 col0\" >deep_learning</td>\n",
       "      <td id=\"T_27149_row3_col1\" class=\"data row3 col1\" >under_sample</td>\n",
       "      <td id=\"T_27149_row3_col2\" class=\"data row3 col2\" >96.38%</td>\n",
       "      <td id=\"T_27149_row3_col3\" class=\"data row3 col3\" >0.951</td>\n",
       "      <td id=\"T_27149_row3_col4\" class=\"data row3 col4\" >0.513</td>\n",
       "      <td id=\"T_27149_row3_col5\" class=\"data row3 col5\" >0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_27149_level0_row4\" class=\"row_heading level0 row4\" >2</th>\n",
       "      <td id=\"T_27149_row4_col0\" class=\"data row4 col0\" >deep_learning</td>\n",
       "      <td id=\"T_27149_row4_col1\" class=\"data row4 col1\" >SMOTE</td>\n",
       "      <td id=\"T_27149_row4_col2\" class=\"data row4 col2\" >96.37%</td>\n",
       "      <td id=\"T_27149_row4_col3\" class=\"data row4 col3\" >1.0</td>\n",
       "      <td id=\"T_27149_row4_col4\" class=\"data row4 col4\" >0.316</td>\n",
       "      <td id=\"T_27149_row4_col5\" class=\"data row4 col5\" >0.480000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1c2637a61c0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result_dl.rename(columns = {'pecision':'precision'}, inplace=True)\n",
    "df_result_dl= df_result_dl.sort_values('auc',ascending= False)\n",
    "def display_metrics(df_result_dl):\n",
    "    return df_result_dl.style.bar(subset=['auc'], color='lightskyblue')\\\n",
    "                    .bar(subset=[\"precision\"], color='lightgreen')\\\n",
    "                    .bar(subset=[\"recall\"], color='orange')\\\n",
    "                    .bar(subset=[\"F1\"], color='red')\\\n",
    "                    .format({'auc':'{:.2%}','precision':'{:.3}','recall':'{:.3}'})\n",
    "df_filter_got_result =df_result_dl[[\"Model_N\",\"Imbalance\",\"auc\",'precision','recall','F1']]\n",
    "display_metrics(df_filter_got_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "306badf5-d579-470f-ad16-7f6cb9fd6a53",
   "metadata": {},
   "source": [
    "# Conclussion  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0993835-5a49-469a-a232-f598d7231bad",
   "metadata": {},
   "source": [
    "### Deep learning approch with  over-sampling inbalance handling method has auc score at 97.34% and F1 is 0.7 that provide greater performance than other  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
